{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88968,"status":"ok","timestamp":1743324243984,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"PaOkiimBIHdE","outputId":"438125d5-c804-4722-9a2c-e47ec0017bb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing CLIP...\n","Number of GPUs available: 1\n","Using GPU: cuda:0\n","Devices: ['cuda:0']\n","Number of CPU cores available: 12\n","THREAD_NUMBER set to: 2\n","Sun Mar 30 08:44:03 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0             44W /  400W |       5MiB /  40960MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","\n","Architecture:                         x86_64\n","CPU op-mode(s):                       32-bit, 64-bit\n","Address sizes:                        46 bits physical, 48 bits virtual\n","Byte Order:                           Little Endian\n","CPU(s):                               12\n","On-line CPU(s) list:                  0-11\n","Vendor ID:                            GenuineIntel\n","Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\n","CPU family:                           6\n","Model:                                85\n","Thread(s) per core:                   2\n","Core(s) per socket:                   6\n","Socket(s):                            1\n","Stepping:                             7\n","BogoMIPS:                             4400.39\n","Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","Hypervisor vendor:                    KVM\n","Virtualization type:                  full\n","L1d cache:                            192 KiB (6 instances)\n","L1i cache:                            192 KiB (6 instances)\n","L2 cache:                             6 MiB (6 instances)\n","L3 cache:                             38.5 MiB (1 instance)\n","NUMA node(s):                         1\n","NUMA node0 CPU(s):                    0-11\n","Vulnerability Gather data sampling:   Not affected\n","Vulnerability Itlb multihit:          Not affected\n","Vulnerability L1tf:                   Not affected\n","Vulnerability Mds:                    Not affected\n","Vulnerability Meltdown:               Not affected\n","Vulnerability Mmio stale data:        Vulnerable\n","Vulnerability Reg file data sampling: Not affected\n","Vulnerability Retbleed:               Vulnerable\n","Vulnerability Spec rstack overflow:   Not affected\n","Vulnerability Spec store bypass:      Vulnerable\n","Vulnerability Spectre v1:             Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers\n","Vulnerability Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIBRS: Vulnerable; BHI: Vulnerable (Syscall hardening enabled)\n","Vulnerability Srbds:                  Not affected\n","Vulnerability Tsx async abort:        Vulnerable\n","\n"]}],"source":["import os\n","os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"  # or \":16:8\"\n","\n","import sys\n","import subprocess\n","\n","def install(package):\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n","\n","# Function to attempt to import a module, and install it if not present\n","def try_import(module_name, package_name=None):\n","    try:\n","        module = __import__(module_name)\n","        return module\n","    except ImportError:\n","        if package_name is None:\n","            package_name = module_name\n","        print(f\"Installing {package_name}...\")\n","        install(package_name)\n","        module = __import__(module_name)\n","        return module\n","\n","# Standard library imports (no need to install)\n","import logging\n","from datetime import datetime\n","from copy import deepcopy\n","import gc\n","import random\n","import time\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from typing import Iterable, Union, Optional\n","\n","# Third-party imports\n","torch = try_import('torch')\n","torchvision = try_import('torchvision')\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import numpy as np\n","np = try_import('numpy')\n","# Import torch.nn as nn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split, Subset, Dataset\n","import torchvision.models as models\n","from torch.nn.functional import tanh, softmax\n","\n","from torchvision.datasets import utils\n","from PIL import Image\n","import os.path\n","import shutil\n","\n","\n","# sklearn imports\n","sklearn = try_import('sklearn', 'scikit-learn')\n","from sklearn.model_selection import train_test_split\n","from sklearn.cluster import AgglomerativeClustering, KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.metrics.pairwise import cosine_distances,euclidean_distances\n","from sklearn.metrics import pairwise_distances\n","\n","\n","# Other third-party imports\n","plt = try_import('matplotlib.pyplot', 'matplotlib')\n","pd = try_import('pandas')\n","\n","# Install and import CLIP\n","try:\n","    import clip\n","except ImportError:\n","    print(\"Installing CLIP...\")\n","    install('git+https://github.com/openai/CLIP.git')\n","    import clip\n","\n","\n","\n","# torch.use_deterministic_algorithms(True, warn_only=True)\n","torch.manual_seed(0)\n","\n","# Device configuration\n","# Get the number of available GPUs\n","num_gpus = torch.cuda.device_count()\n","print(f\"Number of GPUs available: {num_gpus}\")\n","\n","# If GPUs are available, choose the desired device index (within the available range)\n","# Otherwise, default to CPU\n","if num_gpus > 0:\n","    desired_gpu_index = 3  # This is the index you originally wanted\n","    device_index = min(desired_gpu_index, num_gpus - 1)  # Clamp to available range\n","    device = torch.device(f\"cuda:{device_index}\")\n","    torch.cuda.set_device(device)  # Set the device\n","    print(f\"Using GPU: {device}\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"No GPUs available, using CPU.\")\n","\n","\n","#set devices to multiple GPUs\n","unwanted_device_indices = []\n","available_device_indices = list(range(num_gpus))\n","devices = [f'cuda:{i}' for i in available_device_indices if i not in unwanted_device_indices]\n","if not devices:\n","    devices = ['cpu']\n","    # raise RuntimeError(\"Desired GPUs are not available.\")\n","print(f\"Devices: {devices}\")\n","\n","\n","\n","\n","import multiprocessing\n","\n","# Get the number of available CPU cores\n","num_cores = multiprocessing.cpu_count()\n","\n","# Set THREAD_NUMBER to the number of CPU cores\n","THREAD_NUMBER = min(num_cores, 2*(len(devices)))\n","# THREAD_NUMBER = 20 # num_cores\n","\n","print(f\"Number of CPU cores available: {num_cores}\")\n","print(f\"THREAD_NUMBER set to: {THREAD_NUMBER}\")\n","\n","\n","\n","# Check GPU information\n","def check_gpu():\n","    try:\n","        gpu_info = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n","        print(gpu_info)\n","    except Exception as e:\n","        print('Not connected to a GPU or nvidia-smi not found.')\n","\n","check_gpu()\n","\n","# Check CPU information\n","def check_cpu():\n","    try:\n","        cpu_info = subprocess.check_output(['lscpu']).decode('utf-8')\n","        print(cpu_info)\n","    except Exception as e:\n","        print('Could not retrieve CPU information.')\n","\n","check_cpu()"]},{"cell_type":"markdown","metadata":{"id":"TPXgVfNmnhES"},"source":["# Function to determine the data root directory"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31472,"status":"ok","timestamp":1743324275456,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"_QYFIElVnecH","outputId":"719b38e3-3582-4b7d-bcf8-170c00309b91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Function to determine the data root directory\n","def get_data_root():\n","    if 'COLAB_GPU' in os.environ:\n","        # Mount Google Drive if needed\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        data_root = '/content/drive/MyDrive/PhD/XFED result/Result XFED log/colab output/'\n","    else:\n","        data_root = './data/'\n","    return data_root\n","\n","# Get the appropriate data root directory\n","data_root = get_data_root()"]},{"cell_type":"markdown","metadata":{"id":"TLIncX6sIy49"},"source":["# Model Definition for different datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1743324275479,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"7zE8s1djJkuN"},"outputs":[],"source":["class FashionMNISTAlexNet(nn.Module):\n","    def __init__(self):\n","        super(FashionMNISTAlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=0),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 10),\n","            nn.LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","class FeatureNorm(nn.Module):\n","    def __init__(self, feature_shape):\n","        super().__init__()\n","        self.gamma = nn.Parameter(torch.ones(1))\n","        self.beta = nn.Parameter(torch.zeros(1, feature_shape))\n","\n","    def forward(self, x):\n","        x = torch.einsum('ni, j->ni', x, self.gamma)\n","        x = x + self.beta\n","        return  x\n","\n","class purchase_fully_connected_IN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(purchase_fully_connected_IN, self).__init__()\n","        self.fc1 = nn.Linear(600, 1024, bias=False)  # First layer: input size 600, output size 1024\n","        self.fc2 = nn.Linear(1024, 100, bias=False)  # Second layer: input size 1024, output size 100\n","        self.fc3 = nn.Linear(100, num_classes, bias=False)  # Output layer: input size 100, output size num_classes\n","        self.norm = FeatureNorm(600)\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","        x = torch.tanh(self.fc1(x))  # Apply tanh activation after the first layer\n","        x = torch.tanh(self.fc2(x))  # Apply tanh activation after the second layer\n","        logits = self.fc3(x)         # Output layer, no activation\n","        return logits\n","\n","class Purchase(torch.utils.data.Dataset):\n","    def __init__(self, root =data_root + 'dataset_purchase',train=True, download=True, transform = None):\n","        self.images = []\n","        self.root = root\n","        self.targets = []\n","        self.train = train\n","        self.download = download\n","        self.transform = transform\n","\n","        x_train, x_test, y_train, y_test = self._train_test_split()\n","\n","        if self.train:\n","            self._setup_dataset(x_train, y_train)\n","        else:\n","            self._setup_dataset(x_test, y_test)\n","\n","    def _train_test_split(self):\n","        df = pd.read_csv(self.root)\n","\n","        img_names = df.iloc[:, 1:].to_numpy(dtype='f')\n","        img_label = df.iloc[:, 0].to_numpy()-1\n","        x_train,x_test, y_train, y_test = train_test_split(img_names, img_label, train_size=0.8,\n","                                                            random_state=1)\n","        return x_train, x_test, y_train, y_test\n","\n","    def _setup_dataset(self, x, y):\n","            self.images = x\n","            self.targets = y\n","\n","    def __len__(self): # Added the __len__ method\n","        return len(self.images)\n","\n","    def __getitem__(self, item):\n","        img = self.images[item]\n","        label = self.targets[item]\n","        return img, label\n","\n","class ThreeLayerDNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(ThreeLayerDNN, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu1 = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.relu2 = nn.ReLU()\n","        self.fc3 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","class FourLayerDNN(nn.Module):\n","    def __init__(self):\n","        super(FourLayerDNN, self).__init__()\n","        # Flatten the input image\n","        self.flatten = nn.Flatten()\n","        # Define the fully connected layers\n","        self.fc1 = nn.Linear(3 * 32 * 32, 1024)\n","        self.relu1 = nn.ReLU()\n","        self.fc2 = nn.Linear(1024, 512)\n","        self.relu2 = nn.ReLU()\n","        self.fc3 = nn.Linear(512, 256)\n","        self.relu3 = nn.ReLU()\n","        self.fc4 = nn.Linear(256, 10)  # Output layer for 10 classes\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.relu1(self.fc1(x))\n","        x = self.relu2(self.fc2(x))\n","        x = self.relu3(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","class InputNorm(nn.Module):\n","    def __init__(self, num_channel, num_feature):\n","        super().__init__()\n","        self.num_channel = num_channel\n","        self.gamma = nn.Parameter(torch.ones(num_channel))\n","        self.beta = nn.Parameter(torch.zeros(num_channel, num_feature, num_feature))\n","    def forward(self, x):\n","        if self.num_channel == 1:\n","            x = self.gamma*x\n","            x = x + self.beta\n","            return  x\n","        if self.num_channel == 3:\n","            return torch.einsum('...ijk, i->...ijk', x, self.gamma) + self.beta\n","\n","class mnist_fully_connected_IN(nn.Module):\n","    def __init__(self,num_classes):\n","        super(mnist_fully_connected_IN, self).__init__()\n","        self.hidden1 = 600\n","        self.hidden2 = 100\n","        self.fc1 = nn.Linear(28 * 28, self.hidden1, bias=False)\n","        self.fc2 = nn.Linear(self.hidden1, self.hidden2, bias=False)\n","        self.fc3 = nn.Linear(self.hidden2, num_classes, bias=False)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.norm = InputNorm(1, 28)\n","\n","    def forward(self,x):\n","        x = self.norm(x)\n","        x = x.view(-1, 28 * 28)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        logits = self.fc3(x)\n","        return logits\n","\n","class CHMNISTDataset(Dataset):\n","    def __init__(self, image_folder, transform=None):\n","        self.image_folder = image_folder\n","        self.transform = transform\n","        self.image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder)]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image = Image.open(image_path).convert('L')  # Convert to grayscale\n","        label = int(image_path.split('_')[-1].split('.')[0])  # Assuming label is in filename\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","class LogisticRegressionModel(nn.Module):\n","    def __init__(self, input_dim):\n","        super(LogisticRegressionModel, self).__init__()\n","        # Define the linear layer for logistic regression\n","        self.linear = nn.Linear(input_dim, 1)\n","\n","    def forward(self, x):\n","        # Apply the linear layer and then the sigmoid activation\n","        out = torch.sigmoid(self.linear(x))\n","        return out\n","\n","class FEMNISTDataset(torchvision.datasets.MNIST):\n","    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n","        super(torchvision.datasets.MNIST, self).__init__(root, transform=transform, target_transform=target_transform)\n","        self.download = download\n","        self.download_link = 'https://media.githubusercontent.com/media/GwenLegate/femnist-dataset-PyTorch/main/femnist.tar.gz'\n","        self.file_md5 = 'a8a28afae0e007f1acb87e37919a21db'\n","        self.train = train\n","        self.root = root\n","        self.training_file = f'{self.root}/FEMNIST/processed/femnist_train.pt'\n","        self.test_file = f'{self.root}/FEMNIST/processed/femnist_test.pt'\n","        self.user_list = f'{self.root}/FEMNIST/processed/femnist_user_keys.pt'\n","\n","        if not os.path.exists(f'{self.root}/FEMNIST/processed/femnist_test.pt') \\\n","                or not os.path.exists(f'{self.root}/FEMNIST/processed/femnist_train.pt'):\n","            if self.download:\n","                self.dataset_download()\n","            else:\n","                raise RuntimeError('Dataset not found, set parameter download=True to download')\n","\n","        if self.train:\n","            data_file = self.training_file\n","        else:\n","            data_file = self.test_file\n","\n","        data_targets_users = torch.load(data_file)\n","        self.data, self.targets, self.users = torch.Tensor(data_targets_users[0]), torch.Tensor(data_targets_users[1]), data_targets_users[2]\n","        self.user_ids = torch.load(self.user_list)\n","\n","    def __getitem__(self, index):\n","        img, target = self.data[index], int(self.targets[index])\n","\n","        # Reshape the flattened image to 28x28\n","        img = img.view(28, 28).numpy().astype(np.uint8)\n","\n","        # Convert to PIL Image in grayscale mode\n","        img = Image.fromarray(img, mode='L')\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","        return img, target  # Return only img and target\n","\n","    def dataset_download(self):\n","        paths = [f'{self.root}/FEMNIST/raw/', f'{self.root}/FEMNIST/processed/']\n","        for path in paths:\n","            if not os.path.exists(path):\n","                os.makedirs(path)\n","\n","        # download files\n","        filename = self.download_link.split('/')[-1]\n","        utils.download_and_extract_archive(self.download_link, download_root=f'{self.root}/FEMNIST/raw/', filename=filename, md5=self.file_md5)\n","\n","        files = ['femnist_train.pt', 'femnist_test.pt', 'femnist_user_keys.pt']\n","        for file in files:\n","            # move to processed dir\n","            shutil.move(os.path.join(f'{self.root}/FEMNIST/raw/', file), f'{self.root}/FEMNIST/processed/')"]},{"cell_type":"markdown","metadata":{"id":"2o1uD2lVKAqO"},"source":["Loading Model for different datasets (FashionMNIST, CIFAR-10, PURCHASE, MNIST, EMNIST, CIFAR-100)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1743324275506,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"tGc5WAzrKNDl"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","class SymbiPredictDataset(Dataset):\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        features = torch.tensor(self.data[idx], dtype=torch.float32)\n","        label = torch.tensor(self.labels[idx], dtype=torch.long)\n","        return features, label\n","\n","class TabularNet(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(TabularNet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, num_classes)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","def load_model(dataset: str):\n","    \"\"\"Load and prepare the model and datasets based on the given dataset name.\"\"\"\n","    if dataset == 'FashionMNIST':\n","        transform = transforms.Compose([\n","            transforms.Resize((227, 227)),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.1307,), (0.3081,))\n","        ])\n","        train_data = torchvision.datasets.FashionMNIST(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.FashionMNIST(root=data_root, train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","        classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n","        model = FashionMNISTAlexNet().to(device)\n","\n","    elif dataset == 'CIFAR10':\n","        transform = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        ])\n","        train_data = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","        classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n","\n","        model = models.alexnet(pretrained=True)\n","        model.classifier[1] = nn.Linear(9216, 4096)\n","        model.classifier[4] = nn.Linear(4096, 1024)\n","        model.classifier[6] = nn.Linear(1024, 10)\n","        model = model.to(device)\n","\n","    elif dataset == 'PURCHASE':\n","        train_data = Purchase(train=True, download=True)\n","        test_data = Purchase(train=False, download=True)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","\n","        model = purchase_fully_connected_IN(100).to(device)\n","\n","    elif dataset == 'CHMNIST':\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5,), (0.5,))\n","        ])\n","        train_data = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform) # Assuming CHMNIST is similar to MNIST\n","        test_data = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","        trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n","        testloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n","        model=models.mobilenet_v2(pretrained=True).to(device)\n","        model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","\n","\n","\n","    elif dataset == 'EMNIST':\n","        transform = transforms.Compose([\n","            transforms.Resize((28, 28)),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5,), (0.5,))\n","        ])\n","\n","        train_data = torchvision.datasets.EMNIST(root=data_root, split='byclass', train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.EMNIST(root=data_root, split='byclass', train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","\n","        model = ThreeLayerDNN(input_size=28 * 28, hidden_size=512, output_size=62).to(device)\n","\n","    elif dataset == 'MNIST':\n","        # Define transformation for MNIST\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),        # Convert image to PyTorch tensor\n","            transforms.Normalize((0.5,), (0.5,))  # Normalize grayscale values to [-1, 1]\n","        ])\n","\n","        # Load the MNIST dataset (\"ByClass\" split as an example)\n","        train_data = torchvision.datasets.MNIST(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.MNIST(root=data_root, train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","\n","        # Load the pre-trained VGG16 model\n","        model = mnist_fully_connected_IN(10).to(device)\n","\n","    elif dataset == 'CIFAR100':\n","        # Define the transformation for the dataset (matching CLIP preprocessing)\n","        transform = transforms.Compose([\n","            transforms.Resize((224, 224)),  # CLIP expects 224x224 input\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),\n","        ])\n","\n","        # Load the CIFAR100 dataset\n","        train_data = torchvision.datasets.CIFAR100(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.CIFAR100(root=data_root, train=False, download=True, transform=transform)\n","\n","        # Create DataLoader for train and test sets\n","        trainloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=8)\n","        testloader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=8)\n","\n","        # Define the class labels for CIFAR100\n","        classes = [str(i) for i in range(100)]  # CIFAR100 has 100 classes\n","\n","        # Load the CLIP model from OpenAI\n","        model_clip, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","        # Convert CLIP model to float32 to match other layers and data\n","        model_clip = model_clip.float()\n","\n","        # Freeze the CLIP model's parameters (we're only training the classifier)\n","        for param in model_clip.parameters():\n","            param.requires_grad = False\n","\n","        # Define a simple 1-layer DNN model on top of CLIP features\n","        class CLIP_DNN(nn.Module):\n","            def __init__(self, clip_model, num_classes=100):\n","                super(CLIP_DNN, self).__init__()\n","                self.clip_model = clip_model\n","                self.fc = nn.Linear(512, num_classes)  # CLIP ViT-B/32 gives 512-dimensional features\n","\n","            def forward(self, images):\n","                with torch.no_grad():\n","                    # Extract image features using CLIP's image encoder (cast to float32)\n","                    image_features = self.clip_model.encode_image(images).float()\n","                return self.fc(image_features)\n","\n","        # Initialize the model\n","        model = CLIP_DNN(model_clip, num_classes=100)\n","\n","        # Move the model to the device (GPU or CPU)\n","        model = model.to(device)\n","\n","\n","    elif dataset == 'SYMBIPREDICT':\n","        # Load the CSV file\n","        csv_file = os.path.join(data_root, 'symbipredict_2022.csv')\n","        df = pd.read_csv(csv_file)\n","\n","        # Encode target labels\n","        label_encoder = LabelEncoder()\n","        df['prognosis'] = label_encoder.fit_transform(df['prognosis'])\n","\n","        # Separate features and labels\n","        X = df.drop(columns=['prognosis']).values\n","        y = df['prognosis'].values\n","\n","        # Standardize features\n","        scaler = StandardScaler()\n","        X = scaler.fit_transform(X)\n","\n","        # Split into training and testing sets\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","        # Create Dataset instances\n","        train_data = SymbiPredictDataset(X_train, y_train)\n","        test_data = SymbiPredictDataset(X_test, y_test)\n","\n","        # DataLoader for test data only\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n","\n","        # Define model\n","        input_dim = X_train.shape[1]\n","        num_classes = len(label_encoder.classes_)\n","        model = TabularNet(input_dim=input_dim, num_classes=num_classes).to(device)\n","\n","    else:\n","        raise ValueError(\"Dataset not supported\")\n","\n","    return model, train_data, testloader\n"]},{"cell_type":"markdown","metadata":{"id":"htLtRlfGK1ku"},"source":["Aggregation Rules (\n","FedAvg / Mean,\n","Median,\n","Trimmed Mean,\n","Multi-Krum,\n","Clipped Clustering,\n","SignGuard)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1743324275514,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"qwM4nYoULKwO"},"outputs":[],"source":["def tr_mean(all_updates: torch.Tensor) -> torch.Tensor:\n","    \"\"\"Apply Trimmed Mean aggregation with 20% assumed attackers.\"\"\"\n","    # tmp = all_updates\n","    # all_updates = all_updates.cpu()\n","    # del tmp\n","    # torch.cuda.empty_cache()\n","    sorted_updates = torch.sort(all_updates, dim=0)[0]\n","    num_clients = len(all_updates)\n","    n_attackers = round(0.2 * num_clients)\n","    if n_attackers != 0 and 2 * n_attackers < num_clients:\n","        ret = torch.mean(sorted_updates[n_attackers:-n_attackers], dim=0)\n","        # print(\"sorted_updates\", sorted_updates)\n","        # print(\"num_clients\", num_clients)\n","        # print(\"n_attackers\", n_attackers)\n","        # print(\"ret\", ret)\n","        return ret\n","    return torch.mean(sorted_updates, dim=0).to(device)\n","\n","def multi_krum_optimized(local_updates: torch.Tensor):\n","    \"\"\"\n","    Implements a memory-optimized version of the Multi-Krum aggregation rule with explicit deletion of local variables.\n","    Parameters:\n","    - local_updates: A tensor of shape (num_clients, num_params) containing the flattened model updates from each client.\n","    Returns:\n","    - The aggregated model update as a tensor of shape (num_params,).\n","    \"\"\"\n","    num_clients = local_updates.size(0)\n","    byzantine_client_num = int(num_clients * 0.2)  # Assuming 20% are byzantine clients\n","    krum_limit = num_clients - byzantine_client_num - 2\n","\n","    # Instead of computing a full pairwise distance matrix, compute distances incrementally\n","    scores = torch.zeros(num_clients)\n","\n","    for i in range(num_clients):\n","        # Compute the squared L2 distances between client `i` and all other clients\n","        distances = torch.sum((local_updates - local_updates[i]) ** 2, dim=1)\n","\n","        # Sort distances and ignore the first distance (which is 0, i.e., distance to itself)\n","        sorted_distances, _ = torch.sort(distances)\n","\n","        # Sum the smallest `krum_limit` distances (ignore the first one)\n","        scores[i] = torch.sum(sorted_distances[1:krum_limit + 1])\n","\n","        # Explicitly delete large tensors to free memory\n","        del distances, sorted_distances\n","\n","    # Select the indices of the `krum_limit` clients with the lowest scores\n","    selected_indices = torch.topk(-scores, krum_limit, largest=True).indices\n","\n","    # Average the updates of the selected clients\n","    aggregated_update = torch.mean(local_updates[selected_indices], dim=0)\n","\n","    # Clean up memory before returning\n","    del scores, local_updates\n","\n","    return aggregated_update, selected_indices\n","\n","def clip_tensor_norm_(\n","    parameters: Union[torch.Tensor, Iterable[torch.Tensor]],\n","    max_norm: float,\n","    norm_type: float = 2.0,\n","    error_if_nonfinite: bool = False,\n",") -> torch.Tensor:\n","    if isinstance(parameters, torch.Tensor):\n","        parameters = [parameters]\n","\n","    max_norm = float(max_norm)\n","    norm_type = float(norm_type)\n","\n","    if len(parameters) == 0:\n","        return torch.tensor(0.0)\n","\n","    device = parameters[0].device\n","\n","    if norm_type ==  float('inf'):\n","        norms = [p.detach().abs().max().to(device) for p in parameters]\n","        total_norm = norms[0] if len(norms) == 1 else torch.max(torch.stack(norms))\n","    else:\n","        total_norm = torch.norm(\n","            torch.cat(\n","                [\n","                    p.detach().view(-1).to(device)\n","                    for p in parameters\n","                    if p.dtype != torch.int64\n","                ]\n","            ),\n","            norm_type,\n","        )\n","\n","    if error_if_nonfinite and torch.logical_or(total_norm.isnan(), total_norm.isinf()):\n","        raise RuntimeError(\n","            f\"The total norm of order {norm_type} for gradients from \"\n","            \"`parameters` is non-finite, so it cannot be clipped. To disable \"\n","            \"this error and scale the gradients by the non-finite norm anyway, \"\n","            \"set `error_if_nonfinite=False`\"\n","        )\n","\n","    clip_coef = max_norm / (total_norm + 1e-6)\n","    clip_coef_clamped = torch.clamp(clip_coef, max=1.0)\n","\n","    for p in parameters:\n","        if p.dtype != torch.int64:\n","            p.mul_(clip_coef_clamped.to(p.device))\n","\n","def Clippedclustering(updates: torch.Tensor):\n","    tau = 1e5\n","    l2norm_his = []\n","\n","    # Calculate L2 norms in a single operation\n","    l2norms = [torch.norm(update).item() for update in updates]\n","    l2norm_his.extend(l2norms)\n","\n","    threshold = np.median(l2norm_his)\n","    threshold = min(threshold, tau)\n","\n","    # Clip tensor norms above the threshold\n","    for idx, l2 in enumerate(l2norms):\n","        if l2 > threshold:\n","            clip_tensor_norm_(updates[idx], threshold)\n","\n","    num = len(updates)\n","\n","    dis_max = 1 - torch.mm(\n","        updates, updates.t()\n","    ).cpu().numpy()  # Convert to numpy for AgglomerativeClustering\n","\n","    # Handle boundary conditions for distance matrix\n","    dis_max = np.where(np.isinf(dis_max), 2.0, np.where(np.isnan(dis_max), 2.0, dis_max))\n","\n","    # Hierarchical clustering\n","    clustering = AgglomerativeClustering(\n","        metric=\"precomputed\", linkage=\"average\", n_clusters=2\n","    )\n","    clustering.fit(dis_max)\n","\n","    flag = 1 if np.sum(clustering.labels_) > num // 2 else 0\n","    S1_idxs = [idx for idx, label in enumerate(clustering.labels_) if label == flag]\n","\n","    # Vectorized feature extraction\n","    num_para = len(updates[0])\n","    feature0 = (updates > 0).float().mean(dim=1)\n","    feature1 = (updates < 0).float().mean(dim=1)\n","    feature2 = (updates == 0).float().mean(dim=1)\n","\n","    features = torch.stack([feature0, feature1, feature2], dim=1).cpu().numpy()\n","\n","    # KMeans clustering\n","    kmeans = KMeans(n_clusters=2, random_state=0).fit(features)\n","    flag = 1 if np.sum(kmeans.labels_) > num // 2 else 0\n","    S2_idxs = [idx for idx, label in enumerate(kmeans.labels_) if label == flag]\n","\n","    # Select intersection of both clustering methods\n","    selected_idxs = list(set(S1_idxs) & set(S2_idxs))\n","\n","    # Return the mean of selected updates\n","    return torch.mean(updates[selected_idxs], dim=0)\n","\n","def SignGuard(updates):\n","    # updates = updates.cpu()\n","\n","    num = updates.shape[0]\n","    # Compute L2 norms across all dimensions except the first\n","    l2norms = torch.norm(updates, dim=tuple(range(1, updates.ndim)))\n","\n","    # Compute the median using torch.median (stays on GPU)\n","    M = torch.median(l2norms)\n","    L = 0.1\n","    R = 3.0\n","\n","    # Create a mask for S1 indices\n","    mask1 = (l2norms >= L * M) & (l2norms <= R * M)\n","    del l2norms, M  # Delete l2norms and M as they're no longer needed\n","    torch.cuda.empty_cache()\n","\n","    # Flatten updates for feature computation\n","    updates_flat = updates.view(updates.shape[0], -1).cpu()\n","    num_para = updates_flat.size(1)\n","\n","    # Compute features using vectorized operations\n","    positive_counts = (updates_flat > 0).sum(dim=1).float() / num_para\n","    negative_counts = (updates_flat < 0).sum(dim=1).float() / num_para\n","    zero_counts = (updates_flat == 0).sum(dim=1).float() / num_para\n","\n","    features = torch.stack([positive_counts, negative_counts, zero_counts], dim=1).cpu().numpy()\n","    del updates_flat, positive_counts, negative_counts, zero_counts  # Clean up\n","    torch.cuda.empty_cache()\n","\n","    # Perform KMeans clustering\n","    kmeans = KMeans(n_clusters=2, random_state=0).fit(features)\n","    labels = kmeans.labels_\n","    del kmeans, features  # Clean up CPU memory\n","\n","    # Convert labels back to a CUDA tensor\n","    labels = torch.from_numpy(labels).to(device)\n","\n","    # Determine the majority cluster\n","    flag = 1 if labels.sum() > num // 2 else 0\n","\n","    # Create a mask for S2 indices\n","    mask2 = (labels == flag)\n","    del labels  # Delete labels as it's no longer needed\n","    torch.cuda.empty_cache()\n","\n","    # Intersection of S1 and S2 indices\n","    inter_mask = mask1 & mask2\n","    del mask1, mask2  # Clean up masks\n","    torch.cuda.empty_cache()\n","\n","    # Select the updates based on the intersection mask\n","    selected_updates = updates[inter_mask]\n","    del updates, inter_mask  # Delete updates and inter_mask\n","    torch.cuda.empty_cache()\n","\n","    # Compute and return the mean of the selected updates\n","    result = torch.mean(selected_updates, dim=0)\n","    del selected_updates  # Clean up selected_updates\n","    torch.cuda.empty_cache()\n","\n","    return result.to(device)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1743324275527,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"CD43V5SHHWwD"},"outputs":[],"source":["from collections import Counter\n","\n","def print_dataset_statistics(dataset):\n","    \"\"\"Prints dataset statistics including sample count, classes, and sample count per class.\n","\n","    Args:\n","        dataset: The PyTorch dataset object.\n","    \"\"\"\n","    labels = [label for _, label in dataset]  # Extract all labels\n","    label_counts = Counter(labels)            # Count label occurrences\n","\n","    num_samples = len(dataset)                # Total number of samples\n","    num_classes = len(label_counts)            # Number of unique classes\n","\n","    print(f\"Dataset Statistics:\")\n","    print(f\"  Number of samples: {num_samples}\")\n","    print(f\"  Number of classes: {num_classes}\")\n","    print(f\"  Sample count per class:\")\n","    for label, count in label_counts.items():\n","        print(f\"    Label {label}: {count} samples\")\n","\n","# # Example usage:\n","# global_model, train_data, testloader = load_model('MNIST')\n","# print_dataset_statistics(train_data)  # Assuming 'train_data' is your dataset"]},{"cell_type":"markdown","metadata":{"id":"WgmZW6tziyz6"},"source":["Attacks (XFED)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1743324275530,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"6ZFitOiQi5uH"},"outputs":[],"source":["def get_mu_pairwise_distance(global_models, MU_MULTIPLIER):\n","    \"\"\"Compute pairwise distance based deviation (mu).\"\"\"\n","    num_models = len(global_models)\n","    # print(\"num_models\", num_models)\n","    # print(\"global_models\", global_models)\n","    if num_models > 1:\n","        if isinstance(global_models, list):\n","            global_models_tensor = torch.vstack(global_models)\n","        else:\n","            global_models_tensor = global_models\n","        # Step 1: Calculate the centroid (mean vector)\n","        centroid = torch.mean(global_models_tensor, dim=0)\n","        # Step 2: Compute the Euclidean distance of each vector from the centroid\n","        # Step 3: Calculate the standard deviation of the distances\n","        distances = torch.norm(global_models_tensor - centroid, dim=1)\n","        std_dev = torch.sqrt(torch.dot(distances, distances) / num_models)\n","        mu = MU_MULTIPLIER * std_dev\n","        return mu\n","    else:\n","        return torch.tensor(0.0)\n","\n","def xfed_c(user_grads, n_attackers, dev_type, len_global, global_model_data, global_models, collab):\n","    if collab == 0:\n","        all_updates = user_grads[:n_attackers]\n","        start_idx = 0\n","    else:\n","        individual_attackers = n_attackers - collab\n","        all_updates = user_grads[individual_attackers:n_attackers]\n","        start_idx = individual_attackers\n","\n","    model_re = torch.mean(all_updates, dim=0).to(device)\n","\n","    if dev_type == 'C_XFED_unit_vec' or dev_type == 'Hybrid_XFED_unit_vec':\n","        deviation = model_re / torch.norm(model_re)\n","    elif dev_type == 'C_XFED_sign' or dev_type == 'Hybrid_XFED_sign':\n","        sgn_vec = torch.sign(model_re)\n","        deviation = sgn_vec / torch.norm(sgn_vec)\n","    elif dev_type == 'C_XFED_std':\n","        deviation = torch.std(all_updates, dim=0)\n","\n","    if len_global > 1:\n","        # print(torch.norm(model_re - global_model_data), get_mu_pairwise_distance(global_models, 3), get_mu_pairwise_distance(all_updates, 1))\n","        # mu = torch.max(torch.norm(model_re - global_model_data), get_mu_pairwise_distance(global_models))\n","        # mu = torch.max(torch.norm(model_re - global_model_data), get_mu_pairwise_distance(all_updates))\n","        mu = get_mu_pairwise_distance(all_updates, 3)\n","    else:\n","        mu = torch.tensor(1.0)\n","\n","     # Calculate delta and malicious updates\n","    deviation *= mu\n","    mal_update = (model_re - deviation)\n","\n","    del model_re, deviation\n","    torch.cuda.empty_cache()\n","\n","\n","    for i in range(start_idx, n_attackers):\n","        tmp = user_grads[i]\n","        user_grads[i] = mal_update\n","        del tmp\n","        torch.cuda.empty_cache()\n","\n","    return user_grads\n","\n","    # Create the final stacked tensor of updates\n","    # Combine the malicious updates with the rest of the user_grads\n","    # mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","    # return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dw82zh_Zjslf"},"source":["Attacks( VIRAT, FANG-TR-MEAN, FANG-KRUM, LIE)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1743324275536,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"ynbQi9pnjy-G"},"outputs":[],"source":["\n","def virat_min_max(user_grads, n_attackers, dev_type='VIRAT_unit_vec', epoch = 0, threshold=50):\n","    \"\"\"Implement VIRAT Min-Max attack.\"\"\"\n","    all_updates = user_grads[:n_attackers].to(device)\n","    model_re = torch.mean(all_updates, dim=0).to(device)\n","\n","    if dev_type == 'VIRAT_unit_vec':\n","        deviation = model_re / torch.norm(model_re)\n","    elif dev_type == 'VIRAT_sign':\n","        deviation = torch.sign(model_re)\n","    elif dev_type == 'VIRAT_std':\n","        deviation = torch.std(all_updates, dim=0)\n","    else:\n","        raise ValueError(f\"Unknown deviation type: {dev_type}\")\n","\n","    lamda = torch.tensor([threshold], dtype=torch.float).to(device)\n","    threshold_diff = 1e-5\n","    lamda_fail = lamda.clone()\n","    lamda_succ = torch.tensor(0, dtype=torch.float).to(device)\n","\n","    distances = []\n","    for update in all_updates:\n","        distance = torch.norm((all_updates - update), dim=1) ** 2\n","        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n","\n","    max_distance = torch.max(distances)\n","    del distances\n","\n","    while torch.abs(lamda_succ - lamda) > threshold_diff:\n","        mal_update = model_re - lamda * deviation\n","        distance = torch.norm(all_updates - mal_update, dim=1) ** 2\n","        max_d = torch.max(distance)\n","\n","        if max_d <= max_distance:\n","            lamda_succ = lamda.clone()\n","            lamda += lamda_fail / 2\n","        else:\n","            lamda -= lamda_fail / 2\n","\n","        lamda_fail /= 2\n","    print(f\"For round {epoch}, max_distance\", max_distance, \"lamda_succ\", lamda_succ)\n","    mal_update = (model_re - lamda_succ * deviation) #.to('cpu')\n","    mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","    return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n","\n","def fang_attack_trmean_partial(user_grads, n_attackers):\n","\n","    all_updates = user_grads[:n_attackers]\n","    model_re = torch.mean(all_updates, 0)\n","    model_std = torch.std(all_updates, 0)\n","    deviation = torch.sign(model_re)\n","\n","    max_vector_low = model_re + 3 * model_std\n","    max_vector_hig = model_re + 4 * model_std\n","    min_vector_low = model_re - 4 * model_std\n","    min_vector_hig = model_re - 3 * model_std\n","\n","    max_range = torch.cat((max_vector_low[:,None], max_vector_hig[:,None]), dim=1)\n","    min_range = torch.cat((min_vector_low[:,None], min_vector_hig[:,None]), dim=1)\n","\n","    rand = torch.from_numpy(np.random.uniform(0, 1, [len(deviation), n_attackers])).type(torch.FloatTensor).to(device)\n","\n","    max_rand = torch.stack([max_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([max_range[:, 1] - max_range[:, 0]] * rand.shape[1]).T\n","    min_rand = torch.stack([min_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([min_range[:, 1] - min_range[:, 0]] * rand.shape[1]).T\n","\n","    deviation_sign = (deviation > 0).type(torch.FloatTensor).to(device)\n","\n","    mal_update = (torch.stack([deviation_sign] * max_rand.shape[1]).T * max_rand + torch.stack(\n","        [deviation_sign] * min_rand.shape[1]).T * min_rand).T\n","\n","    return torch.cat((mal_update, user_grads[n_attackers:]), dim=0)\n","\n","def compute_lambda_fang(all_updates, model_re, n_attackers):\n","    distances = []\n","    n_benign, d = all_updates.shape\n","    for update in all_updates:\n","        distance = torch.norm((all_updates - update), dim=1)\n","        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n","\n","    distances[distances == 0] = 10000\n","    distances = torch.sort(distances, dim=1)[0]\n","    scores = torch.sum(distances[:, :n_benign - 2 - n_attackers], dim=1)\n","    min_score = torch.min(scores)\n","    term_1 = min_score / ((n_benign - n_attackers - 1) * torch.sqrt(torch.Tensor([d]))[0])\n","    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n","\n","    return (term_1 + max_wre_dist)\n","\n","def get_malicious_updates_fang(all_updates, model_re, deviation, n_attackers):\n","\n","    lamda = 100 # compute_lambda_fang(all_updates, model_re, n_attackers)\n","    threshold = torch.tensor(1e-5)\n","\n","    mal_updates = []\n","    while lamda > threshold:\n","        mal_update = (model_re - lamda * deviation)\n","\n","        mal_updates = torch.stack([mal_update] * n_attackers)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","\n","        _, selected_indices = multi_krum_optimized(mal_updates)\n","        # print(f'len {len(mal_updates)}, lamda {lamda}, indices {selected_indices}')\n","\n","        if torch.any(selected_indices < n_attackers):\n","            return mal_update\n","\n","        lamda *= 0.5\n","\n","    if not len(mal_updates):\n","        print(lamda, threshold)\n","        mal_update = (model_re - lamda * deviation)\n","    return mal_update\n","\n","def lie_attack(user_grads, n_attackers, z):\n","\n","    # Stack the gradients for the attackers\n","    all_updates = user_grads[:n_attackers]\n","\n","    # Calculate mean and standard deviation of the attacker's updates\n","    avg = torch.mean(all_updates, dim=0)\n","    std = torch.std(all_updates, dim=0)\n","\n","    # Generate malicious updates\n","    mal_update = avg + z * std\n","\n","    mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","    return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n"]},{"cell_type":"markdown","metadata":{"id":"_pUsLI-nkkTK"},"source":["Code for calculating Z value"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1743324275545,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"_gUO5IWDkp0n","outputId":"d48d1197-bb5e-443c-8661-84acef54ff0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7\n"]}],"source":["z_values={(50,3):0.69847, (50,5):0.7054, (50,8):0.71904, (50,10):0.72575, (50,12):0.73891, (100,20):0.72907, (40, 8): 0.72575, (100,5):0.69497, (100,10):0.7054, (100,15):0.71566, (100,25):0.74215, (100, 30):0.75804}\n","# z value calculation code to execute lie attack\n","import math\n","# Update the value of m to 10\n","n=100\n","m = 30\n","\n","# Recalculate s and z\n","s = math.floor(n / 2 + 1) - m\n","z = (n - m - s) / (n - m)\n","print(z)"]},{"cell_type":"markdown","metadata":{"id":"AfA9uC4lkvAv"},"source":["Federated Learning Training"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1743324275577,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"zXWWAdggktr4"},"outputs":[],"source":["\n","\n","\n","def train_local_model(client_id, client_indices, global_model, train_data, batch_size, criterion, device, optimizer):\n","    sampled_indices = random.sample(client_indices, min(batch_size, len(client_indices)))\n","    sampled_data = Subset(train_data, sampled_indices)\n","    # print(f\"client_id: {client_id}, sampled_indices: {len(sampled_indices)}, sampled_data: {len(sampled_data)}\")\n","    sampled_loader = DataLoader(sampled_data, batch_size=len(sampled_indices), shuffle=False, num_workers=0) # Set batch_size to the length of sampled_data\n","\n","    # Move the model to the assigned GPU device\n","    local_model = deepcopy(global_model).to(device)\n","    if optimizer == 'SGD':\n","        local_optimizer = optim.SGD(local_model.parameters(), lr=0.5, momentum=0.9)\n","    else:\n","        local_optimizer = torch.optim.Adam(local_model.parameters(), lr=0.001)\n","\n","\n","    for inputs, targets in sampled_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        # print(len(inputs), len(targets))\n","        local_optimizer.zero_grad()\n","        outputs = local_model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n","        local_optimizer.step()\n","\n","    # Collect model parameters for aggregation\n","    # local_params = torch.cat([param.data.view(-1).cpu() for param in local_model.parameters()])\n","    local_params = torch.cat([param.data.view(-1) for param in local_model.parameters()])\n","\n","\n","    # Cleanup\n","    del local_model, sampled_data, sampled_loader\n","    torch.cuda.empty_cache()\n","\n","    return client_id, local_params\n","\n","\n","def federated_learning(num_clients, aggregation, n_attackers, attack_type, dataset, n_round, batch_size, optim, client_data_size, collab):\n","    \"\"\"Main federated learning loop.\"\"\"\n","    global_model, train_data, testloader = load_model(dataset)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    clients_data_indices = []\n","    total_data_size = len(train_data)\n","    cross_device = client_data_size > 0\n","    if cross_device:\n","        total_data_size = len(train_data)\n","        all_indices = list(range(total_data_size))\n","\n","        for i in range(num_clients):\n","            # Each client gets 'client_data_size' random samples from all_indices\n","            # This does NOT remove those samples from all_indices,\n","            # so clients can have overlapping subsets.\n","            subset = random.sample(all_indices, client_data_size)\n","            clients_data_indices.append(subset)\n","    else:\n","        # Step 1: Split the dataset among clients\n","        client_data_size = total_data_size // num_clients\n","        print(\"client_data_size\", client_data_size)\n","        indices = list(range(total_data_size))\n","        random.shuffle(indices)\n","        clients_data_indices = [indices[i * client_data_size:(i + 1) * client_data_size] for i in range(num_clients)]\n","        attackers_in_this_round = n_attackers\n","\n","    global_models, global_model_data = [], []\n","\n","    with ThreadPoolExecutor(max_workers=THREAD_NUMBER) as executor:  # Adjust max_workers based on your system capabilities\n","        for epoch in range(n_round):\n","            global_model.train()\n","            local_models_data_diff = []\n","\n","            # Delete the oldest item if size is greater then 25\n","            if len(global_models) > 4:\n","                del global_models[0]\n","\n","            if cross_device:\n","                # Number of clients to train this round\n","                num_selected = max(1, int(0.01 * num_clients))\n","                selected_client_ids = random.sample(range(num_clients), num_selected)\n","\n","                # 1) Sort client IDs\n","                selected_client_ids.sort()\n","\n","                # 2) Count how many selected IDs are < n_attackers\n","                attackers_in_this_round = sum(1 for cid in selected_client_ids if cid < n_attackers)\n","                print(f\"Selected clients (sorted): {selected_client_ids}\")\n","                print(f\"Number of attackers in this round: {attackers_in_this_round}\")\n","\n","                futures = []\n","                for client_id in selected_client_ids:\n","                    client_indices = clients_data_indices[client_id]\n","                    futures.append(\n","                        executor.submit(\n","                            train_local_model,\n","                            client_id,\n","                            client_indices,\n","                            global_model,\n","                            train_data,\n","                            batch_size,\n","                            criterion,\n","                            devices[client_id % len(devices)],\n","                            optim\n","                        )\n","                    )\n","            else:\n","                futures = [\n","                    executor.submit(\n","                        train_local_model,\n","                        client_id,\n","                        client_indices,\n","                        global_model,\n","                        train_data,\n","                        batch_size,\n","                        criterion,\n","                        devices[client_id % len(devices)],  # Alternate between 'cuda:0' and 'cuda:1'\n","                        optim\n","                    )\n","                    for client_id, client_indices in enumerate(clients_data_indices)\n","                ]\n","\n","            # Collect results\n","            for future in as_completed(futures):\n","                client_id, local_params = future.result()\n","                local_models_data_diff.append(local_params)\n","\n","            for i in range(torch.cuda.device_count()):\n","                torch.cuda.set_device(i)\n","                torch.cuda.empty_cache()\n","            if num_gpus > 0:\n","                torch.cuda.set_device(device)\n","            print(f'For round {epoch}, training done')\n","            # time.sleep(30)\n","            local_models_data = torch.stack(local_models_data_diff).to(device)\n","            del local_models_data_diff\n","            gc.collect()\n","\n","            if attack_type.startswith('XFED'):\n","                for local_machine in range(attackers_in_this_round):\n","                    if attack_type == 'XFED_unit_vec':\n","                        deviation = local_models_data[local_machine] / torch.norm(local_models_data[local_machine])\n","                    elif attack_type == 'XFED_sign':\n","                        sgn_vec = torch.sign(local_models_data[local_machine])\n","                        deviation = sgn_vec / torch.norm(sgn_vec)\n","                    else:\n","                        raise ValueError(\"Invalid attack type\")\n","\n","                    if len(global_models) > 1:\n","\n","                        # version 1\n","                        # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu\", torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models))\n","                        # mu = torch.max(torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models, MU_MULTIPLIER))\n","\n","                        # version 2\n","                        # mu = torch.norm(local_models_data[local_machine] - global_model_data)\n","                        # print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}\")\n","\n","                        # version 3\n","                        # global_models.append(local_models_data[local_machine])\n","                        global_distance, pairwise_distance = torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models, MU_MULTIPLIER=MU_MULTIPLIER)\n","                        # global_models.pop()\n","                        # mu = torch.max(global_distance, pairwise_distance)\n","                        # mu = torch.min(global_distance, pairwise_distance)\n","                        # mu = global_distance * 0.5\n","                        # mu = (pairwise_distance + global_distance) / torch.tensor(2)\n","                        mu = pairwise_distance\n","                        print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}, global_distance: {global_distance}, pairwise_distance: {pairwise_distance}\")\n","\n","                    else:\n","                        mu = torch.tensor(1.0)\n","\n","                    delta = mu * deviation\n","\n","                    # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu: {mu}\\ndeviation: {deviation}\\ndelta: {delta}\\nlocal model: {local_models_data[local_machine]}\\nglobal model: {global_model_data}\")\n","                    if epoch == 0:\n","                        print(f'local_models_data[local_machine] {local_models_data[local_machine].shape} delta {delta.shape}')\n","                        local_models_data[local_machine] -= delta\n","                    else:\n","                        # del local_models_data[local_machine]\n","                        local_models_data[local_machine] = global_model_data - delta\n","                    # print(f\"after update model after attack: {local_models_data[local_machine]}\\n\")\n","                    del deviation, delta, mu\n","\n","\n","            elif attack_type.startswith('VIRAT') and attackers_in_this_round > 0:\n","                local_models_data = virat_min_max(local_models_data, attackers_in_this_round, attack_type, epoch=epoch)\n","\n","            elif attack_type.startswith('LIE') and attackers_in_this_round > 0:\n","                local_models_data = lie_attack(local_models_data, attackers_in_this_round, z_values[(num_clients, n_attackers)])\n","\n","            elif attack_type =='FANG_TR_MEAN' and attackers_in_this_round > 0:\n","                local_models_data = fang_attack_trmean_partial(local_models_data, attackers_in_this_round)\n","\n","            elif attack_type =='FANG_KRUM' and attackers_in_this_round > 0:\n","                attacker_grads = local_models_data[:n_attackers]\n","                agg_grads = torch.mean(attacker_grads, 0)\n","                deviation = torch.sign(agg_grads)\n","                mal_update = get_malicious_updates_fang(attacker_grads, agg_grads, deviation, n_attackers)\n","                mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","                return torch.cat((mal_updates, local_models_data[n_attackers:]), dim=0)\n","\n","            elif attack_type.startswith('C_XFED'):\n","                local_models_data = xfed_c(local_models_data, attackers_in_this_round, attack_type, len(global_models), global_model_data, global_models, 0)\n","\n","            elif attack_type.startswith('Hybrid_XFED'):\n","                individual_attacker = attackers_in_this_round - collab\n","                for local_machine in range(individual_attacker):\n","                    if attack_type == 'Hybrid_XFED_unit_vec':\n","                        deviation = local_models_data[local_machine] / torch.norm(local_models_data[local_machine])\n","                    elif attack_type == 'Hybrid_XFED_sign':\n","                        sgn_vec = torch.sign(local_models_data[local_machine])\n","                        deviation = sgn_vec / torch.norm(sgn_vec)\n","                    else:\n","                        raise ValueError(\"Invalid attack type\")\n","\n","                    if len(global_models) > 1:\n","                        global_distance, pairwise_distance = torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models, MU_MULTIPLIER=MU_MULTIPLIER)\n","                        mu = pairwise_distance\n","                        # print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}, global_distance: {global_distance}, pairwise_distance: {pairwise_distance}\")\n","\n","                    else:\n","                        mu = torch.tensor(1.0)\n","\n","                    delta = mu * deviation\n","\n","                    # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu: {mu}\\ndeviation: {deviation}\\ndelta: {delta}\\nlocal model: {local_models_data[local_machine]}\\nglobal model: {global_model_data}\")\n","                    if epoch == 0:\n","                        # print(f'local_models_data[local_machine] {local_models_data[local_machine].shape} delta {delta.shape}')\n","                        local_models_data[local_machine] -= delta\n","                    else:\n","                        # del local_models_data[local_machine]\n","                        local_models_data[local_machine] = global_model_data - delta\n","                    # print(f\"after update model after attack: {local_models_data[local_machine]}\\n\")\n","                    del deviation, delta, mu\n","\n","                local_models_data = xfed_c(local_models_data, attackers_in_this_round, attack_type, len(global_models), global_model_data, global_models, collab)\n","\n","            else:\n","                raise ValueError(\"Invalid attack type\")\n","\n","            # print(f'For round {epoch}, attack done, Lenght of local_models_data:', len(local_models_data))\n","\n","            # Aggregate model updates\n","            if aggregation == 'MEAN':\n","                global_model_data = torch.mean(local_models_data, dim=0)\n","            elif aggregation == 'MEDIAN':\n","                global_model_data = torch.median(local_models_data, dim=0)[0]\n","            elif aggregation == 'KRUM':\n","                # Check if local_models_data is already a tensor\n","                if isinstance(local_models_data, list):\n","                    global_model_data, _ = multi_krum_optimized(local_updates=local_models_data)\n","                else:\n","                    global_model_data, _ = multi_krum_optimized(local_updates=local_models_data)\n","            elif aggregation == 'TR-MEAN':\n","                global_model_data = tr_mean(local_models_data)\n","            elif aggregation == 'CC':\n","                global_model_data = Clippedclustering(local_models_data)\n","            elif aggregation == 'SignGuard':\n","                global_model_data = SignGuard(local_models_data)\n","            else:\n","                raise ValueError(\"Invalid aggregation method\")\n","\n","            if torch.isnan(global_model_data).any():\n","                raise ValueError(\"NaN detected in model aggregation\")\n","\n","            # Update global model\n","            start_idx = 0\n","            with torch.no_grad():\n","                for param in global_model.parameters():\n","                    param_size = param.numel()\n","                    param.copy_(global_model_data[start_idx:start_idx + param_size].view(param.shape))\n","                    start_idx += param_size\n","\n","            # global_models.append(global_model_data.cpu())\n","            global_models.append(global_model_data)\n","\n","            print(f'For round {epoch}, aggregation done')\n","            last_ten_percent = int(n_round * 0.89)\n","            if epoch >= last_ten_percent or epoch%20 == 0:\n","                # Evaluate global model\n","                global_model.eval()\n","                global_model = global_model.to(device)\n","                correct = 0\n","                total = 0\n","                with torch.no_grad():\n","                    for images, labels in testloader:\n","                        images, labels = images.to(device), labels.to(device)\n","                        outputs = global_model(images)\n","                        _, predicted = torch.max(outputs.data, 1)\n","                        total += labels.size(0)\n","                        correct += (predicted == labels).sum().item()\n","\n","                accuracy = 100 * correct / total\n","                print(f'Time {datetime.now()}: Accuracy on round {epoch}, total {num_clients}, attackers {n_attackers}, attack_type {attack_type}, aggregation {aggregation} is: {accuracy:.2f} %')\n","\n","                # File path to save the accuracy log\n","                file_path = os.path.join(data_root, f'accuracy_{dataset}_{aggregation}_{attack_type}_{n_attackers}_mu{MU_MULTIPLIER}_cd_{cross_device}_collab{collab}_log.txt')\n","\n","                # Append accuracy to the file in the data_root location\n","                with open(file_path, 'a') as f:\n","                    f.write(f'Time {datetime.now()}: Accuracy on round {epoch}, dataset {dataset}, total {num_clients}, attackers {n_attackers}, round attackers {attackers_in_this_round}, attack_type {attack_type}, aggregation {aggregation} is: {accuracy:.2f} %\\n')\n","\n","            # global_model = global_model.to('cpu')\n","            del local_models_data\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","\n","    # Final cleanup after training\n","    del global_model, train_data, testloader, global_models, criterion\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NG0kwZK9lM9X"},"source":["Example Execution"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"jnRgpMBTlSqv","outputId":"eea81597-3719-4308-d1c4-79ea30e20f85","executionInfo":{"status":"error","timestamp":1743324319156,"user_tz":-360,"elapsed":43577,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected clients (sorted): [4, 147, 173, 176, 294, 357, 395, 620, 663, 695, 705, 852, 1011, 1089, 1216, 1472, 1498, 1542, 1825, 1837, 1853, 1974, 2056, 2097, 2142, 2282, 2285, 2346, 2464, 2498, 2540, 2814, 3142, 3194, 3303, 3445, 3502, 3573, 3576, 3631, 3829, 3935, 3967, 4071, 4135, 4317, 4527, 4605, 4636, 4637, 4713, 4732, 4885, 4888, 4915, 5264, 5328, 5533, 5724, 5823, 5859, 5940, 5957, 6071, 6196, 6419, 6446, 6543, 6598, 6667, 7096, 7183, 7255, 7302, 7309, 7312, 7332, 7346, 7429, 7493, 7504, 7523, 7564, 7611, 7736, 7799, 7975, 8109, 8113, 8165, 8192, 8373, 8408, 8417, 8693, 8997, 9321, 9344, 9568, 9574, 9604, 9612, 9740, 9920, 10148, 10211, 10319, 10642, 10925, 10984, 11151, 11190, 11297, 11350, 11713, 11739, 11808, 11990, 12008, 12306, 12314, 12320, 13098, 13115, 13464, 13465, 13502, 13588, 13663, 13738, 13991, 14081, 14223, 14314, 14416, 14435, 14476, 14635, 14771, 14785, 14821, 14935, 15159, 15193, 15348, 15364, 15419, 15544, 15665, 16130, 16343, 16366, 16412, 16488, 16547, 16838, 16927, 17024, 17100, 17174, 17217, 17240, 17302, 17809, 17920, 18177, 18222, 18355, 18398, 18435, 18448, 18548, 18559, 18975, 19033, 19036, 19051, 19127, 19136, 19158, 19173, 19312, 19393, 19498, 19603, 19729, 19940, 19973, 20113, 20123, 20175, 20370, 20465, 21045, 21214, 21239, 21303, 21351, 21359, 21474, 21706, 21783, 22236, 22253, 22261, 22295, 22384, 22528, 22637, 22673, 22730, 22842, 22891, 22930, 22989, 23050, 23252, 23314, 23329, 23406, 23585, 23687, 23716, 23769, 23897, 23920, 23982, 24254, 24308, 24356, 24450, 24488, 24523, 24580, 24675, 24964, 25003, 25052, 25078, 25091, 25107, 25115, 25202, 25282, 25301, 25812, 25814, 25826, 25856, 26029, 26044, 26101, 26186, 26300, 26379, 26435, 26503, 26565, 26645, 26706, 26758, 26914, 26916, 26924, 27029, 27038, 27187, 27404, 27474, 27558, 27595, 27619, 27624, 27691, 27890, 27898, 28112, 28149, 28211, 28304, 28493, 28607, 28651, 28667, 28670, 28727, 29085, 29381, 29467, 29487, 29534, 29546, 29939, 30067, 30274, 30366, 30511, 30566, 30587, 30625, 30637, 30725, 30735, 30850, 30945, 31013, 31041, 31307, 31716, 31725, 31743, 31756, 31799, 31979, 32043, 32125, 32252, 32279, 32320, 32329, 32398, 32749, 32754, 32771, 32946, 33318, 33628, 33643, 33645, 33735, 33760, 33925, 33967, 34044, 34309, 34342, 34551, 34892, 34903, 34964, 34973, 34990, 35098, 35112, 35282, 35294, 35389, 35555, 35733, 35912, 35995, 36040, 36097, 36128, 36406, 36627, 36726, 36825, 36950, 36973, 37132, 37164, 37167, 37225, 37268, 37318, 37324, 37394, 37428, 37432, 37475, 37543, 37548, 37626, 37701, 37716, 37800, 37920, 37950, 38028, 38073, 38197, 38281, 38313, 38592, 38700, 38732, 38787, 38941, 39030, 39192, 39227, 39312, 39319, 39511, 39601, 39722, 39788, 39942, 39987, 40085, 40221, 40427, 40519, 40587, 40801, 40883, 40994, 41147, 41170, 41223, 41243, 41385, 41514, 41607, 41724, 41778, 41926, 42072, 42248, 42371, 42434, 42441, 42449, 42823, 42853, 43064, 43075, 43092, 43181, 43214, 43260, 43546, 43690, 43696, 43727, 43783, 44322, 44413, 44453, 44695, 44705, 44751, 44757, 44967, 45060, 45067, 45564, 45684, 45759, 45761, 45842, 45912, 45915, 46017, 46269, 46315, 46329, 46379, 46747, 46770, 46798, 46804, 47012, 47150, 47156, 47224, 47302, 47412, 47414, 47470, 47498, 47599, 47611, 47680, 47687, 47814, 47903, 47917, 47991, 48322, 48392, 48415, 48424, 48466, 48511, 48544, 48581, 48667, 48861, 48894, 48949, 49094, 49119, 49285, 49440, 49651, 49768, 49861, 49991]\n","Number of attackers in this round: 104\n","For round 0, training done\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 27.24 GiB. GPU 0 has a total capacity of 39.56 GiB of which 10.21 GiB is free. Process 3180 has 29.34 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 121.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-34e5caa501f2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mattackers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0;31m# torch.cuda.memory._record_memory_history()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     \u001b[0mfederated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attackers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattackers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EMNIST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattack_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_data_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0;31m# federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=300, dataset='EMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0;31m# federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=250, dataset='FashionMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-f079181afcd8>\u001b[0m in \u001b[0;36mfederated_learning\u001b[0;34m(num_clients, aggregation, n_attackers, attack_type, dataset, n_round, batch_size, optim, client_data_size, collab)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0magg_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattacker_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mdeviation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mmal_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_malicious_updates_fang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattacker_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeviation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attackers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mmal_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmal_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_attackers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmal_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_models_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_attackers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-bc9a1f6c377f>\u001b[0m in \u001b[0;36mget_malicious_updates_fang\u001b[0;34m(all_updates, model_re, deviation, n_attackers)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mmal_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmal_update\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_attackers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mmal_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mmal_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmal_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 27.24 GiB. GPU 0 has a total capacity of 39.56 GiB of which 10.21 GiB is free. Process 3180 has 29.34 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 121.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}],"source":["# Example execution\n","for MU_MULTIPLIER in [3]:\n","    for cb in [0]:\n","        for attack_type in ['FANG_KRUM']: # 'Hybrid_XFED_unit_vec','Hybrid_XFED_sign'  'XFED_unit_vec', 'XFED_sign', 'VIRAT_unit_vec', 'C_XFED_sign', 'LIE', 'FANG_TR_MEAN'\n","            for agg in ['KRUM']: # 'MEAN', 'MEDIAN', 'KRUM', 'TR-MEAN', 'SignGuard', 'CC' 'MEAN', 'MEDIAN', 'KRUM', 'TR-MEAN', 'SignGuard'\n","                for attackers in [10000]:\n","                    # torch.cuda.memory._record_memory_history()\n","                    federated_learning(num_clients=50000, n_attackers=attackers, aggregation=agg, n_round=500, dataset='EMNIST', attack_type=attack_type, batch_size=100, optim=\"SGD\", client_data_size=100, collab=cb)\n","                    # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=300, dataset='EMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\n","                    # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=250, dataset='FashionMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\n","                    # federated_learning(num_clients=50, n_attackers=attackers, aggregation=agg, n_round=255, dataset='CIFAR10', attack_type=attack_type, batch_size=250)\n","                    # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=1000, dataset='SVHN', attack_type=attack_type, batch_size=64, optim=\"SGD\")\n","                    # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=275, dataset='MNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\n","                    # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=500, dataset='PURCHASE', attack_type=attack_type, batch_size=128, optim=\"SGD\", cross_device=False, collab=cb)\n","                    # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=300, dataset='CIFAR100', attack_type=attack_type, batch_size=250, optim=\"Adam\")\n","                    # federated_learning(num_clients=200, n_attackers=attackers, aggregation=agg, n_round=50, dataset='SYMBIPREDICT', attack_type=attack_type, batch_size=10, optim=\"SGD\", collab=0)\n","                    # federated_learning(num_clients=200, n_attackers=attackers, aggregation=agg, n_round=50, dataset='SYMBIPREDICT', attack_type=attack_type, batch_size=10, optim=\"Adam\", cross_device=False, collab=0)\n","                    # torch.cuda.memory._dump_snapshot(\"cifar10.pickle\")\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1X3t5mq5GeYar0SJTQdAWqgIr9zVQTsLp","timestamp":1737090410437},{"file_id":"1zDVH8FKTgN-bePGXWP0Hy_EIVOkPG2KF","timestamp":1730633766005}],"authorship_tag":"ABX9TyMhXhw6l25oqXp2dvkAGUf3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}