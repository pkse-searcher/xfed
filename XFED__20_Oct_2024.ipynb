{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyM2jfsozH0nx+xirbOBYe74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkse-searcher/xfed/blob/main/XFED__20_Oct_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaOkiimBIHdE",
        "outputId": "9e01e199-5138-4c9e-b6f8-26187e0d0ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores available: 12\n",
            "THREAD_NUMBER set to: 12\n",
            "Number of GPUs available: 1\n",
            "Using GPU: cuda:0\n",
            "Devices: ['cuda:0']\n",
            "Wed Oct 23 19:43:26 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   47C    P8              17W /  72W |      4MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "\n",
            "Architecture:                         x86_64\n",
            "CPU op-mode(s):                       32-bit, 64-bit\n",
            "Address sizes:                        46 bits physical, 48 bits virtual\n",
            "Byte Order:                           Little Endian\n",
            "CPU(s):                               12\n",
            "On-line CPU(s) list:                  0-11\n",
            "Vendor ID:                            GenuineIntel\n",
            "Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "CPU family:                           6\n",
            "Model:                                85\n",
            "Thread(s) per core:                   2\n",
            "Core(s) per socket:                   6\n",
            "Socket(s):                            1\n",
            "Stepping:                             7\n",
            "BogoMIPS:                             4400.42\n",
            "Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n",
            "Hypervisor vendor:                    KVM\n",
            "Virtualization type:                  full\n",
            "L1d cache:                            192 KiB (6 instances)\n",
            "L1i cache:                            192 KiB (6 instances)\n",
            "L2 cache:                             6 MiB (6 instances)\n",
            "L3 cache:                             38.5 MiB (1 instance)\n",
            "NUMA node(s):                         1\n",
            "NUMA node0 CPU(s):                    0-11\n",
            "Vulnerability Gather data sampling:   Not affected\n",
            "Vulnerability Itlb multihit:          Not affected\n",
            "Vulnerability L1tf:                   Not affected\n",
            "Vulnerability Mds:                    Not affected\n",
            "Vulnerability Meltdown:               Not affected\n",
            "Vulnerability Mmio stale data:        Vulnerable\n",
            "Vulnerability Reg file data sampling: Not affected\n",
            "Vulnerability Retbleed:               Vulnerable\n",
            "Vulnerability Spec rstack overflow:   Not affected\n",
            "Vulnerability Spec store bypass:      Vulnerable\n",
            "Vulnerability Spectre v1:             Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers\n",
            "Vulnerability Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIBRS: Vulnerable; BHI: Vulnerable (Syscall hardening enabled)\n",
            "Vulnerability Srbds:                  Not affected\n",
            "Vulnerability Tsx async abort:        Vulnerable\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"  # or \":16:8\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Function to attempt to import a module, and install it if not present\n",
        "def try_import(module_name, package_name=None):\n",
        "    try:\n",
        "        module = __import__(module_name)\n",
        "        return module\n",
        "    except ImportError:\n",
        "        if package_name is None:\n",
        "            package_name = module_name\n",
        "        print(f\"Installing {package_name}...\")\n",
        "        install(package_name)\n",
        "        module = __import__(module_name)\n",
        "        return module\n",
        "\n",
        "# Standard library imports (no need to install)\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "import gc\n",
        "import random\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from typing import Iterable, Union, Optional\n",
        "\n",
        "# Third-party imports\n",
        "torch = try_import('torch')\n",
        "torchvision = try_import('torchvision')\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "np = try_import('numpy')\n",
        "# Import torch.nn as nn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import torchvision.models\n",
        "from torch.nn.functional import tanh, softmax\n",
        "\n",
        "# sklearn imports\n",
        "sklearn = try_import('sklearn')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.pairwise import cosine_distances,euclidean_distances\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "# Other third-party imports\n",
        "plt = try_import('matplotlib.pyplot', 'matplotlib')\n",
        "pd = try_import('pandas')\n",
        "\n",
        "# Install and import CLIP\n",
        "try:\n",
        "    import clip\n",
        "except ImportError:\n",
        "    print(\"Installing CLIP...\")\n",
        "    install('git+https://github.com/openai/CLIP.git')\n",
        "    import clip\n",
        "\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "# Get the number of available CPU cores\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "\n",
        "# Set THREAD_NUMBER to the number of CPU cores\n",
        "THREAD_NUMBER = num_cores\n",
        "\n",
        "print(f\"Number of CPU cores available: {num_cores}\")\n",
        "print(f\"THREAD_NUMBER set to: {THREAD_NUMBER}\")\n",
        "\n",
        "\n",
        "# torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "# Get the number of available GPUs\n",
        "num_gpus = torch.cuda.device_count()\n",
        "print(f\"Number of GPUs available: {num_gpus}\")\n",
        "\n",
        "# If GPUs are available, choose the desired device index (within the available range)\n",
        "# Otherwise, default to CPU\n",
        "if num_gpus > 0:\n",
        "    desired_gpu_index = 3  # This is the index you originally wanted\n",
        "    device_index = min(desired_gpu_index, num_gpus - 1)  # Clamp to available range\n",
        "    device = torch.device(f\"cuda:{device_index}\")\n",
        "    print(f\"Using GPU: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPUs available, using CPU.\")\n",
        "\n",
        "torch.cuda.set_device(device)  # Set the device\n",
        "\n",
        "\n",
        "#set devices to multiple GPUs\n",
        "unwanted_device_indices = []\n",
        "available_device_indices = list(range(num_gpus))\n",
        "devices = [f'cuda:{i}' for i in available_device_indices if i not in unwanted_device_indices]\n",
        "if not devices:\n",
        "    raise RuntimeError(\"Desired GPUs are not available.\")\n",
        "print(f\"Devices: {devices}\")\n",
        "\n",
        "\n",
        "# Check GPU information\n",
        "def check_gpu():\n",
        "    try:\n",
        "        gpu_info = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n",
        "        print(gpu_info)\n",
        "    except Exception as e:\n",
        "        print('Not connected to a GPU or nvidia-smi not found.')\n",
        "\n",
        "check_gpu()\n",
        "\n",
        "# Check CPU information\n",
        "def check_cpu():\n",
        "    try:\n",
        "        cpu_info = subprocess.check_output(['lscpu']).decode('utf-8')\n",
        "        print(cpu_info)\n",
        "    except Exception as e:\n",
        "        print('Could not retrieve CPU information.')\n",
        "\n",
        "check_cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to determine the data root directory"
      ],
      "metadata": {
        "id": "TPXgVfNmnhES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine the data root directory\n",
        "def get_data_root():\n",
        "    if 'COLAB_GPU' in os.environ:\n",
        "        # Mount Google Drive if needed\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        data_root = '/content/drive/MyDrive/PhD/XFED result/data/'\n",
        "    else:\n",
        "        data_root = './data/'\n",
        "    return data_root\n",
        "\n",
        "# Get the appropriate data root directory\n",
        "data_root = get_data_root()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QYFIElVnecH",
        "outputId": "3d6563ae-8347-4efd-9c36-2d5a34a962d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition for different datasets"
      ],
      "metadata": {
        "id": "TLIncX6sIy49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTAlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionMNISTAlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class FeatureNorm(nn.Module):\n",
        "    def __init__(self, feature_shape):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(1))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, feature_shape))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.einsum('ni, j->ni', x, self.gamma)\n",
        "        x = x + self.beta\n",
        "        return  x\n",
        "\n",
        "class purchase_fully_connected_IN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(purchase_fully_connected_IN, self).__init__()\n",
        "        self.fc1 = nn.Linear(600, 1024, bias=False)  # First layer: input size 600, output size 1024\n",
        "        self.fc2 = nn.Linear(1024, 100, bias=False)  # Second layer: input size 1024, output size 100\n",
        "        self.fc3 = nn.Linear(100, num_classes, bias=False)  # Output layer: input size 100, output size num_classes\n",
        "        self.norm = FeatureNorm(600)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        x = torch.tanh(self.fc1(x))  # Apply tanh activation after the first layer\n",
        "        x = torch.tanh(self.fc2(x))  # Apply tanh activation after the second layer\n",
        "        logits = self.fc3(x)         # Output layer, no activation\n",
        "        return logits\n",
        "\n",
        "class Purchase(torch.utils.data.Dataset):\n",
        "    def __init__(self, root =data_root + 'purchase/dataset_purchase',train=True, download=True, transform = None):\n",
        "        self.images = []\n",
        "        self.root = root\n",
        "        self.targets = []\n",
        "        self.train = train\n",
        "        self.download = download\n",
        "        self.transform = transform\n",
        "\n",
        "        x_train, x_test, y_train, y_test = self._train_test_split()\n",
        "\n",
        "        if self.train:\n",
        "            self._setup_dataset(x_train, y_train)\n",
        "        else:\n",
        "            self._setup_dataset(x_test, y_test)\n",
        "\n",
        "    def _train_test_split(self):\n",
        "        df = pd.read_csv(self.root)\n",
        "\n",
        "        img_names = df.iloc[:, 1:].to_numpy(dtype='f')\n",
        "        img_label = df.iloc[:, 0].to_numpy()-1\n",
        "        x_train,x_test, y_train, y_test = train_test_split(img_names, img_label, train_size=0.8,\n",
        "                                                            random_state=1)\n",
        "        return x_train, x_test, y_train, y_test\n",
        "\n",
        "    def _setup_dataset(self, x, y):\n",
        "            self.images = x\n",
        "            self.targets = y\n",
        "\n",
        "    def __len__(self): # Added the __len__ method\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        img = self.images[item]\n",
        "        label = self.targets[item]\n",
        "        return img, label\n",
        "\n",
        "class ThreeLayerDNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ThreeLayerDNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class FourLayerDNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FourLayerDNN, self).__init__()\n",
        "        # Flatten the input image\n",
        "        self.flatten = nn.Flatten()\n",
        "        # Define the fully connected layers\n",
        "        self.fc1 = nn.Linear(3 * 32 * 32, 1024)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(256, 10)  # Output layer for 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        x = self.relu3(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class InputNorm(nn.Module):\n",
        "    def __init__(self, num_channel, num_feature):\n",
        "        super().__init__()\n",
        "        self.num_channel = num_channel\n",
        "        self.gamma = nn.Parameter(torch.ones(num_channel))\n",
        "        self.beta = nn.Parameter(torch.zeros(num_channel, num_feature, num_feature))\n",
        "    def forward(self, x):\n",
        "        if self.num_channel == 1:\n",
        "            x = self.gamma*x\n",
        "            x = x + self.beta\n",
        "            return  x\n",
        "        if self.num_channel == 3:\n",
        "            return torch.einsum('...ijk, i->...ijk', x, self.gamma) + self.beta\n",
        "\n",
        "class mnist_fully_connected_IN(nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "        super(mnist_fully_connected_IN, self).__init__()\n",
        "        self.hidden1 = 600\n",
        "        self.hidden2 = 100\n",
        "        self.fc1 = nn.Linear(28 * 28, self.hidden1, bias=False)\n",
        "        self.fc2 = nn.Linear(self.hidden1, self.hidden2, bias=False)\n",
        "        self.fc3 = nn.Linear(self.hidden2, num_classes, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "        self.norm = InputNorm(1, 28)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.norm(x)\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        logits = self.fc3(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "7zE8s1djJkuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Model for different datasets (FashionMNIST, CIFAR-10, PURCHASE, MNIST, EMNIST, CIFAR-100)"
      ],
      "metadata": {
        "id": "2o1uD2lVKAqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_model(dataset: str):\n",
        "    \"\"\"Load and prepare the model and datasets based on the given dataset name.\"\"\"\n",
        "    if dataset == 'FashionMNIST':\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((227, 227)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "        train_data = torchvision.datasets.FashionMNIST(root=data_root, train=True, download=True, transform=transform)\n",
        "        test_data = torchvision.datasets.FashionMNIST(root=data_root, train=False, download=True, transform=transform)\n",
        "        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n",
        "        classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
        "        model = FashionMNISTAlexNet().to(device)\n",
        "\n",
        "    elif dataset == 'CIFAR10':\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        train_data = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
        "        test_data = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform)\n",
        "        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n",
        "        classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
        "\n",
        "        model = models.alexnet(pretrained=True)\n",
        "        model.classifier[1] = nn.Linear(9216, 4096)\n",
        "        model.classifier[4] = nn.Linear(4096, 1024)\n",
        "        model.classifier[6] = nn.Linear(1024, 10)\n",
        "        model = model.to(device)\n",
        "\n",
        "    elif dataset == 'PURCHASE':\n",
        "        train_data = Purchase(train=True, download=True)\n",
        "        test_data = Purchase(train=False, download=True)\n",
        "        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n",
        "\n",
        "        model = purchase_fully_connected_IN(100).to(device)\n",
        "\n",
        "    elif dataset == 'SVHN':\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(32),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "        ])\n",
        "        train_data = torchvision.datasets.SVHN(root=data_root, split='train', download=True, transform=transform)\n",
        "        test_data = torchvision.datasets.SVHN(root=data_root, split='test', download=True, transform=transform)\n",
        "        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n",
        "\n",
        "        # Use the 4-layer CNN for SVHN\n",
        "        model = models.googlenet(weights='DEFAULT').to(device)\n",
        "\n",
        "    elif dataset == 'EMNIST':\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "        train_data = torchvision.datasets.EMNIST(root='./data', split='byclass', train=True, download=True, transform=transform)\n",
        "        test_data = torchvision.datasets.EMNIST(root='./data', split='byclass', train=False, download=True, transform=transform)\n",
        "        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n",
        "\n",
        "        model = ThreeLayerDNN(input_size=28 * 28, hidden_size=512, output_size=62).to(device)\n",
        "\n",
        "    elif dataset == 'MNIST':\n",
        "        # Define transformation for MNIST\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),        # Convert image to PyTorch tensor\n",
        "            transforms.Normalize((0.5,), (0.5,))  # Normalize grayscale values to [-1, 1]\n",
        "        ])\n",
        "\n",
        "        # Load the MNIST dataset (\"ByClass\" split as an example)\n",
        "        train_data = torchvision.datasets.MNIST(root=data_root, train=True, download=True, transform=transform)\n",
        "        test_data = torchvision.datasets.MNIST(root=data_root, train=False, download=True, transform=transform)\n",
        "        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n",
        "\n",
        "        # Load the pre-trained VGG16 model\n",
        "        model = mnist_fully_connected_IN(10).to(device)\n",
        "\n",
        "    elif dataset == 'CIFAR100':\n",
        "        # Define the transformation for the dataset (matching CLIP preprocessing)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),  # CLIP expects 224x224 input\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),\n",
        "        ])\n",
        "\n",
        "        # Load the CIFAR100 dataset\n",
        "        train_data = torchvision.datasets.CIFAR100(root=data_root, train=True, download=True, transform=transform)\n",
        "        test_data = torchvision.datasets.CIFAR100(root=data_root, train=False, download=True, transform=transform)\n",
        "\n",
        "        # Create DataLoader for train and test sets\n",
        "        trainloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=8)\n",
        "        testloader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=8)\n",
        "\n",
        "        # Define the class labels for CIFAR100\n",
        "        classes = [str(i) for i in range(100)]  # CIFAR100 has 100 classes\n",
        "\n",
        "        # Load the CLIP model from OpenAI\n",
        "        model_clip, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "        # Convert CLIP model to float32 to match other layers and data\n",
        "        model_clip = model_clip.float()\n",
        "\n",
        "        # Freeze the CLIP model's parameters (we're only training the classifier)\n",
        "        for param in model_clip.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Define a simple 1-layer DNN model on top of CLIP features\n",
        "        class CLIP_DNN(nn.Module):\n",
        "            def __init__(self, clip_model, num_classes=100):\n",
        "                super(CLIP_DNN, self).__init__()\n",
        "                self.clip_model = clip_model\n",
        "                self.fc = nn.Linear(512, num_classes)  # CLIP ViT-B/32 gives 512-dimensional features\n",
        "\n",
        "            def forward(self, images):\n",
        "                with torch.no_grad():\n",
        "                    # Extract image features using CLIP's image encoder (cast to float32)\n",
        "                    image_features = self.clip_model.encode_image(images).float()\n",
        "                return self.fc(image_features)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = CLIP_DNN(model_clip, num_classes=100)\n",
        "\n",
        "        # Move the model to the device (GPU or CPU)\n",
        "        model = model.to(device)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Dataset not supported\")\n",
        "\n",
        "    return model, train_data, testloader\n"
      ],
      "metadata": {
        "id": "tGc5WAzrKNDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation Rules (\n",
        "FedAvg / Mean,\n",
        "Median,\n",
        "Trimmed Mean,\n",
        "Multi-Krum,\n",
        "Clipped Clustering,\n",
        "SignGuard)"
      ],
      "metadata": {
        "id": "htLtRlfGK1ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tr_mean(all_updates: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Apply Trimmed Mean aggregation with 20% assumed attackers.\"\"\"\n",
        "    sorted_updates = torch.sort(all_updates, dim=0)[0]\n",
        "    num_clients = len(all_updates)\n",
        "    n_attackers = round(0.2 * num_clients)\n",
        "    if n_attackers != 0 and 2 * n_attackers < num_clients:\n",
        "        ret = torch.mean(sorted_updates[n_attackers:-n_attackers], dim=0)\n",
        "        # print(\"sorted_updates\", sorted_updates)\n",
        "        # print(\"num_clients\", num_clients)\n",
        "        # print(\"n_attackers\", n_attackers)\n",
        "        # print(\"ret\", ret)\n",
        "        return ret\n",
        "    return torch.mean(sorted_updates, dim=0)\n",
        "\n",
        "def multi_krum_optimized(local_updates: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Implements a memory-optimized version of the Multi-Krum aggregation rule with explicit deletion of local variables.\n",
        "    Parameters:\n",
        "    - local_updates: A tensor of shape (num_clients, num_params) containing the flattened model updates from each client.\n",
        "    Returns:\n",
        "    - The aggregated model update as a tensor of shape (num_params,).\n",
        "    \"\"\"\n",
        "    num_clients = local_updates.size(0)\n",
        "    byzantine_client_num = int(num_clients * 0.2)  # Assuming 20% are byzantine clients\n",
        "    krum_limit = num_clients - byzantine_client_num - 2\n",
        "\n",
        "    # Instead of computing a full pairwise distance matrix, compute distances incrementally\n",
        "    scores = torch.zeros(num_clients)\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        # Compute the squared L2 distances between client `i` and all other clients\n",
        "        distances = torch.sum((local_updates - local_updates[i]) ** 2, dim=1)\n",
        "\n",
        "        # Sort distances and ignore the first distance (which is 0, i.e., distance to itself)\n",
        "        sorted_distances, _ = torch.sort(distances)\n",
        "\n",
        "        # Sum the smallest `krum_limit` distances (ignore the first one)\n",
        "        scores[i] = torch.sum(sorted_distances[1:krum_limit + 1])\n",
        "\n",
        "        # Explicitly delete large tensors to free memory\n",
        "        del distances, sorted_distances\n",
        "\n",
        "    # Select the indices of the `krum_limit` clients with the lowest scores\n",
        "    selected_indices = torch.topk(-scores, krum_limit, largest=True).indices\n",
        "\n",
        "    # Average the updates of the selected clients\n",
        "    aggregated_update = torch.mean(local_updates[selected_indices], dim=0)\n",
        "\n",
        "    # Clean up memory before returning\n",
        "    del scores, local_updates\n",
        "\n",
        "    return aggregated_update, selected_indices\n",
        "\n",
        "def clip_tensor_norm_(\n",
        "    parameters: Union[torch.Tensor, Iterable[torch.Tensor]],\n",
        "    max_norm: float,\n",
        "    norm_type: float = 2.0,\n",
        "    error_if_nonfinite: bool = False,\n",
        ") -> torch.Tensor:\n",
        "    if isinstance(parameters, torch.Tensor):\n",
        "        parameters = [parameters]\n",
        "\n",
        "    max_norm = float(max_norm)\n",
        "    norm_type = float(norm_type)\n",
        "\n",
        "    if len(parameters) == 0:\n",
        "        return torch.tensor(0.0)\n",
        "\n",
        "    device = parameters[0].device\n",
        "\n",
        "    if norm_type == inf:\n",
        "        norms = [p.detach().abs().max().to(device) for p in parameters]\n",
        "        total_norm = norms[0] if len(norms) == 1 else torch.max(torch.stack(norms))\n",
        "    else:\n",
        "        total_norm = torch.norm(\n",
        "            torch.cat(\n",
        "                [\n",
        "                    p.detach().view(-1).to(device)\n",
        "                    for p in parameters\n",
        "                    if p.dtype != torch.int64\n",
        "                ]\n",
        "            ),\n",
        "            norm_type,\n",
        "        )\n",
        "\n",
        "    if error_if_nonfinite and torch.logical_or(total_norm.isnan(), total_norm.isinf()):\n",
        "        raise RuntimeError(\n",
        "            f\"The total norm of order {norm_type} for gradients from \"\n",
        "            \"`parameters` is non-finite, so it cannot be clipped. To disable \"\n",
        "            \"this error and scale the gradients by the non-finite norm anyway, \"\n",
        "            \"set `error_if_nonfinite=False`\"\n",
        "        )\n",
        "\n",
        "    clip_coef = max_norm / (total_norm + 1e-6)\n",
        "    clip_coef_clamped = torch.clamp(clip_coef, max=1.0)\n",
        "\n",
        "    for p in parameters:\n",
        "        if p.dtype != torch.int64:\n",
        "            p.mul_(clip_coef_clamped.to(p.device))\n",
        "\n",
        "def Clippedclustering(updates: torch.Tensor):\n",
        "    tau = 1e5\n",
        "    l2norm_his = []\n",
        "\n",
        "    # Calculate L2 norms in a single operation\n",
        "    l2norms = [torch.norm(update).item() for update in updates]\n",
        "    l2norm_his.extend(l2norms)\n",
        "\n",
        "    threshold = np.median(l2norm_his)\n",
        "    threshold = min(threshold, tau)\n",
        "\n",
        "    # Clip tensor norms above the threshold\n",
        "    for idx, l2 in enumerate(l2norms):\n",
        "        if l2 > threshold:\n",
        "            clip_tensor_norm_(updates[idx], threshold)\n",
        "\n",
        "    num = len(updates)\n",
        "\n",
        "    dis_max = 1 - torch.mm(\n",
        "        updates, updates.t()\n",
        "    ).cpu().numpy()  # Convert to numpy for AgglomerativeClustering\n",
        "\n",
        "    # Handle boundary conditions for distance matrix\n",
        "    dis_max = np.where(np.isinf(dis_max), 2.0, np.where(np.isnan(dis_max), 2.0, dis_max))\n",
        "\n",
        "    # Hierarchical clustering\n",
        "    clustering = AgglomerativeClustering(\n",
        "        metric=\"precomputed\", linkage=\"average\", n_clusters=2\n",
        "    )\n",
        "    clustering.fit(dis_max)\n",
        "\n",
        "    flag = 1 if np.sum(clustering.labels_) > num // 2 else 0\n",
        "    S1_idxs = [idx for idx, label in enumerate(clustering.labels_) if label == flag]\n",
        "\n",
        "    # Vectorized feature extraction\n",
        "    num_para = len(updates[0])\n",
        "    feature0 = (updates > 0).float().mean(dim=1)\n",
        "    feature1 = (updates < 0).float().mean(dim=1)\n",
        "    feature2 = (updates == 0).float().mean(dim=1)\n",
        "\n",
        "    features = torch.stack([feature0, feature1, feature2], dim=1).cpu().numpy()\n",
        "\n",
        "    # KMeans clustering\n",
        "    kmeans = KMeans(n_clusters=2, random_state=0).fit(features)\n",
        "    flag = 1 if np.sum(kmeans.labels_) > num // 2 else 0\n",
        "    S2_idxs = [idx for idx, label in enumerate(kmeans.labels_) if label == flag]\n",
        "\n",
        "    # Select intersection of both clustering methods\n",
        "    selected_idxs = list(set(S1_idxs) & set(S2_idxs))\n",
        "\n",
        "    # Return the mean of selected updates\n",
        "    return torch.mean(updates[selected_idxs], dim=0)\n",
        "\n",
        "def SignGuard(updates):\n",
        "    # updates = updates.cpu()\n",
        "\n",
        "    num = updates.shape[0]\n",
        "    # Compute L2 norms across all dimensions except the first\n",
        "    l2norms = torch.norm(updates, dim=tuple(range(1, updates.ndim)))\n",
        "\n",
        "    # Compute the median using torch.median (stays on GPU)\n",
        "    M = torch.median(l2norms)\n",
        "    L = 0.1\n",
        "    R = 3.0\n",
        "\n",
        "    # Create a mask for S1 indices\n",
        "    mask1 = (l2norms >= L * M) & (l2norms <= R * M)\n",
        "    del l2norms, M  # Delete l2norms and M as they're no longer needed\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Flatten updates for feature computation\n",
        "    updates_flat = updates.view(updates.shape[0], -1).cpu()\n",
        "    num_para = updates_flat.size(1)\n",
        "\n",
        "    # Compute features using vectorized operations\n",
        "    positive_counts = (updates_flat > 0).sum(dim=1).float() / num_para\n",
        "    negative_counts = (updates_flat < 0).sum(dim=1).float() / num_para\n",
        "    zero_counts = (updates_flat == 0).sum(dim=1).float() / num_para\n",
        "\n",
        "    features = torch.stack([positive_counts, negative_counts, zero_counts], dim=1).cpu().numpy()\n",
        "    del updates_flat, positive_counts, negative_counts, zero_counts  # Clean up\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Perform KMeans clustering\n",
        "    kmeans = KMeans(n_clusters=2, random_state=0).fit(features)\n",
        "    labels = kmeans.labels_\n",
        "    del kmeans, features  # Clean up CPU memory\n",
        "\n",
        "    # Convert labels back to a CUDA tensor\n",
        "    labels = torch.from_numpy(labels).to(device)\n",
        "\n",
        "    # Determine the majority cluster\n",
        "    flag = 1 if labels.sum() > num // 2 else 0\n",
        "\n",
        "    # Create a mask for S2 indices\n",
        "    mask2 = (labels == flag)\n",
        "    del labels  # Delete labels as it's no longer needed\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Intersection of S1 and S2 indices\n",
        "    inter_mask = mask1 & mask2\n",
        "    del mask1, mask2  # Clean up masks\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Select the updates based on the intersection mask\n",
        "    selected_updates = updates[inter_mask]\n",
        "    del updates, inter_mask  # Delete updates and inter_mask\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Compute and return the mean of the selected updates\n",
        "    result = torch.mean(selected_updates, dim=0)\n",
        "    del selected_updates  # Clean up selected_updates\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result.to(device)"
      ],
      "metadata": {
        "id": "qwM4nYoULKwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attacks (XFED)"
      ],
      "metadata": {
        "id": "WgmZW6tziyz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mu_pairwise_distance(global_models):\n",
        "    \"\"\"Compute pairwise distance based deviation (mu).\"\"\"\n",
        "    num_models = len(global_models)\n",
        "    # print(\"num_models\", num_models)\n",
        "    # print(\"global_models\", global_models)\n",
        "    if num_models > 1:\n",
        "        global_models_tensor = torch.vstack(global_models)\n",
        "        # Step 1: Calculate the centroid (mean vector)\n",
        "        centroid = torch.mean(global_models_tensor, dim=0)\n",
        "        # Step 2: Compute the Euclidean distance of each vector from the centroid\n",
        "        # Step 3: Calculate the standard deviation of the distances\n",
        "        distances = torch.norm(global_models_tensor - centroid, dim=1)\n",
        "        std_dev = torch.sqrt(torch.dot(distances, distances) / num_models)\n",
        "        mu = MU_MULTIPLIER * std_dev\n",
        "        return mu\n",
        "    else:\n",
        "        return torch.tensor(0.0)\n"
      ],
      "metadata": {
        "id": "6ZFitOiQi5uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attacks( VIRAT, FANG-TR-MEAN, FANG-KRUM, LIE)"
      ],
      "metadata": {
        "id": "Dw82zh_Zjslf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def virat_min_max(user_grads, n_attackers, dev_type='VIRAT_unit_vec', epoch = 0, threshold=50):\n",
        "    \"\"\"Implement VIRAT Min-Max attack.\"\"\"\n",
        "    all_updates = user_grads[:n_attackers].to(device)\n",
        "    model_re = torch.mean(all_updates, dim=0).to(device)\n",
        "\n",
        "    if dev_type == 'VIRAT_unit_vec':\n",
        "        deviation = model_re / torch.norm(model_re)\n",
        "    elif dev_type == 'VIRAT_sign':\n",
        "        deviation = torch.sign(model_re)\n",
        "    elif dev_type == 'VIRAT_std':\n",
        "        deviation = torch.std(all_updates, dim=0)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown deviation type: {dev_type}\")\n",
        "\n",
        "    lamda = torch.tensor([threshold], dtype=torch.float).to(device)\n",
        "    threshold_diff = 1e-5\n",
        "    lamda_fail = lamda.clone()\n",
        "    lamda_succ = torch.tensor(0, dtype=torch.float).to(device)\n",
        "\n",
        "    distances = []\n",
        "    for update in all_updates:\n",
        "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
        "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
        "\n",
        "    max_distance = torch.max(distances)\n",
        "    del distances\n",
        "\n",
        "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
        "        mal_update = model_re - lamda * deviation\n",
        "        distance = torch.norm(all_updates - mal_update, dim=1) ** 2\n",
        "        max_d = torch.max(distance)\n",
        "\n",
        "        if max_d <= max_distance:\n",
        "            lamda_succ = lamda.clone()\n",
        "            lamda += lamda_fail / 2\n",
        "        else:\n",
        "            lamda -= lamda_fail / 2\n",
        "\n",
        "        lamda_fail /= 2\n",
        "    print(f\"For round {epoch}, max_distance\", max_distance, \"lamda_succ\", lamda_succ)\n",
        "    mal_update = (model_re - lamda_succ * deviation) #.to('cpu')\n",
        "    mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n",
        "    return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n",
        "\n",
        "def fang_attack_trmean_partial(user_grads, n_attackers):\n",
        "\n",
        "    all_updates = user_grads[:n_attackers]\n",
        "    model_re = torch.mean(all_updates, 0)\n",
        "    model_std = torch.std(all_updates, 0)\n",
        "    deviation = torch.sign(model_re)\n",
        "\n",
        "    max_vector_low = model_re + 3 * model_std\n",
        "    max_vector_hig = model_re + 4 * model_std\n",
        "    min_vector_low = model_re - 4 * model_std\n",
        "    min_vector_hig = model_re - 3 * model_std\n",
        "\n",
        "    max_range = torch.cat((max_vector_low[:,None], max_vector_hig[:,None]), dim=1)\n",
        "    min_range = torch.cat((min_vector_low[:,None], min_vector_hig[:,None]), dim=1)\n",
        "\n",
        "    rand = torch.from_numpy(np.random.uniform(0, 1, [len(deviation), n_attackers])).type(torch.FloatTensor)\n",
        "\n",
        "    max_rand = torch.stack([max_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([max_range[:, 1] - max_range[:, 0]] * rand.shape[1]).T\n",
        "    min_rand = torch.stack([min_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([min_range[:, 1] - min_range[:, 0]] * rand.shape[1]).T\n",
        "\n",
        "    mal_update = (torch.stack([(deviation > 0).type(torch.FloatTensor)] * max_rand.shape[1]).T * max_rand + torch.stack(\n",
        "        [(deviation > 0).type(torch.FloatTensor)] * min_rand.shape[1]).T * min_rand).T\n",
        "\n",
        "    return list(torch.unbind(mal_update, dim=0)) + user_grads[n_attackers:]\n",
        "\n",
        "def compute_lambda_fang(all_updates, model_re, n_attackers):\n",
        "    distances = []\n",
        "    n_benign, d = all_updates.shape\n",
        "    for update in all_updates:\n",
        "        distance = torch.norm((all_updates - update), dim=1)\n",
        "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
        "\n",
        "    distances[distances == 0] = 10000\n",
        "    distances = torch.sort(distances, dim=1)[0]\n",
        "    scores = torch.sum(distances[:, :n_benign - 2 - n_attackers], dim=1)\n",
        "    min_score = torch.min(scores)\n",
        "    term_1 = min_score / ((n_benign - n_attackers - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
        "    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
        "\n",
        "    return (term_1 + max_wre_dist)\n",
        "\n",
        "def get_malicious_updates_fang(all_updates, model_re, deviation, n_attackers):\n",
        "\n",
        "    lamda = 100 # compute_lambda_fang(all_updates, model_re, n_attackers)\n",
        "    threshold = torch.tensor(1e-5)\n",
        "\n",
        "    mal_updates = []\n",
        "    while lamda > threshold:\n",
        "        mal_update = (model_re - lamda * deviation)\n",
        "\n",
        "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
        "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
        "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
        "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
        "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
        "\n",
        "        _, selected_indices = multi_krum_optimized(mal_updates)\n",
        "        # print(f'len {len(mal_updates)}, lamda {lamda}, indices {selected_indices}')\n",
        "\n",
        "        if torch.any(selected_indices < n_attackers):\n",
        "            return mal_update\n",
        "\n",
        "        lamda *= 0.5\n",
        "\n",
        "    if not len(mal_updates):\n",
        "        print(lamda, threshold)\n",
        "        mal_update = (model_re - lamda * deviation)\n",
        "    return mal_update\n",
        "\n",
        "def lie_attack(user_grads, n_attackers, z):\n",
        "\n",
        "    # Stack the gradients for the attackers\n",
        "    all_updates = torch.stack(user_grads[:n_attackers])\n",
        "\n",
        "    # Calculate mean and standard deviation of the attacker's updates\n",
        "    avg = torch.mean(all_updates, dim=0)\n",
        "    std = torch.std(all_updates, dim=0)\n",
        "\n",
        "    # Generate malicious updates\n",
        "    mal_update = avg + z * std\n",
        "\n",
        "    mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n",
        "    return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "ynbQi9pnjy-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for calculating Z value"
      ],
      "metadata": {
        "id": "_pUsLI-nkkTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_values={(50,3):0.69847, (50,5):0.7054, (50,8):0.71904, (50,10):0.72575, (50,12):0.73891, (100,20):0.72907, (40, 8): 0.72575, (100,5):0.69497, (100,10):0.7054, (100,15):0.71566, (100,25):0.74215, (100, 30):0.75804}\n",
        "# z value calculation code to execute lie attack\n",
        "import math\n",
        "# Update the value of m to 10\n",
        "n=100\n",
        "m = 30\n",
        "\n",
        "# Recalculate s and z\n",
        "s = math.floor(n / 2 + 1) - m\n",
        "z = (n - m - s) / (n - m)\n",
        "print(z)"
      ],
      "metadata": {
        "id": "_gUO5IWDkp0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467eca95-ba5f-48e7-c8b6-eb8b508f5b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Federated Learning Training"
      ],
      "metadata": {
        "id": "AfA9uC4lkvAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MU_MULTIPLIER = 3\n",
        "\n",
        "def train_local_model(client_id, client_indices, global_model, train_data, batch_size, criterion, device, optimizer):\n",
        "    sampled_indices = random.sample(client_indices, min(batch_size, len(client_indices)))\n",
        "    sampled_data = Subset(train_data, sampled_indices)\n",
        "    # print(f\"client_id: {client_id}, sampled_indices: {len(sampled_indices)}, sampled_data: {len(sampled_data)}\")\n",
        "    sampled_loader = DataLoader(sampled_data, batch_size=len(sampled_indices), shuffle=False, num_workers=0) # Set batch_size to the length of sampled_data\n",
        "\n",
        "    # Move the model to the assigned GPU device\n",
        "    local_model = deepcopy(global_model).to(device)\n",
        "    if optimizer == 'SGD':\n",
        "        local_optimizer = optim.SGD(local_model.parameters(), lr=0.5, momentum=0.9)\n",
        "    else:\n",
        "        local_optimizer = torch.optim.Adam(local_model.parameters(), lr=1e-3)\n",
        "\n",
        "    for inputs, targets in sampled_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        # print(len(inputs), len(targets))\n",
        "        local_optimizer.zero_grad()\n",
        "        outputs = local_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n",
        "        local_optimizer.step()\n",
        "\n",
        "    # Collect model parameters for aggregation\n",
        "    local_params = torch.cat([param.data.view(-1).cpu() for param in local_model.parameters()])\n",
        "    # local_params = torch.cat([param.data.view(-1) for param in local_model.parameters()])\n",
        "\n",
        "\n",
        "    # Cleanup\n",
        "    del local_model, sampled_data, sampled_loader\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return client_id, local_params\n",
        "\n",
        "\n",
        "def federated_learning(num_clients=10, aggregation='MEAN', n_attackers=3, attack_type='XFED_unit_vec', dataset='CIFAR10', n_round=1000, batch_size=64, optim='SGD'):\n",
        "    \"\"\"Main federated learning loop.\"\"\"\n",
        "    global_model, train_data, testloader = load_model(dataset)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Step 1: Split the dataset among clients\n",
        "    total_data_size = len(train_data)\n",
        "    client_data_size = total_data_size // num_clients\n",
        "    print(\"client_data_size\", client_data_size)\n",
        "    indices = list(range(total_data_size))\n",
        "    random.shuffle(indices)\n",
        "    clients_data_indices = [indices[i * client_data_size:(i + 1) * client_data_size] for i in range(num_clients)]\n",
        "\n",
        "    global_models, global_model_data = [], []\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=THREAD_NUMBER) as executor:  # Adjust max_workers based on your system capabilities\n",
        "        for epoch in range(n_round):\n",
        "            global_model.train()\n",
        "            local_models_data_diff = []\n",
        "\n",
        "            # Delete the oldest item if size is greater then 25\n",
        "            if len(global_models) > 8:\n",
        "                del global_models[0]\n",
        "\n",
        "            futures = [\n",
        "                executor.submit(\n",
        "                    train_local_model,\n",
        "                    client_id,\n",
        "                    client_indices,\n",
        "                    global_model,\n",
        "                    train_data,\n",
        "                    batch_size,\n",
        "                    criterion,\n",
        "                    devices[client_id % len(devices)],  # Alternate between 'cuda:0' and 'cuda:1'\n",
        "                    optim\n",
        "                )\n",
        "                for client_id, client_indices in enumerate(clients_data_indices)\n",
        "            ]\n",
        "\n",
        "            # Collect results\n",
        "            for future in as_completed(futures):\n",
        "                client_id, local_params = future.result()\n",
        "                local_models_data_diff.append(local_params)\n",
        "\n",
        "            for i in range(torch.cuda.device_count()):\n",
        "                torch.cuda.set_device(i)\n",
        "                torch.cuda.empty_cache()\n",
        "            torch.cuda.set_device(device)\n",
        "            print(f'For round {epoch}, training done')\n",
        "            # time.sleep(30)\n",
        "            local_models_data = torch.stack(local_models_data_diff).to(device)\n",
        "            del local_models_data_diff\n",
        "            gc.collect()\n",
        "\n",
        "            if attack_type.startswith('XFED'):\n",
        "                for local_machine in range(n_attackers):\n",
        "                    if attack_type == 'XFED_unit_vec':\n",
        "                        deviation = local_models_data[local_machine] / torch.norm(local_models_data[local_machine])\n",
        "                    elif attack_type == 'XFED_sign':\n",
        "                        sgn_vec = torch.sign(local_models_data[local_machine])\n",
        "                        deviation = sgn_vec / torch.norm(sgn_vec)\n",
        "                    else:\n",
        "                        raise ValueError(\"Invalid attack type\")\n",
        "\n",
        "                    if len(global_models) > 1:\n",
        "\n",
        "                        # version 1\n",
        "                        # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu\", torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models))\n",
        "                        mu = torch.max(torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models))\n",
        "\n",
        "                        # version 2\n",
        "                        # mu = torch.norm(local_models_data[local_machine] - global_model_data)\n",
        "                        # print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}\")\n",
        "\n",
        "                        # version 3\n",
        "                        #global_distance, pairwise_distance = torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models)\n",
        "                        #mu = torch.max(global_distance, pairwise_distance)\n",
        "                        #print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}, global_distance: {global_distance}, pairwise_distance: {pairwise_distance}\")\n",
        "\n",
        "                    else:\n",
        "                        mu = torch.tensor(1.0)\n",
        "                    delta = mu * deviation\n",
        "\n",
        "                    # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu: {mu}\\ndeviation: {deviation}\\ndelta: {delta}\\nlocal model: {local_models_data[local_machine]}\\nglobal model: {global_model_data}\")\n",
        "                    if epoch == 0:\n",
        "                        local_models_data[local_machine] -= delta\n",
        "                    else:\n",
        "                        # del local_models_data[local_machine]\n",
        "                        local_models_data[local_machine] = global_model_data - delta\n",
        "                    # print(f\"after update model after attack: {local_models_data[local_machine]}\\n\")\n",
        "                    del deviation, delta, mu\n",
        "\n",
        "            elif attack_type.startswith('VIRAT') and n_attackers > 0:\n",
        "                local_models_data = virat_min_max(local_models_data, n_attackers, attack_type, epoch=epoch)\n",
        "\n",
        "            elif attack_type.startswith('LIE') and n_attackers > 0:\n",
        "                local_models_data = lie_attack(local_models_data, n_attackers, z_values[(num_clients, n_attackers)])\n",
        "\n",
        "            elif attack_type =='FANG_TR_MEAN' and n_attackers > 0:\n",
        "                local_models_data = fang_attack_trmean_partial(local_models_data, n_attackers)\n",
        "\n",
        "            elif attack_type =='FANG_KRUM' and n_attackers > 0:\n",
        "                attacker_grads = torch.stack(local_models_data[:n_attackers])\n",
        "                agg_grads = torch.mean(attacker_grads, 0)\n",
        "                deviation = torch.sign(agg_grads)\n",
        "                mal_update = get_malicious_updates_fang(attacker_grads, agg_grads, deviation, n_attackers)\n",
        "                local_models_data = [mal_update] * n_attackers + local_models_data[n_attackers:]\n",
        "\n",
        "\n",
        "\n",
        "            print(f'For round {epoch}, attack done, Lenght of local_models_data:', len(local_models_data))\n",
        "\n",
        "            # Aggregate model updates\n",
        "            if aggregation == 'MEAN':\n",
        "                global_model_data = torch.mean(local_models_data, dim=0)\n",
        "            elif aggregation == 'MEDIAN':\n",
        "                global_model_data = torch.median(local_models_data, dim=0)[0]\n",
        "            elif aggregation == 'KRUM':\n",
        "                # Check if local_models_data is already a tensor\n",
        "                if isinstance(local_models_data, list):\n",
        "                    global_model_data, _ = multi_krum_optimized(local_updates=local_models_data)\n",
        "                else:\n",
        "                    global_model_data, _ = multi_krum_optimized(local_updates=local_models_data)\n",
        "            elif aggregation == 'TR-MEAN':\n",
        "                global_model_data = tr_mean(local_models_data)\n",
        "            elif aggregation == 'CC':\n",
        "                global_model_data = Clippedclustering(local_models_data)\n",
        "            elif aggregation == 'SignGuard':\n",
        "                global_model_data = SignGuard(local_models_data)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid aggregation method\")\n",
        "\n",
        "            if torch.isnan(global_model_data).any():\n",
        "                raise ValueError(\"NaN detected in model aggregation\")\n",
        "\n",
        "            # Update global model\n",
        "            start_idx = 0\n",
        "            with torch.no_grad():\n",
        "                for param in global_model.parameters():\n",
        "                    param_size = param.numel()\n",
        "                    param.copy_(global_model_data[start_idx:start_idx + param_size].view(param.shape))\n",
        "                    start_idx += param_size\n",
        "\n",
        "            global_models.append(global_model_data.cpu())\n",
        "\n",
        "            print(f'For round {epoch}, aggregation done')\n",
        "            last_ten_percent = int(n_round * 0.80)\n",
        "            if epoch >= last_ten_percent or epoch%20 == 0:\n",
        "                # Evaluate global model\n",
        "                global_model.eval()\n",
        "                global_model = global_model.to(device)\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                    for images, labels in testloader:\n",
        "                        images, labels = images.to(device), labels.to(device)\n",
        "                        outputs = global_model(images)\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        total += labels.size(0)\n",
        "                        correct += (predicted == labels).sum().item()\n",
        "\n",
        "                accuracy = 100 * correct / total\n",
        "                print(f'Time {datetime.now()}: Accuracy on round {epoch}, total {num_clients}, attackers {n_attackers}, attack_type {attack_type}, aggregation {aggregation} is: {accuracy:.2f} %')\n",
        "\n",
        "\n",
        "                # Append accuracy to a file\n",
        "                with open(f'accuracy_{dataset}_{aggregation}_{attack_type}_{n_attackers}_mu{MU_MULTIPLIER}_log.txt', 'a') as f:\n",
        "                    f.write(f'Time {datetime.now()}: Accuracy on round {epoch}, dataset {dataset},total {num_clients}, attackers {n_attackers}, attack_type {attack_type}, aggregation {aggregation} is: {accuracy:.2f} %\\n')\n",
        "\n",
        "            # global_model = global_model.to('cpu')\n",
        "            del local_models_data\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    # Final cleanup after training\n",
        "    del global_model, train_data, testloader, global_models, criterion\n",
        "\n"
      ],
      "metadata": {
        "id": "zXWWAdggktr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Execution"
      ],
      "metadata": {
        "id": "NG0kwZK9lM9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example execution\n",
        "for attack_type in ['VIRAT_unit_vec']: # 'XFED_unit_vec', 'XFED_sign', 'VIRAT_unit_vec', 'LIE', 'FANG_TR_MEAN'\n",
        "    for agg in ['SignGuard']: # 'MEAN', 'MEDIAN', 'KRUM', 'TR-MEAN'\n",
        "        for attackers in [0]:\n",
        "            # torch.cuda.memory._record_memory_history()\n",
        "             federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=300, dataset='EMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\n",
        "            # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=250, dataset='FashionMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\n",
        "            # federated_learning(num_clients=50, n_attackers=attackers, aggregation=agg, n_round=255, dataset='CIFAR10', attack_type=attack_type, batch_size=250)\n",
        "            # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=1000, dataset='SVHN', attack_type=attack_type, batch_size=64, optim=\"SGD\")\n",
        "            # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=275, dataset='MNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\n",
        "            # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=500, dataset='PURCHASE', attack_type=attack_type, batch_size=128, optim=\"SGD\")\n",
        "            # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=300, dataset='CIFAR100', attack_type=attack_type, batch_size=250, optim=\"Adam\")\n",
        "            # torch.cuda.memory._dump_snapshot(\"cifar10.pickle\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jnRgpMBTlSqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb66f4ef-f92f-4f39-948c-115fe3488ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/gzip.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 562M/562M [00:26<00:00, 21.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/EMNIST/raw/gzip.zip to ./data/EMNIST/raw\n",
            "client_data_size 17448\n",
            "For round 0, training done\n",
            "For round 0, attack done, Lenght of local_models_data: 40\n",
            "For round 0, aggregation done\n",
            "Time 2024-10-23 19:44:27.066859: Accuracy on round 0, total 40, attackers 0, attack_type VIRAT_unit_vec, aggregation SignGuard is: 16.64 %\n",
            "For round 1, training done\n",
            "For round 1, attack done, Lenght of local_models_data: 40\n",
            "For round 1, aggregation done\n",
            "For round 2, training done\n",
            "For round 2, attack done, Lenght of local_models_data: 40\n",
            "For round 2, aggregation done\n",
            "For round 3, training done\n",
            "For round 3, attack done, Lenght of local_models_data: 40\n",
            "For round 3, aggregation done\n",
            "For round 4, training done\n",
            "For round 4, attack done, Lenght of local_models_data: 40\n",
            "For round 4, aggregation done\n",
            "For round 5, training done\n",
            "For round 5, attack done, Lenght of local_models_data: 40\n",
            "For round 5, aggregation done\n",
            "For round 6, training done\n",
            "For round 6, attack done, Lenght of local_models_data: 40\n",
            "For round 6, aggregation done\n",
            "For round 7, training done\n",
            "For round 7, attack done, Lenght of local_models_data: 40\n",
            "For round 7, aggregation done\n",
            "For round 8, training done\n",
            "For round 8, attack done, Lenght of local_models_data: 40\n",
            "For round 8, aggregation done\n",
            "For round 9, training done\n",
            "For round 9, attack done, Lenght of local_models_data: 40\n",
            "For round 9, aggregation done\n",
            "For round 10, training done\n",
            "For round 10, attack done, Lenght of local_models_data: 40\n",
            "For round 10, aggregation done\n",
            "For round 11, training done\n",
            "For round 11, attack done, Lenght of local_models_data: 40\n",
            "For round 11, aggregation done\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a8a8ac2fb310>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattackers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m# torch.cuda.memory._record_memory_history()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m              \u001b[0mfederated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attackers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattackers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EMNIST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattack_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;31m# federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=250, dataset='FashionMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# federated_learning(num_clients=50, n_attackers=attackers, aggregation=agg, n_round=255, dataset='CIFAR10', attack_type=attack_type, batch_size=250)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-2d00bbdda3b2>\u001b[0m in \u001b[0;36mfederated_learning\u001b[0;34m(num_clients, aggregation, n_attackers, attack_type, dataset, n_round, batch_size, optim)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Collect results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mlocal_models_data_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    243\u001b[0m                             len(pending), total_futures))\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}