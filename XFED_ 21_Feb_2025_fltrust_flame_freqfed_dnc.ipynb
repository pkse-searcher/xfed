{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22819,"status":"ok","timestamp":1744700133587,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"_QYFIElVnecH","outputId":"c608e90f-3b16-4a1f-b327-46ac3ffb6b70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Function to determine the data root directory\n","import os\n","def get_data_root():\n","    if 'COLAB_GPU' in os.environ:\n","        # Mount Google Drive if needed\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        data_root = '/content/drive/MyDrive/PhD/XFED result/Result XFED log/colab output/'\n","    else:\n","        data_root = './data/'\n","    return data_root\n","\n","# Get the appropriate data root directory\n","data_root = get_data_root()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11524,"status":"ok","timestamp":1744700145113,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"PaOkiimBIHdE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95053ced-5a20-49a3-eb64-133850a2aa1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of GPUs available: 1\n","Using GPU: cuda:0\n","Devices: ['cuda:0']\n","Number of CPU cores available: 12\n","THREAD_NUMBER set to: 2\n","Tue Apr 15 06:55:43 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0             46W /  400W |       5MiB /  40960MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","\n","Architecture:                         x86_64\n","CPU op-mode(s):                       32-bit, 64-bit\n","Address sizes:                        46 bits physical, 48 bits virtual\n","Byte Order:                           Little Endian\n","CPU(s):                               12\n","On-line CPU(s) list:                  0-11\n","Vendor ID:                            GenuineIntel\n","Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\n","CPU family:                           6\n","Model:                                85\n","Thread(s) per core:                   2\n","Core(s) per socket:                   6\n","Socket(s):                            1\n","Stepping:                             7\n","BogoMIPS:                             4400.41\n","Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","Hypervisor vendor:                    KVM\n","Virtualization type:                  full\n","L1d cache:                            192 KiB (6 instances)\n","L1i cache:                            192 KiB (6 instances)\n","L2 cache:                             6 MiB (6 instances)\n","L3 cache:                             38.5 MiB (1 instance)\n","NUMA node(s):                         1\n","NUMA node0 CPU(s):                    0-11\n","Vulnerability Gather data sampling:   Not affected\n","Vulnerability Itlb multihit:          Not affected\n","Vulnerability L1tf:                   Not affected\n","Vulnerability Mds:                    Not affected\n","Vulnerability Meltdown:               Not affected\n","Vulnerability Mmio stale data:        Vulnerable\n","Vulnerability Reg file data sampling: Not affected\n","Vulnerability Retbleed:               Vulnerable\n","Vulnerability Spec rstack overflow:   Not affected\n","Vulnerability Spec store bypass:      Vulnerable\n","Vulnerability Spectre v1:             Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers\n","Vulnerability Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIBRS: Vulnerable; BHI: Vulnerable (Syscall hardening enabled)\n","Vulnerability Srbds:                  Not affected\n","Vulnerability Tsx async abort:        Vulnerable\n","\n"]}],"source":["import os\n","os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"  # or \":16:8\"\n","\n","import sys\n","import subprocess\n","\n","def install(package):\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n","\n","# Function to attempt to import a module, and install it if not present\n","def try_import(module_name, package_name=None):\n","    try:\n","        module = __import__(module_name)\n","        return module\n","    except ImportError:\n","        if package_name is None:\n","            package_name = module_name\n","        print(f\"Installing {package_name}...\")\n","        install(package_name)\n","        module = __import__(module_name)\n","        return module\n","\n","# Standard library imports (no need to install)\n","import logging\n","from datetime import datetime\n","from copy import deepcopy\n","import gc\n","import random\n","import time\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from typing import Iterable, Union, Optional\n","\n","# Third-party imports\n","torch = try_import('torch')\n","torchvision = try_import('torchvision')\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import numpy as np\n","np = try_import('numpy')\n","# Import torch.nn as nn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split, Subset, Dataset, ConcatDataset\n","import torchvision.models as models\n","from torch.nn.functional import tanh, softmax\n","\n","from torchvision.datasets import utils\n","from PIL import Image\n","import os.path\n","import shutil\n","\n","\n","# sklearn imports\n","sklearn = try_import('sklearn', 'scikit-learn')\n","from sklearn.model_selection import train_test_split\n","from sklearn.cluster import AgglomerativeClustering, KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.metrics.pairwise import cosine_distances,euclidean_distances\n","from sklearn.metrics import pairwise_distances\n","import sklearn.metrics.pairwise as smp\n","\n","import hdbscan\n","\n","# Other third-party imports\n","plt = try_import('matplotlib.pyplot', 'matplotlib')\n","pd = try_import('pandas')\n","\n","\n","\n","# torch.use_deterministic_algorithms(True, warn_only=True)\n","torch.manual_seed(0)\n","\n","# Device configuration\n","# Get the number of available GPUs\n","num_gpus = torch.cuda.device_count()\n","print(f\"Number of GPUs available: {num_gpus}\")\n","\n","# If GPUs are available, choose the desired device index (within the available range)\n","# Otherwise, default to CPU\n","if num_gpus > 0:\n","    desired_gpu_index = 3  # This is the index you originally wanted\n","    device_index = min(desired_gpu_index, num_gpus - 1)  # Clamp to available range\n","    device = torch.device(f\"cuda:{device_index}\")\n","    torch.cuda.set_device(device)  # Set the device\n","    print(f\"Using GPU: {device}\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"No GPUs available, using CPU.\")\n","\n","\n","#set devices to multiple GPUs\n","unwanted_device_indices = []\n","available_device_indices = list(range(num_gpus))\n","devices = [f'cuda:{i}' for i in available_device_indices if i not in unwanted_device_indices]\n","if not devices:\n","    devices = ['cpu']\n","    # raise RuntimeError(\"Desired GPUs are not available.\")\n","print(f\"Devices: {devices}\")\n","\n","\n","\n","\n","import multiprocessing\n","\n","# Get the number of available CPU cores\n","num_cores = multiprocessing.cpu_count()\n","\n","# Set THREAD_NUMBER to the number of CPU cores\n","THREAD_NUMBER = min(num_cores, 2*(len(devices)))\n","# THREAD_NUMBER = 20 # num_cores\n","\n","print(f\"Number of CPU cores available: {num_cores}\")\n","print(f\"THREAD_NUMBER set to: {THREAD_NUMBER}\")\n","\n","\n","\n","# Check GPU information\n","def check_gpu():\n","    try:\n","        gpu_info = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n","        print(gpu_info)\n","    except Exception as e:\n","        print('Not connected to a GPU or nvidia-smi not found.')\n","\n","check_gpu()\n","\n","# Check CPU information\n","def check_cpu():\n","    try:\n","        cpu_info = subprocess.check_output(['lscpu']).decode('utf-8')\n","        print(cpu_info)\n","    except Exception as e:\n","        print('Could not retrieve CPU information.')\n","\n","check_cpu()"]},{"cell_type":"markdown","metadata":{"id":"TPXgVfNmnhES"},"source":["# Function to determine the data root directory"]},{"cell_type":"markdown","metadata":{"id":"TLIncX6sIy49"},"source":["# Model Definition for different datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1744700145158,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"7zE8s1djJkuN"},"outputs":[],"source":["class FashionMNISTAlexNet(nn.Module):\n","    def __init__(self):\n","        super(FashionMNISTAlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=0),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 10),\n","            nn.LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","class FeatureNorm(nn.Module):\n","    def __init__(self, feature_shape):\n","        super().__init__()\n","        self.gamma = nn.Parameter(torch.ones(1))\n","        self.beta = nn.Parameter(torch.zeros(1, feature_shape))\n","\n","    def forward(self, x):\n","        x = torch.einsum('ni, j->ni', x, self.gamma)\n","        x = x + self.beta\n","        return  x\n","\n","class purchase_fully_connected_IN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(purchase_fully_connected_IN, self).__init__()\n","        self.fc1 = nn.Linear(600, 1024, bias=False)  # First layer: input size 600, output size 1024\n","        self.fc2 = nn.Linear(1024, 100, bias=False)  # Second layer: input size 1024, output size 100\n","        self.fc3 = nn.Linear(100, num_classes, bias=False)  # Output layer: input size 100, output size num_classes\n","        self.norm = FeatureNorm(600)\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","        x = torch.tanh(self.fc1(x))  # Apply tanh activation after the first layer\n","        x = torch.tanh(self.fc2(x))  # Apply tanh activation after the second layer\n","        logits = self.fc3(x)         # Output layer, no activation\n","        return logits\n","\n","class Purchase(torch.utils.data.Dataset):\n","    def __init__(self, root =data_root + 'dataset_purchase',train=True, download=True, transform = None):\n","        self.images = []\n","        self.root = root\n","        self.targets = []\n","        self.train = train\n","        self.download = download\n","        self.transform = transform\n","\n","        x_train, x_test, y_train, y_test = self._train_test_split()\n","\n","        if self.train:\n","            self._setup_dataset(x_train, y_train)\n","        else:\n","            self._setup_dataset(x_test, y_test)\n","\n","    def _train_test_split(self):\n","        df = pd.read_csv(self.root)\n","\n","        img_names = df.iloc[:, 1:].to_numpy(dtype='f')\n","        img_label = df.iloc[:, 0].to_numpy()-1\n","        x_train,x_test, y_train, y_test = train_test_split(img_names, img_label, train_size=0.8,\n","                                                            random_state=1)\n","        return x_train, x_test, y_train, y_test\n","\n","    def _setup_dataset(self, x, y):\n","            self.images = x\n","            self.targets = y\n","\n","    def __len__(self): # Added the __len__ method\n","        return len(self.images)\n","\n","    def __getitem__(self, item):\n","        img = self.images[item]\n","        label = self.targets[item]\n","        return img, label\n","\n","class ThreeLayerDNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(ThreeLayerDNN, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu1 = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.relu2 = nn.ReLU()\n","        self.fc3 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","class FourLayerDNN(nn.Module):\n","    def __init__(self):\n","        super(FourLayerDNN, self).__init__()\n","        # Flatten the input image\n","        self.flatten = nn.Flatten()\n","        # Define the fully connected layers\n","        self.fc1 = nn.Linear(3 * 32 * 32, 1024)\n","        self.relu1 = nn.ReLU()\n","        self.fc2 = nn.Linear(1024, 512)\n","        self.relu2 = nn.ReLU()\n","        self.fc3 = nn.Linear(512, 256)\n","        self.relu3 = nn.ReLU()\n","        self.fc4 = nn.Linear(256, 10)  # Output layer for 10 classes\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.relu1(self.fc1(x))\n","        x = self.relu2(self.fc2(x))\n","        x = self.relu3(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","class InputNorm(nn.Module):\n","    def __init__(self, num_channel, num_feature):\n","        super().__init__()\n","        self.num_channel = num_channel\n","        self.gamma = nn.Parameter(torch.ones(num_channel))\n","        self.beta = nn.Parameter(torch.zeros(num_channel, num_feature, num_feature))\n","    def forward(self, x):\n","        if self.num_channel == 1:\n","            x = self.gamma*x\n","            x = x + self.beta\n","            return  x\n","        if self.num_channel == 3:\n","            return torch.einsum('...ijk, i->...ijk', x, self.gamma) + self.beta\n","\n","class mnist_fully_connected_IN(nn.Module):\n","    def __init__(self,num_classes):\n","        super(mnist_fully_connected_IN, self).__init__()\n","        self.hidden1 = 600\n","        self.hidden2 = 100\n","        self.fc1 = nn.Linear(28 * 28, self.hidden1, bias=False)\n","        self.fc2 = nn.Linear(self.hidden1, self.hidden2, bias=False)\n","        self.fc3 = nn.Linear(self.hidden2, num_classes, bias=False)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.norm = InputNorm(1, 28)\n","\n","    def forward(self,x):\n","        x = self.norm(x)\n","        x = x.view(-1, 28 * 28)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        logits = self.fc3(x)\n","        return logits\n","\n","class CHMNISTDataset(Dataset):\n","    def __init__(self, image_folder, transform=None):\n","        self.image_folder = image_folder\n","        self.transform = transform\n","        self.image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder)]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image = Image.open(image_path).convert('L')  # Convert to grayscale\n","        label = int(image_path.split('_')[-1].split('.')[0])  # Assuming label is in filename\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","\n","class HARLogisticRegression(nn.Module):\n","    \"\"\"\n","    A single-layer logistic regression model for multi-class HAR classification.\n","    \"\"\"\n","    def __init__(self, input_dim, num_classes=6):\n","        super(HARLogisticRegression, self).__init__()\n","        self.linear = nn.Linear(input_dim, num_classes)  # raw logits\n","\n","    def forward(self, x):\n","        return self.linear(x)  # No softmax/sigmoid; use CrossEntropyLoss externally\n","\n","\n","class LogisticRegressionModel(nn.Module):\n","    def __init__(self, input_dim):\n","        super(LogisticRegressionModel, self).__init__()\n","        # Define the linear layer for logistic regression\n","        self.linear = nn.Linear(input_dim, 1)\n","\n","    def forward(self, x):\n","        # Apply the linear layer and then the sigmoid activation\n","        out = torch.sigmoid(self.linear(x))\n","        return out\n","\n","class FEMNISTDataset(torchvision.datasets.MNIST):\n","    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n","        super(torchvision.datasets.MNIST, self).__init__(root, transform=transform, target_transform=target_transform)\n","        self.download = download\n","        self.download_link = 'https://media.githubusercontent.com/media/GwenLegate/femnist-dataset-PyTorch/main/femnist.tar.gz'\n","        self.file_md5 = 'a8a28afae0e007f1acb87e37919a21db'\n","        self.train = train\n","        self.root = root\n","        self.training_file = f'{self.root}/FEMNIST/processed/femnist_train.pt'\n","        self.test_file = f'{self.root}/FEMNIST/processed/femnist_test.pt'\n","        self.user_list = f'{self.root}/FEMNIST/processed/femnist_user_keys.pt'\n","\n","        if not os.path.exists(f'{self.root}/FEMNIST/processed/femnist_test.pt') \\\n","                or not os.path.exists(f'{self.root}/FEMNIST/processed/femnist_train.pt'):\n","            if self.download:\n","                self.dataset_download()\n","            else:\n","                raise RuntimeError('Dataset not found, set parameter download=True to download')\n","\n","        if self.train:\n","            data_file = self.training_file\n","        else:\n","            data_file = self.test_file\n","\n","        data_targets_users = torch.load(data_file)\n","        self.data, self.targets, self.users = torch.Tensor(data_targets_users[0]), torch.Tensor(data_targets_users[1]), data_targets_users[2]\n","        self.user_ids = torch.load(self.user_list)\n","\n","    def __getitem__(self, index):\n","        img, target = self.data[index], int(self.targets[index])\n","\n","        # Reshape the flattened image to 28x28\n","        img = img.view(28, 28).numpy().astype(np.uint8)\n","\n","        # Convert to PIL Image in grayscale mode\n","        img = Image.fromarray(img, mode='L')\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","        return img, target  # Return only img and target\n","\n","    def dataset_download(self):\n","        paths = [f'{self.root}/FEMNIST/raw/', f'{self.root}/FEMNIST/processed/']\n","        for path in paths:\n","            if not os.path.exists(path):\n","                os.makedirs(path)\n","\n","        # download files\n","        filename = self.download_link.split('/')[-1]\n","        utils.download_and_extract_archive(self.download_link, download_root=f'{self.root}/FEMNIST/raw/', filename=filename, md5=self.file_md5)\n","\n","        files = ['femnist_train.pt', 'femnist_test.pt', 'femnist_user_keys.pt']\n","        for file in files:\n","            # move to processed dir\n","            shutil.move(os.path.join(f'{self.root}/FEMNIST/raw/', file), f'{self.root}/FEMNIST/processed/')"]},{"cell_type":"markdown","metadata":{"id":"2o1uD2lVKAqO"},"source":["Loading Model for different datasets (FashionMNIST, CIFAR-10, PURCHASE, MNIST, EMNIST, CIFAR-100)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":78,"status":"ok","timestamp":1744700145238,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"tGc5WAzrKNDl"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","class SymbiPredictDataset(Dataset):\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        features = torch.tensor(self.data[idx], dtype=torch.float32)\n","        label = torch.tensor(self.labels[idx], dtype=torch.long)\n","        return features, label\n","\n","class TabularNet(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(TabularNet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, num_classes)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","class HARLocalDataset(Dataset):\n","    \"\"\"\n","    A simple PyTorch Dataset for a subset of HAR data (features + labels).\n","    \"\"\"\n","    def __init__(self, features, labels):\n","        # Convert to PyTorch tensors\n","        self.features = torch.tensor(features, dtype=torch.float32)\n","\n","        # Convert labels to numerical if they are not already\n","        if labels.dtype == np.object_:\n","            from sklearn.preprocessing import LabelEncoder\n","            encoder = LabelEncoder()\n","            labels = encoder.fit_transform(labels)\n","\n","        self.labels = torch.tensor(labels, dtype=torch.long)\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        return self.features[idx], self.labels[idx]\n","\n","\n","def load_model(dataset: str):\n","    \"\"\"Load and prepare the model and datasets based on the given dataset name.\"\"\"\n","    if dataset == 'FashionMNIST':\n","        transform = transforms.Compose([\n","            transforms.Resize((227, 227)),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.1307,), (0.3081,))\n","        ])\n","        train_data = torchvision.datasets.FashionMNIST(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.FashionMNIST(root=data_root, train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","        classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n","        model = FashionMNISTAlexNet().to(device)\n","\n","    elif dataset == 'FashionMNIST_3DNN':\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.1307,), (0.3081,))\n","        ])\n","        train_data = torchvision.datasets.FashionMNIST(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.FashionMNIST(root=data_root, train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","        classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n","        model = ThreeLayerDNN(input_size=784, hidden_size=512, output_size=10).to(device)\n","\n","    elif dataset == 'CIFAR10':\n","        transform = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        ])\n","        train_data = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","        classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n","\n","        model = models.alexnet(pretrained=True)\n","        model.classifier[1] = nn.Linear(9216, 4096)\n","        model.classifier[4] = nn.Linear(4096, 1024)\n","        model.classifier[6] = nn.Linear(1024, 10)\n","        model = model.to(device)\n","\n","    elif dataset == 'PURCHASE':\n","        train_data = Purchase(train=True, download=True)\n","        test_data = Purchase(train=False, download=True)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","\n","        model = purchase_fully_connected_IN(100).to(device)\n","\n","    elif dataset == 'CHMNIST':\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5,), (0.5,))\n","        ])\n","        train_data = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform) # Assuming CHMNIST is similar to MNIST\n","        test_data = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","        trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n","        testloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n","        model=models.mobilenet_v2(pretrained=True).to(device)\n","        model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","\n","    elif dataset == 'HAR':\n","        # Path to your CSV with 563 columns total: 561 features, then 'subject', then 'Activity'\n","        har_csv_path = os.path.join(data_root, 'har_all_in_one.csv')  # Adjust path as needed\n","\n","        # Read the CSV. If your CSV has column names as in your screenshot, you can keep header=0\n","        # But if you have no row of column names, do header=None. Adjust as needed.\n","        df = pd.read_csv(har_csv_path, header=0)\n","\n","        # Suppose:\n","        #   columns [0..560] => 561 features\n","        #   column 561 => subject in [1..30]\n","        #   column 562 => activity in [1..6] or string labels\n","        X = df.iloc[:, :561].values      # shape (N, 561)\n","        subjects = df.iloc[:, 561].values\n","        activity = df.iloc[:, 562].values\n","\n","        # If activity is integer [1..6], but we want [0..5] for CrossEntropyLoss, do:\n","        # activity = activity - 1  # now [0..5]\n","\n","        # Standardize all features\n","        scaler = StandardScaler()\n","        X = scaler.fit_transform(X)\n","\n","        # We'll build \"per-subject\" train/test sets\n","        train_datasets = []\n","        test_datasets = []\n","\n","        # Identify unique subject IDs\n","        unique_subjects = np.unique(subjects)\n","        print(\"Subjects found:\", unique_subjects)\n","\n","        for subj_id in unique_subjects:\n","            # Gather rows for this subject\n","            subj_mask = (subjects == subj_id)\n","            X_sub = X[subj_mask]\n","            y_sub = activity[subj_mask]\n","\n","            # 75/25 train/test for THIS subject\n","            X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n","                X_sub, y_sub, test_size=0.25, random_state=42\n","            )\n","\n","            # Wrap them in Datasets\n","            ds_train_sub = HARLocalDataset(X_train_sub, y_train_sub)\n","            ds_test_sub  = HARLocalDataset(X_test_sub,  y_test_sub)\n","\n","            train_datasets.append(ds_train_sub)\n","            test_datasets.append(ds_test_sub)\n","\n","        # Concat all per-subject train sets into one large train_data, likewise for test sets\n","        train_data = ConcatDataset(train_datasets)\n","        test_data  = ConcatDataset(test_datasets)\n","\n","        # Build a testloader for the entire test set\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n","\n","        # Build logistic regression model\n","        input_dim = 561\n","        # If your activity is 0..5, then num_classes=6\n","        # If you have 6 distinct string labels, also 6 total classes after label encoding\n","        num_classes = len(np.unique(activity))\n","        model = HARLogisticRegression(input_dim, num_classes).to(device)\n","\n","    elif dataset == 'EMNIST':\n","        transform = transforms.Compose([\n","            transforms.Resize((28, 28)),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5,), (0.5,))\n","        ])\n","\n","        train_data = torchvision.datasets.EMNIST(root='./data', split='byclass', train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.EMNIST(root='./data', split='byclass', train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","\n","        model = ThreeLayerDNN(input_size=28 * 28, hidden_size=512, output_size=62).to(device)\n","\n","    elif dataset == 'MNIST':\n","        # Define transformation for MNIST\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),        # Convert image to PyTorch tensor\n","            transforms.Normalize((0.5,), (0.5,))  # Normalize grayscale values to [-1, 1]\n","        ])\n","\n","        # Load the MNIST dataset (\"ByClass\" split as an example)\n","        train_data = torchvision.datasets.MNIST(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.MNIST(root=data_root, train=False, download=True, transform=transform)\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)\n","\n","        # Load the pre-trained VGG16 model\n","        model = mnist_fully_connected_IN(10).to(device)\n","\n","    elif dataset == 'CIFAR100':\n","        # Install and import CLIP\n","        try:\n","            import clip\n","        except ImportError:\n","            print(\"Installing CLIP...\")\n","            install('git+https://github.com/openai/CLIP.git')\n","            import clip\n","        # Define the transformation for the dataset (matching CLIP preprocessing)\n","        transform = transforms.Compose([\n","            transforms.Resize((224, 224)),  # CLIP expects 224x224 input\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),\n","        ])\n","\n","        # Load the CIFAR100 dataset\n","        train_data = torchvision.datasets.CIFAR100(root=data_root, train=True, download=True, transform=transform)\n","        test_data = torchvision.datasets.CIFAR100(root=data_root, train=False, download=True, transform=transform)\n","\n","        # Create DataLoader for train and test sets\n","        trainloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=8)\n","        testloader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=8)\n","\n","        # Define the class labels for CIFAR100\n","        classes = [str(i) for i in range(100)]  # CIFAR100 has 100 classes\n","\n","        # Load the CLIP model from OpenAI\n","        model_clip, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","        # Convert CLIP model to float32 to match other layers and data\n","        model_clip = model_clip.float()\n","\n","        # Freeze the CLIP model's parameters (we're only training the classifier)\n","        for param in model_clip.parameters():\n","            param.requires_grad = False\n","\n","        # Define a simple 1-layer DNN model on top of CLIP features\n","        class CLIP_DNN(nn.Module):\n","            def __init__(self, clip_model, num_classes=100):\n","                super(CLIP_DNN, self).__init__()\n","                self.clip_model = clip_model\n","                self.fc = nn.Linear(512, num_classes)  # CLIP ViT-B/32 gives 512-dimensional features\n","\n","            def forward(self, images):\n","                with torch.no_grad():\n","                    # Extract image features using CLIP's image encoder (cast to float32)\n","                    image_features = self.clip_model.encode_image(images).float()\n","                return self.fc(image_features)\n","\n","        # Initialize the model\n","        model = CLIP_DNN(model_clip, num_classes=100)\n","\n","        # Move the model to the device (GPU or CPU)\n","        model = model.to(device)\n","\n","\n","    elif dataset == 'SYMBIPREDICT':\n","        # Load the CSV file\n","        csv_file = os.path.join(data_root, 'symbipredict_2022.csv')\n","        df = pd.read_csv(csv_file)\n","\n","        # Encode target labels\n","        label_encoder = LabelEncoder()\n","        df['prognosis'] = label_encoder.fit_transform(df['prognosis'])\n","\n","        # Separate features and labels\n","        X = df.drop(columns=['prognosis']).values\n","        y = df['prognosis'].values\n","\n","        # Standardize features\n","        scaler = StandardScaler()\n","        X = scaler.fit_transform(X)\n","\n","        # Split into training and testing sets\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","        # Create Dataset instances\n","        train_data = SymbiPredictDataset(X_train, y_train)\n","        test_data = SymbiPredictDataset(X_test, y_test)\n","\n","        # DataLoader for test data only\n","        testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n","\n","        # Define model\n","        input_dim = X_train.shape[1]\n","        num_classes = len(label_encoder.classes_)\n","        model = TabularNet(input_dim=input_dim, num_classes=num_classes).to(device)\n","\n","    else:\n","        raise ValueError(\"Dataset not supported\")\n","\n","    return model, train_data, testloader\n"]},{"cell_type":"markdown","metadata":{"id":"htLtRlfGK1ku"},"source":["Aggregation Rules (\n","FedAvg / Mean,\n","Median,\n","Trimmed Mean,\n","Multi-Krum,\n","Clipped Clustering,\n","SignGuard)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":87,"status":"ok","timestamp":1744700145327,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"qwM4nYoULKwO"},"outputs":[],"source":["def tr_mean(all_updates: torch.Tensor) -> torch.Tensor:\n","    \"\"\"Apply Trimmed Mean aggregation with 20% assumed attackers.\"\"\"\n","    # tmp = all_updates\n","    # all_updates = all_updates.cpu()\n","    # del tmp\n","    # torch.cuda.empty_cache()\n","    sorted_updates = torch.sort(all_updates, dim=0)[0]\n","    num_clients = len(all_updates)\n","    n_attackers = round(0.2 * num_clients)\n","    if n_attackers != 0 and 2 * n_attackers < num_clients:\n","        ret = torch.mean(sorted_updates[n_attackers:-n_attackers], dim=0)\n","        # print(\"sorted_updates\", sorted_updates)\n","        # print(\"num_clients\", num_clients)\n","        # print(\"n_attackers\", n_attackers)\n","        # print(\"ret\", ret)\n","        return ret\n","    return torch.mean(sorted_updates, dim=0).to(device)\n","\n","def multi_krum_optimized(local_updates: torch.Tensor):\n","    \"\"\"\n","    Implements a memory-optimized version of the Multi-Krum aggregation rule with explicit deletion of local variables.\n","    Parameters:\n","    - local_updates: A tensor of shape (num_clients, num_params) containing the flattened model updates from each client.\n","    Returns:\n","    - The aggregated model update as a tensor of shape (num_params,).\n","    \"\"\"\n","    num_clients = local_updates.size(0)\n","    byzantine_client_num = int(num_clients * 0.2)  # Assuming 20% are byzantine clients\n","    krum_limit = num_clients - byzantine_client_num - 2\n","\n","    # Instead of computing a full pairwise distance matrix, compute distances incrementally\n","    scores = torch.zeros(num_clients)\n","\n","    for i in range(num_clients):\n","        # Compute the squared L2 distances between client `i` and all other clients\n","        distances = torch.sum((local_updates - local_updates[i]) ** 2, dim=1)\n","\n","        # Sort distances and ignore the first distance (which is 0, i.e., distance to itself)\n","        sorted_distances, _ = torch.sort(distances)\n","\n","        # Sum the smallest `krum_limit` distances (ignore the first one)\n","        scores[i] = torch.sum(sorted_distances[1:krum_limit + 1])\n","\n","        # Explicitly delete large tensors to free memory\n","        del distances, sorted_distances\n","\n","    # Select the indices of the `krum_limit` clients with the lowest scores\n","    selected_indices = torch.topk(-scores, krum_limit, largest=True).indices\n","\n","    # Average the updates of the selected clients\n","    aggregated_update = torch.mean(local_updates[selected_indices], dim=0)\n","\n","    # Clean up memory before returning\n","    del scores, local_updates\n","\n","    return aggregated_update, selected_indices\n","\n","def clip_tensor_norm_(\n","    parameters: Union[torch.Tensor, Iterable[torch.Tensor]],\n","    max_norm: float,\n","    norm_type: float = 2.0,\n","    error_if_nonfinite: bool = False,\n",") -> torch.Tensor:\n","    if isinstance(parameters, torch.Tensor):\n","        parameters = [parameters]\n","\n","    max_norm = float(max_norm)\n","    norm_type = float(norm_type)\n","\n","    if len(parameters) == 0:\n","        return torch.tensor(0.0)\n","\n","    device = parameters[0].device\n","\n","    if norm_type ==  float('inf'):\n","        norms = [p.detach().abs().max().to(device) for p in parameters]\n","        total_norm = norms[0] if len(norms) == 1 else torch.max(torch.stack(norms))\n","    else:\n","        total_norm = torch.norm(\n","            torch.cat(\n","                [\n","                    p.detach().view(-1).to(device)\n","                    for p in parameters\n","                    if p.dtype != torch.int64\n","                ]\n","            ),\n","            norm_type,\n","        )\n","\n","    if error_if_nonfinite and torch.logical_or(total_norm.isnan(), total_norm.isinf()):\n","        raise RuntimeError(\n","            f\"The total norm of order {norm_type} for gradients from \"\n","            \"`parameters` is non-finite, so it cannot be clipped. To disable \"\n","            \"this error and scale the gradients by the non-finite norm anyway, \"\n","            \"set `error_if_nonfinite=False`\"\n","        )\n","\n","    clip_coef = max_norm / (total_norm + 1e-6)\n","    clip_coef_clamped = torch.clamp(clip_coef, max=1.0)\n","\n","    for p in parameters:\n","        if p.dtype != torch.int64:\n","            p.mul_(clip_coef_clamped.to(p.device))\n","\n","def Clippedclustering(updates: torch.Tensor):\n","    tau = 1e5\n","    l2norm_his = []\n","\n","    # Calculate L2 norms in a single operation\n","    l2norms = [torch.norm(update).item() for update in updates]\n","    l2norm_his.extend(l2norms)\n","\n","    threshold = np.median(l2norm_his)\n","    threshold = min(threshold, tau)\n","\n","    # Clip tensor norms above the threshold\n","    for idx, l2 in enumerate(l2norms):\n","        if l2 > threshold:\n","            clip_tensor_norm_(updates[idx], threshold)\n","\n","    num = len(updates)\n","\n","    dis_max = 1 - torch.mm(\n","        updates, updates.t()\n","    ).cpu().numpy()  # Convert to numpy for AgglomerativeClustering\n","\n","    # Handle boundary conditions for distance matrix\n","    dis_max = np.where(np.isinf(dis_max), 2.0, np.where(np.isnan(dis_max), 2.0, dis_max))\n","\n","    # Hierarchical clustering\n","    clustering = AgglomerativeClustering(\n","        metric=\"precomputed\", linkage=\"average\", n_clusters=2\n","    )\n","    clustering.fit(dis_max)\n","\n","    flag = 1 if np.sum(clustering.labels_) > num // 2 else 0\n","    S1_idxs = [idx for idx, label in enumerate(clustering.labels_) if label == flag]\n","\n","    # Vectorized feature extraction\n","    num_para = len(updates[0])\n","    feature0 = (updates > 0).float().mean(dim=1)\n","    feature1 = (updates < 0).float().mean(dim=1)\n","    feature2 = (updates == 0).float().mean(dim=1)\n","\n","    features = torch.stack([feature0, feature1, feature2], dim=1).cpu().numpy()\n","\n","    # KMeans clustering\n","    kmeans = KMeans(n_clusters=2, random_state=0).fit(features)\n","    flag = 1 if np.sum(kmeans.labels_) > num // 2 else 0\n","    S2_idxs = [idx for idx, label in enumerate(kmeans.labels_) if label == flag]\n","\n","    # Select intersection of both clustering methods\n","    selected_idxs = list(set(S1_idxs) & set(S2_idxs))\n","\n","    # Return the mean of selected updates\n","    return torch.mean(updates[selected_idxs], dim=0)\n","\n","def SignGuard(updates):\n","    # updates = updates.cpu()\n","\n","    num = updates.shape[0]\n","    # Compute L2 norms across all dimensions except the first\n","    l2norms = torch.norm(updates, dim=tuple(range(1, updates.ndim)))\n","\n","    # Compute the median using torch.median (stays on GPU)\n","    M = torch.median(l2norms)\n","    L = 0.1\n","    R = 3.0\n","\n","    # Create a mask for S1 indices\n","    mask1 = (l2norms >= L * M) & (l2norms <= R * M)\n","    del l2norms, M  # Delete l2norms and M as they're no longer needed\n","    torch.cuda.empty_cache()\n","\n","    # Flatten updates for feature computation\n","    updates_flat = updates.view(updates.shape[0], -1).cpu()\n","    num_para = updates_flat.size(1)\n","\n","    # Compute features using vectorized operations\n","    positive_counts = (updates_flat > 0).sum(dim=1).float() / num_para\n","    negative_counts = (updates_flat < 0).sum(dim=1).float() / num_para\n","    zero_counts = (updates_flat == 0).sum(dim=1).float() / num_para\n","\n","    features = torch.stack([positive_counts, negative_counts, zero_counts], dim=1).cpu().numpy()\n","    del updates_flat, positive_counts, negative_counts, zero_counts  # Clean up\n","    torch.cuda.empty_cache()\n","\n","    # Perform KMeans clustering\n","    kmeans = KMeans(n_clusters=2, random_state=0).fit(features)\n","    labels = kmeans.labels_\n","    del kmeans, features  # Clean up CPU memory\n","\n","    # Convert labels back to a CUDA tensor\n","    labels = torch.from_numpy(labels).to(device)\n","\n","    # Determine the majority cluster\n","    flag = 1 if labels.sum() > num // 2 else 0\n","\n","    # Create a mask for S2 indices\n","    mask2 = (labels == flag)\n","    del labels  # Delete labels as it's no longer needed\n","    torch.cuda.empty_cache()\n","\n","    # Intersection of S1 and S2 indices\n","    inter_mask = mask1 & mask2\n","    del mask1, mask2  # Clean up masks\n","    torch.cuda.empty_cache()\n","\n","    # Select the updates based on the intersection mask\n","    selected_updates = updates[inter_mask]\n","    del updates, inter_mask  # Delete updates and inter_mask\n","    torch.cuda.empty_cache()\n","\n","    # Compute and return the mean of the selected updates\n","    result = torch.mean(selected_updates, dim=0)\n","    del selected_updates  # Clean up selected_updates\n","    torch.cuda.empty_cache()\n","\n","    return result.to(device)\n","\n","\n","\n","##########################\n","# FLTrust aggregator\n","##########################\n","def FLTrust(global_model_data: torch.Tensor,\n","            local_params_all: torch.Tensor,\n","            server_params: torch.Tensor) -> torch.Tensor:\n","    \"\"\"\n","    Option B approach:\n","      - global_model_data: the old global param vector (1D).\n","      - local_params_all: shape (num_clients, num_params), each row is the\n","        final parameter vector from that client.\n","      - server_params: the final parameter vector from the server's root model training.\n","    Returns:\n","      aggregated_diff: The aggregated difference vector to add to global_model_data.\n","    \"\"\"\n","\n","    # 1) Convert each client's final param to difference from old global\n","    #    local_updates[i] = local_params[i] - old_global_model\n","    client_updates = local_params_all - global_model_data\n","\n","    # 2) Server anchor update = server_params - old global model\n","    anchor_update = server_params - global_model_data\n","\n","    # 3) Trust score = ReLU(cosine_similarity)\n","    TS = F.relu(F.cosine_similarity(client_updates, anchor_update.unsqueeze(0), dim=1))\n","    sum_ts = TS.sum()\n","    if sum_ts == 0:\n","        # Fallback: average the client updates\n","        return torch.mean(client_updates, dim=0)\n","\n","    TS /= sum_ts\n","\n","    # 4) Magnitude normalization\n","    client_norms = torch.norm(client_updates, dim=1, keepdim=True)\n","    anchor_norm = torch.norm(anchor_update)\n","    client_norms[client_norms == 0] = 1e-9\n","\n","    normed_updates = client_updates / client_norms * anchor_norm\n","\n","    # 5) Weighted sum\n","    agg_update = (normed_updates * TS.unsqueeze(1)).sum(dim=0)\n","    return agg_update\n","\n","\n","import numpy as np\n","import torch\n","import sklearn.metrics.pairwise as smp\n","import hdbscan\n","\n","def flame(\n","    local_updates: torch.Tensor,\n","    global_model: torch.nn.Module,\n","    device: torch.device,\n","    num_clients: int,\n","    lamda: float = 0.001\n",") -> torch.Tensor:\n","    \"\"\"\n","    FLAME aggregator function, closely matching the design in\n","    the FLAME paper (Nguyen et al., USENIX Security 2022).\n","\n","    Steps:\n","      1) Convert local updates to float64 and compute pairwise cosine distances.\n","      2) HDBSCAN with min_cluster_size = (num_clients//2 + 1).\n","      3) If largest cluster < 0.5 * num_clients, fallback => treat all as benign.\n","      4) Norm-clipping using median of all update norms as clip_value.\n","      5) Average those clipped, \"benign\" updates => aggregated_update.\n","      6) Add random Gaussian noise: lamda * clip_value => final aggregator.\n","\n","    Args:\n","      local_updates: (num_clients, param_dim) float32 PyTorch tensor\n","      global_model: current global model (unused here, but included for consistency)\n","      device: the GPU/CPU device\n","      num_clients: number of local updates\n","      lamda: scaling factor for the noise\n","\n","    Returns:\n","      aggregated_update: shape (param_dim,) final aggregator vector\n","    \"\"\"\n","\n","    # 1) Convert local updates to double precision (float64) for HDBSCAN\n","    updates_np = local_updates.cpu().numpy().astype(np.float64)\n","\n","    # 2) Compute pairwise cosine distances => shape (num_clients, num_clients)\n","    cd = smp.cosine_distances(updates_np)  # float64 now\n","\n","    # HDBSCAN with min_cluster_size ~ majority\n","    min_cluster = max(2, (num_clients // 2) + 1)\n","    clusterer = hdbscan.HDBSCAN(\n","        min_cluster_size=min_cluster,\n","        min_samples=1,\n","        allow_single_cluster=True,\n","        metric='precomputed'\n","    ).fit(cd)\n","\n","    cluster_labels = clusterer.labels_  # array of size num_clients\n","    print(\"cluster_labels =\", cluster_labels)\n","    print(\"Number of outliers =\", np.sum(cluster_labels == -1))\n","\n","    # 3) Identify largest cluster; if all outliers => treat all as benign\n","    if cluster_labels.max() < 0:\n","        # all outliers => fallback\n","        benign_ids = list(range(num_clients))\n","    else:\n","        # find the largest cluster\n","        max_cluster_index = None\n","        max_cluster_size  = 0\n","        for cl_idx in range(cluster_labels.max() + 1):\n","            size_cl = np.sum(cluster_labels == cl_idx)\n","            if size_cl > max_cluster_size:\n","                max_cluster_size = size_cl\n","                max_cluster_index = cl_idx\n","\n","        # pick all that belong to that cluster\n","        benign_ids = [i for i in range(num_clients) if cluster_labels[i] == max_cluster_index]\n","\n","        # fallback if the largest cluster is too small\n","        if max_cluster_size < 0.5 * num_clients:\n","            print(\"FLAME fallback: largest cluster < 50%, treat all as benign.\")\n","            benign_ids = list(range(num_clients))\n","\n","    # 4) Norm-clipping\n","    # compute the L2 norms of all client updates, get the median\n","    norms = torch.norm(local_updates, p=2, dim=1)  # shape (num_clients,)\n","    norms_np = norms.cpu().numpy()\n","    clip_value = np.median(norms_np)\n","    print(f\"clip_value (median norm) = {clip_value:.4f}\")\n","\n","    accepted_updates = []\n","    for i in benign_ids:\n","        if norms_np[i] > clip_value:\n","            scale = clip_value / norms_np[i]\n","            clipped_vec = local_updates[i] * scale\n","        else:\n","            clipped_vec = local_updates[i]\n","        accepted_updates.append(clipped_vec.unsqueeze(0))\n","\n","    # 5) Merge (average) clipped updates or fallback to average all\n","    if len(accepted_updates) == 0:\n","        # if we ended up with zero accepted => fallback\n","        print(\"FLAME fallback: no accepted updates => average all.\")\n","        aggregated_update = torch.mean(local_updates, dim=0)\n","    else:\n","        merged_tensor = torch.cat(accepted_updates, dim=0)\n","        aggregated_update = merged_tensor.mean(dim=0)\n","\n","    # 6) Add noise: lamda * clip_value\n","    # if clip_value > 0.0:\n","    #     noise_std = lamda * clip_value\n","    #     noise = torch.normal(\n","    #         mean=0.0, std=noise_std,\n","    #         size=aggregated_update.shape,\n","    #         device=device\n","    #     )\n","    #     aggregated_update = aggregated_update + noise\n","    # else:\n","    #     print(\"FLAME note: clip_value = 0 => no noise added.\")\n","\n","    return aggregated_update\n","\n","\n","\n","from scipy.fftpack import dct\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def freqfed_aggregator(\n","    local_updates: torch.Tensor,\n","    min_cluster_size: int = None,\n","    filter_fraction: float = 0.5\n",") -> torch.Tensor:\n","    \"\"\"\n","    FreqFed Aggregation Function\n","\n","    Args:\n","      local_updates: shape (num_clients, param_dim) – each row is a flattened model update from a client.\n","      device: the GPU/CPU device.\n","      min_cluster_size: minimum cluster size used in HDBSCAN.\n","         By default = None => we set it to (num_clients // 2 + 1) as recommended in the paper.\n","      filter_fraction: fraction of DCT-coeffs we keep, from the low-frequency portion. 0.5 => keep half.\n","\n","    Returns:\n","      aggregated_update: shape (param_dim,) the final aggregator vector from the largest cluster.\n","    \"\"\"\n","    num_clients = local_updates.size(0)\n","    # 1) If min_cluster_size not specified, set to at least half the clients + 1\n","    if min_cluster_size is None:\n","        min_cluster_size = max(2, (num_clients // 2) + 1)\n","\n","    # Convert local updates to CPU numpy for processing\n","    updates_np = local_updates.detach().cpu().numpy()  # shape: (num_clients, param_dim)\n","\n","    # 2) For each local update, do 1D DCT, then keep low-frequency portion\n","    F_list = []\n","    for i in range(num_clients):\n","        # local_params is shape (param_dim,). DCT needs a 1D array\n","        param_1d = updates_np[i]   # shape (param_dim,)\n","        dct_1d   = dct(param_1d, norm='ortho')   # 1D DCT\n","\n","        # filtering: keep only the first \"filter_length\" coefficients\n","        filter_length = int(len(dct_1d) * filter_fraction)\n","        if filter_length < 1:\n","            filter_length = 1\n","        filtered = dct_1d[:filter_length]\n","\n","        F_list.append(filtered)\n","\n","    # 3) Build a distance matrix = 1 - cos sim in the filtered space\n","    #   shape => (num_clients, num_clients)\n","    K = len(F_list)\n","    dist_matrix = np.zeros((K, K), dtype=np.float64)\n","    for i in range(K):\n","        for j in range(i + 1, K):\n","            # Cos sim in 1D\n","            csim = cosine_similarity(F_list[i].reshape(1, -1),\n","                                     F_list[j].reshape(1, -1))[0][0]\n","            dist = 1.0 - csim\n","            dist_matrix[i, j] = dist\n","            dist_matrix[j, i] = dist\n","\n","    # 4) HDBSCAN clustering, metric=precomputed\n","    clusterer = hdbscan.HDBSCAN(\n","        min_cluster_size=min_cluster_size,\n","        min_samples=1,\n","        metric='precomputed',\n","        allow_single_cluster=True\n","    )\n","    cluster_labels = clusterer.fit_predict(dist_matrix)\n","\n","    # optional debugging\n","    print(\"[FreqFed] cluster_labels =\", cluster_labels)\n","    outliers = np.sum(cluster_labels == -1)\n","    print(\"[FreqFed] Number of outliers =\", outliers)\n","\n","    # 5) Find the largest cluster. If all are outliers => fallback to all\n","    if cluster_labels.max() < 0:\n","        # means all are -1 => fallback\n","        benign_ids = list(range(num_clients))\n","    else:\n","        # find cluster with the most points\n","        unique_clusters, counts = np.unique(cluster_labels, return_counts=True)\n","        # cluster -1 is outliers, ignore them for largest\n","        best_label = None\n","        best_count = 0\n","        for lbl, cnt in zip(unique_clusters, counts):\n","            if lbl == -1:\n","                continue\n","            if cnt > best_count:\n","                best_label = lbl\n","                best_count = cnt\n","\n","        # if everything except outliers is too small => fallback\n","        if best_count < 1:\n","            benign_ids = list(range(num_clients))\n","        else:\n","            # pick largest cluster\n","            benign_ids = [i for i in range(num_clients) if cluster_labels[i] == best_label]\n","\n","    # 6) Average all local_updates in the largest cluster\n","    #   If the cluster is empty => fallback to all\n","    if len(benign_ids) == 0:\n","        print(\"[FreqFed] fallback: empty largest cluster => average all updates.\")\n","        benign_ids = range(num_clients)\n","\n","    # gather them\n","    accepted = local_updates[benign_ids, :]  # shape => (#accepted, param_dim)\n","    aggregated_update = accepted.mean(dim=0) # shape => (param_dim,)\n","\n","    return aggregated_update.to(device)\n","\n","# import torch\n","# import cupy as cp\n","# import numpy as np\n","\n","# # We'll import the GPU-based HDBSCAN from cuML\n","# # (NOT the CPU-based hdbscan from the standard library.)\n","# from cuml.cluster import HDBSCAN as cuHDBSCAN\n","\n","# def flame_cuml(\n","#     local_updates: torch.Tensor,\n","#     device: torch.device,\n","#     num_clients: int,\n","#     lamda: float = 0.001\n","# ) -> torch.Tensor:\n","#     \"\"\"\n","#     FLAME aggregator with GPU usage, including:\n","#       - Compute pairwise distances in PyTorch on GPU\n","#       - Convert to cupy array\n","#       - Use cuML’s GPU-based HDBSCAN\n","#       - Then do fallback, clipping, and noise injection on GPU\n","\n","#     Steps:\n","#       1) local_updates is on GPU\n","#       2) compute GPU-based cosine similarity => distance matrix\n","#       3) run cuML HDBSCAN with min_cluster_size=(num_clients//2 + 1)\n","#       4) fallback if largest cluster is < 50% or if all outliers\n","#       5) median-based norm clipping on GPU\n","#       6) average & add noise\n","#     \"\"\"\n","\n","#     # local_updates shape: (num_clients, param_dim), on device=GPU\n","#     # 1) Ensure local_updates is on GPU\n","#     local_updates = local_updates.to(device)\n","\n","#     # 2) Compute pairwise cosine distance in PyTorch on GPU\n","#     #    a) normalize each row\n","#     normed = torch.nn.functional.normalize(local_updates, p=2, dim=1)\n","#     #    b) cos sim = normed @ normed.T\n","#     sim = normed @ normed.t()\n","#     #    c) dist = 1 - sim\n","#     dist_mat = 1.0 - sim\n","#     # dist_mat is shape (n, n), on GPU\n","\n","#     # 2b) Convert dist_mat to a cuML-friendly CuPy array (float32 or float64)\n","#     # If you want float64, we can cast. Typically float32 might suffice.\n","#     dist_mat_cupy = cp.asarray(dist_mat.detach().cpu().numpy(), dtype=cp.float32)\n","#     # ^ Unfortunately, we do an intermediate .cpu().numpy() because\n","#     #   PyTorch -> CuPy direct conversion is not always trivial.\n","#     #   If you want a direct approach, you can do dist_mat_contig = dist_mat.contiguous()\n","#     #   Then memory pointer bridging. But the simplest is .cpu().numpy() => cp.asarray.\n","\n","#     # 3) HDBSCAN on GPU\n","#     min_cluster = max(2, (num_clients // 2) + 1)\n","#     clusterer = cuHDBSCAN(\n","#         min_cluster_size=min_cluster,\n","#         min_samples=1,\n","#         metric='precomputed',\n","#         allow_single_cluster=True\n","#     )\n","#     # Fit\n","#     cluster_labels_cupy = clusterer.fit_predict(dist_mat_cupy)\n","#     # cluster_labels_cupy is a cupy array of shape (n,). Let's bring it back to CPU\n","#     cluster_labels = cluster_labels_cupy.get()  # shape (n,) in numpy\n","\n","#     # Print debug\n","#     print(\"cluster_labels =\", cluster_labels)\n","#     outliers_count = np.sum(cluster_labels == -1)\n","#     print(\"Number of outliers =\", outliers_count)\n","\n","#     # 4) Identify the largest cluster (unless all outliers => fallback)\n","#     if cluster_labels.max() < 0:\n","#         # all outliers => fallback => treat all as benign\n","#         benign_ids = list(range(num_clients))\n","#     else:\n","#         # find cluster with the most elements\n","#         max_cluster_index = None\n","#         max_cluster_size  = 0\n","#         for cl_idx in range(cluster_labels.max() + 1):\n","#             size_cl = np.sum(cluster_labels == cl_idx)\n","#             if size_cl > max_cluster_size:\n","#                 max_cluster_size = size_cl\n","#                 max_cluster_index = cl_idx\n","\n","#         # pick all that belong to that cluster\n","#         benign_ids = [i for i in range(num_clients) if cluster_labels[i] == max_cluster_index]\n","\n","#         # fallback if largest cluster is < 50%\n","#         if max_cluster_size < 0.5 * num_clients:\n","#             print(\"FLAME fallback: largest cluster < 50%, treat all as benign.\")\n","#             benign_ids = list(range(num_clients))\n","\n","#     # 5) Norm-clipping\n","#     # compute L2 norms in GPU\n","#     norms = torch.norm(local_updates, p=2, dim=1)  # shape (n,)\n","#     clip_value = norms.median()  # GPU median in newer PyTorch versions\n","\n","#     # For older PyTorch, you might do norms.cpu().median().to(device)\n","#     # We'll assume you can do it fully on GPU if version >=1.7\n","\n","#     print(f\"clip_value (median norm) = {clip_value.item():.4f}\")\n","\n","#     accepted_updates = []\n","#     norms_cpu = norms.detach().cpu().numpy()\n","#     # We do scale on GPU:\n","#     for i in benign_ids:\n","#         # i-th row => local_updates[i]\n","#         # if norms[i] > clip_value => scale\n","#         if norms_cpu[i] > clip_value.item():\n","#             scale = clip_value.item() / norms_cpu[i]\n","#             clipped_vec = local_updates[i] * scale\n","#         else:\n","#             clipped_vec = local_updates[i]\n","#         accepted_updates.append(clipped_vec.unsqueeze(0))\n","\n","#     if len(accepted_updates) == 0:\n","#         print(\"FLAME fallback: no accepted updates => average all.\")\n","#         # just average everything\n","#         aggregated_update = torch.mean(local_updates, dim=0)\n","#     else:\n","#         merged_tensor = torch.cat(accepted_updates, dim=0)  # shape (k, param_dim)\n","#         aggregated_update = merged_tensor.mean(dim=0)\n","\n","#     # 6) Add noise => lamda * clip_value\n","#     # If you want the paper's DP bound exactly, you can set\n","#     # lamda = (1/eps)*math.sqrt(2*math.log(1.25/delta)).\n","#     if clip_value.item() > 0.0:\n","#         noise_std = lamda * clip_value.item()\n","#         noise = torch.normal(mean=0.0, std=noise_std, size=aggregated_update.shape, device=device)\n","#         aggregated_update = aggregated_update + noise\n","#     else:\n","#         print(\"FLAME note: clip_value=0 => no noise added.\")\n","\n","#     return aggregated_update\n","\n","\n","def dnc_aggregator(local_updates: torch.Tensor,\n","                   num_clients: int,\n","                   num_adv: int,\n","                   subsample_frac: float = 0.2,\n","                   num_iters: int = 5,\n","                   fliter_frac: float = 1.0) -> torch.Tensor:\n","    \"\"\"\n","    DNC aggregator logic:\n","      1) local_updates: shape (num_clients, num_params)\n","      2) Repeats num_iters times:\n","         a) randomly subsample 'subsample_frac' portion of parameters\n","         b) center them => (updates - mean)\n","         c) SVD => top singular vector => outlier scores\n","         d) keep the k smallest => intersection across iterations\n","      3) Average the final chosen updates\n","      4) returns (param_dim,) aggregated vector\n","    \"\"\"\n","    device = local_updates.device\n","    # Convert to CPU numpy for easy SVD, or do it in Torch on GPU – up to you:\n","    # For simplicity, we'll do a .cpu().numpy() approach\n","    updates_np = local_updates.cpu().numpy()\n","    num_param = updates_np.shape[1]\n","\n","    # Start with all clients => we refine by intersection\n","    benign_idx = set(range(num_clients))\n","\n","    # number of clients to keep each iteration => #clients - (fliter_frac * #adv)\n","    # if fliter_frac=1.0 and num_adv=10 => we remove 10 => keep (num_clients - 10)\n","    k_keep = int(num_clients - fliter_frac * num_adv)\n","    # if that yields <=0, we keep all\n","    if k_keep <= 0:\n","        k_keep = num_clients\n","\n","    for _ in range(num_iters):\n","        # 1) Subsample fraction of parameters\n","        param_count = int(subsample_frac * num_param)\n","        if param_count <= 0:\n","            # fallback: if param_count <=0 => skip\n","            break\n","        param_idx = np.random.choice(np.arange(num_param),\n","                                     param_count,\n","                                     replace=False)\n","        # shape: (num_clients, param_count)\n","        sampled = updates_np[:, param_idx]\n","\n","        # 2) center\n","        mu = np.mean(sampled, axis=0)\n","        centered = sampled - mu  # shape (num_clients, param_count)\n","\n","        # 3) SVD => top right singular vector\n","        #   np.linalg.svd => (U, S, V) with shape(U)=(C,C), shape(V)=(P,P) if full_matrices\n","        #   but we do full_matrices=False => shape(V)=(rank, param_count)\n","        U, S, V = np.linalg.svd(centered, full_matrices=False)\n","        top_vector = V[0]  # shape (param_count,)\n","\n","        # 4) outlier scores => dot(centered, top_vector)**2\n","        scores = np.dot(centered, top_vector)**2  # shape (num_clients,)\n","\n","        # now we pick the k_keep smallest\n","        if k_keep < len(scores):\n","            # partial sort\n","            chosen = np.argpartition(scores, k_keep)[:k_keep]\n","        else:\n","            chosen = np.arange(len(scores))\n","\n","        # intersect with existing benign\n","        benign_idx = benign_idx.intersection(set(chosen))\n","\n","    # after all iterations, we average only the final benign\n","    if len(benign_idx) == 0:\n","        # fallback => if none remain, just do naive average\n","        aggregator = torch.mean(local_updates, dim=0)\n","    else:\n","        # gather\n","        chosen_arr = local_updates[list(benign_idx)]\n","        aggregator = torch.mean(chosen_arr, dim=0)\n","\n","    return aggregator.to(device)\n","\n","\n","def dnc_aggregator_torch(\n","    local_updates: torch.Tensor,\n","    num_clients: int,\n","    subsample_frac: float = 0.2,\n","    num_iters: int = 5\n",") -> torch.Tensor:\n","    \"\"\"\n","    DNC aggregator, all in Torch on GPU if local_updates is on GPU.\n","\n","    local_updates: shape (num_clients, param_dim), already on the same device\n","    num_clients: total number of clients\n","    num_adv: known or estimated number of attackers\n","    subsample_frac: fraction of parameters to subsample\n","    num_iters: how many repeated outlier computations\n","    fliter_frac: fraction of adversaries to remove each iteration\n","\n","    returns: aggregated vector shape (param_dim,)\n","    \"\"\"\n","\n","    device = local_updates.device\n","    c, p = local_updates.shape\n","\n","    # The maximum # of \"bad\" updates to remove is fliter_frac * num_adv\n","    # => we keep k = num_clients - that many\n","    # k_keep = int(num_clients - fliter_frac * num_adv)\n","    k_keep = int(num_clients * 0.81)\n","    if k_keep <= 0:\n","        k_keep = num_clients  # fallback: keep them all\n","\n","    # We'll keep a boolean mask of shape (num_clients,)\n","    # True means \"still in the candidate benign set\"\n","    keep_mask = torch.ones(c, dtype=torch.bool, device=device)\n","\n","    for _ in range(num_iters):\n","        # 1) Subsample fraction of parameters\n","        param_count = int(subsample_frac * p)\n","        if param_count <= 0:\n","            break\n","        # pick param_count distinct indices\n","        # NB: torch.randperm is typically on CPU, but we can do it on device if needed\n","        # However, for smaller param_count, CPU overhead might be negligible\n","        chosen_params = torch.randperm(p, device=device)[:param_count]\n","\n","        # shape => (C, param_count)\n","        # but we only gather the ones that are still \"keep_mask\"?\n","        # The DnC paper's code basically does the outlier scoring over *all* clients each iteration,\n","        # then intersects. Alternatively, we can keep it the same to be faithful to the paper:\n","        # i.e., we always compute outlier score for all clients, not just the \"kept\" ones from last iteration.\n","        # Then we do intersection. We'll follow that approach:\n","\n","        sub_updates = local_updates[:, chosen_params]\n","\n","        # 2) center\n","        # mean over the *rows* => shape (param_count,)\n","        mu = sub_updates.mean(dim=0)\n","        centered = sub_updates - mu  # shape => (C, param_count)\n","\n","        # 3) SVD => top right singular vector\n","        # shape => U: (C, rank), S: (rank,), V: (param_count, rank) if full_matrices=False\n","        # Actually torch.linalg.svd outputs (U, S, Vh) where Vh is of shape (p, p) for full_matrices=False\n","        # or (p, rank). So top_vector => Vh[0,:] is row 0 of V^T => that means top row => top eigenvector\n","        # in the dimension param_count\n","        U, S, Vh = torch.linalg.svd(centered, full_matrices=False)\n","        # top singular vector is Vh[0], shape => (param_count,)\n","        top_vector = Vh[0, :]\n","\n","        # 4) outlier scores => dot(centered[i], top_vector)^2\n","        # => (C,)\n","        # We can do (centered @ top_vector).pow(2)\n","        # shape => (C,)\n","        dot_vals = torch.matmul(centered, top_vector)\n","        scores = dot_vals.pow(2)\n","\n","        # 5) find k_keep smallest scores among all clients\n","        # topk => \"largest\" by default. We want \"smallest\", so largest=False\n","        # topk returns (values, indices)\n","        if k_keep < c:\n","            # we want k_keep smallest => topk w/ largest=False\n","            val, idx = torch.topk(scores, k_keep, largest=False)\n","        else:\n","            # if k_keep >= c => keep all\n","            idx = torch.arange(c, device=device)\n","\n","        # Now we have the set of \"lowest outlier\" clients for this iteration: idx\n","        # We do an intersection with keep_mask from previous iteration\n","        # We'll create a boolean mask new_mask => shape (C,) => True for those in idx\n","        new_mask = torch.zeros(c, dtype=torch.bool, device=device)\n","        new_mask[idx] = True\n","\n","        # intersection: we keep only those that were in keep_mask & in new_mask\n","        keep_mask = keep_mask & new_mask\n","\n","        # If keep_mask is all false => we can break early if we want\n","        # but let's just continue\n","\n","    # after all iterations, \"keep_mask\" is the final benign set\n","    final_keep_count = keep_mask.sum().item()\n","    if final_keep_count == 0:\n","        # fallback => if none remain, do naive average\n","        aggregator = local_updates.mean(dim=0)\n","    else:\n","        aggregator = local_updates[keep_mask, :].mean(dim=0)\n","\n","    return aggregator\n"]},{"cell_type":"markdown","metadata":{"id":"WgmZW6tziyz6"},"source":["Attacks (XFED)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1744700145334,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"6ZFitOiQi5uH"},"outputs":[],"source":["def get_mu_pairwise_distance(global_models, MU_MULTIPLIER):\n","    \"\"\"Compute pairwise distance based deviation (mu).\"\"\"\n","    num_models = len(global_models)\n","    # print(\"num_models\", num_models)\n","    # print(\"global_models\", global_models)\n","    if num_models > 1:\n","        if isinstance(global_models, list):\n","            global_models_tensor = torch.vstack(global_models)\n","        else:\n","            global_models_tensor = global_models\n","        # Step 1: Calculate the centroid (mean vector)\n","        centroid = torch.mean(global_models_tensor, dim=0)\n","        # Step 2: Compute the Euclidean distance of each vector from the centroid\n","        # Step 3: Calculate the standard deviation of the distances\n","        distances = torch.norm(global_models_tensor - centroid, dim=1)\n","        std_dev = torch.sqrt(torch.dot(distances, distances) / num_models)\n","        mu = MU_MULTIPLIER * std_dev\n","        return mu\n","    else:\n","        return torch.tensor(0.0)\n","\n","def xfed_c(user_grads, n_attackers, dev_type, len_global, global_model_data, global_models, collab):\n","    if collab == 0:\n","        all_updates = user_grads[:n_attackers]\n","        start_idx = 0\n","    else:\n","        individual_attackers = n_attackers - collab\n","        all_updates = user_grads[individual_attackers:n_attackers]\n","        start_idx = individual_attackers\n","\n","    model_re = torch.mean(all_updates, dim=0).to(device)\n","\n","    if dev_type == 'C_XFED_unit_vec' or dev_type == 'Hybrid_XFED_unit_vec':\n","        deviation = model_re / torch.norm(model_re)\n","    elif dev_type == 'C_XFED_sign' or dev_type == 'Hybrid_XFED_sign':\n","        sgn_vec = torch.sign(model_re)\n","        deviation = sgn_vec / torch.norm(sgn_vec)\n","    elif dev_type == 'C_XFED_std':\n","        deviation = torch.std(all_updates, dim=0)\n","\n","    if len_global > 1:\n","        # print(torch.norm(model_re - global_model_data), get_mu_pairwise_distance(global_models, 3), get_mu_pairwise_distance(all_updates, 1))\n","        # mu = torch.max(torch.norm(model_re - global_model_data), get_mu_pairwise_distance(global_models))\n","        # mu = torch.max(torch.norm(model_re - global_model_data), get_mu_pairwise_distance(all_updates))\n","        mu = get_mu_pairwise_distance(all_updates, 3)\n","    else:\n","        mu = torch.tensor(1.0)\n","\n","     # Calculate delta and malicious updates\n","    deviation *= mu\n","    mal_update = (model_re - deviation)\n","\n","    del model_re, deviation\n","    torch.cuda.empty_cache()\n","\n","\n","    for i in range(start_idx, n_attackers):\n","        tmp = user_grads[i]\n","        user_grads[i] = mal_update\n","        del tmp\n","        torch.cuda.empty_cache()\n","\n","    return user_grads\n","\n","    # Create the final stacked tensor of updates\n","    # Combine the malicious updates with the rest of the user_grads\n","    # mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","    # return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dw82zh_Zjslf"},"source":["Attacks( VIRAT, FANG-TR-MEAN, FANG-KRUM, LIE)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1744700145355,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"ynbQi9pnjy-G"},"outputs":[],"source":["\n","def virat_min_max(user_grads, n_attackers, dev_type='VIRAT_unit_vec', epoch = 0, threshold=50):\n","    \"\"\"Implement VIRAT Min-Max attack.\"\"\"\n","    all_updates = user_grads[:n_attackers].to(device)\n","    model_re = torch.mean(all_updates, dim=0).to(device)\n","\n","    if dev_type == 'VIRAT_unit_vec':\n","        deviation = model_re / torch.norm(model_re)\n","    elif dev_type == 'VIRAT_sign':\n","        deviation = torch.sign(model_re)\n","    elif dev_type == 'VIRAT_std':\n","        deviation = torch.std(all_updates, dim=0)\n","    else:\n","        raise ValueError(f\"Unknown deviation type: {dev_type}\")\n","\n","    lamda = torch.tensor([threshold], dtype=torch.float).to(device)\n","    threshold_diff = 1e-5\n","    lamda_fail = lamda.clone()\n","    lamda_succ = torch.tensor(0, dtype=torch.float).to(device)\n","\n","    distances = []\n","    for update in all_updates:\n","        distance = torch.norm((all_updates - update), dim=1) ** 2\n","        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n","\n","    max_distance = torch.max(distances)\n","    del distances\n","\n","    while torch.abs(lamda_succ - lamda) > threshold_diff:\n","        mal_update = model_re - lamda * deviation\n","        distance = torch.norm(all_updates - mal_update, dim=1) ** 2\n","        max_d = torch.max(distance)\n","\n","        if max_d <= max_distance:\n","            lamda_succ = lamda.clone()\n","            lamda += lamda_fail / 2\n","        else:\n","            lamda -= lamda_fail / 2\n","\n","        lamda_fail /= 2\n","    print(f\"For round {epoch}, max_distance\", max_distance, \"lamda_succ\", lamda_succ)\n","    mal_update = (model_re - lamda_succ * deviation) #.to('cpu')\n","    mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","    return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n","\n","def fang_attack_trmean_partial(user_grads, n_attackers):\n","\n","    all_updates = user_grads[:n_attackers]\n","    model_re = torch.mean(all_updates, 0)\n","    model_std = torch.std(all_updates, 0)\n","    deviation = torch.sign(model_re)\n","\n","    max_vector_low = model_re + 3 * model_std\n","    max_vector_hig = model_re + 4 * model_std\n","    min_vector_low = model_re - 4 * model_std\n","    min_vector_hig = model_re - 3 * model_std\n","\n","    max_range = torch.cat((max_vector_low[:,None], max_vector_hig[:,None]), dim=1)\n","    min_range = torch.cat((min_vector_low[:,None], min_vector_hig[:,None]), dim=1)\n","\n","    rand = torch.from_numpy(np.random.uniform(0, 1, [len(deviation), n_attackers])).type(torch.FloatTensor).to(device)\n","\n","    max_rand = torch.stack([max_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([max_range[:, 1] - max_range[:, 0]] * rand.shape[1]).T\n","    min_rand = torch.stack([min_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([min_range[:, 1] - min_range[:, 0]] * rand.shape[1]).T\n","\n","    deviation_sign = (deviation > 0).type(torch.FloatTensor).to(device)\n","\n","    mal_update = (torch.stack([deviation_sign] * max_rand.shape[1]).T * max_rand + torch.stack(\n","        [deviation_sign] * min_rand.shape[1]).T * min_rand).T\n","\n","    return torch.cat((mal_update, user_grads[n_attackers:]), dim=0)\n","\n","def compute_lambda_fang(all_updates, model_re, n_attackers):\n","    distances = []\n","    n_benign, d = all_updates.shape\n","    for update in all_updates:\n","        distance = torch.norm((all_updates - update), dim=1)\n","        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n","\n","    distances[distances == 0] = 10000\n","    distances = torch.sort(distances, dim=1)[0]\n","    scores = torch.sum(distances[:, :n_benign - 2 - n_attackers], dim=1)\n","    min_score = torch.min(scores)\n","    term_1 = min_score / ((n_benign - n_attackers - 1) * torch.sqrt(torch.Tensor([d]))[0])\n","    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n","\n","    return (term_1 + max_wre_dist)\n","\n","def get_malicious_updates_fang(all_updates, model_re, deviation, n_attackers):\n","\n","    lamda = 100 # compute_lambda_fang(all_updates, model_re, n_attackers)\n","    threshold = torch.tensor(1e-5)\n","\n","    mal_updates = []\n","    while lamda > threshold:\n","        mal_update = (model_re - lamda * deviation)\n","\n","        mal_updates = torch.stack([mal_update] * n_attackers)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","        mal_updates = torch.cat((mal_updates, all_updates), 0)\n","\n","        _, selected_indices = multi_krum_optimized(mal_updates)\n","        # print(f'len {len(mal_updates)}, lamda {lamda}, indices {selected_indices}')\n","\n","        if torch.any(selected_indices < n_attackers):\n","            return mal_update\n","\n","        lamda *= 0.5\n","\n","    if not len(mal_updates):\n","        print(lamda, threshold)\n","        mal_update = (model_re - lamda * deviation)\n","    return mal_update\n","\n","def lie_attack(user_grads, n_attackers, z):\n","\n","    # Stack the gradients for the attackers\n","    all_updates = user_grads[:n_attackers]\n","\n","    # Calculate mean and standard deviation of the attacker's updates\n","    avg = torch.mean(all_updates, dim=0)\n","    std = torch.std(all_updates, dim=0)\n","\n","    # Generate malicious updates\n","    mal_update = avg + z * std\n","\n","    mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","    return torch.cat((mal_updates, user_grads[n_attackers:]), dim=0)\n"]},{"cell_type":"markdown","metadata":{"id":"_pUsLI-nkkTK"},"source":["Code for calculating Z value"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1744700145391,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"_gUO5IWDkp0n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c00b8bb8-b9d2-4fa3-858d-d5c84a35932e"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7\n"]}],"source":["z_values={(50,3):0.69847, (50,5):0.7054, (50,8):0.71904, (50,10):0.72575, (50,12):0.73891, (100,20):0.72907, (40, 8): 0.72575, (100,5):0.69497, (100,10):0.7054, (100,15):0.71566, (100,25):0.74215, (100, 30):0.75804}\n","# z value calculation code to execute lie attack\n","import math\n","# Update the value of m to 10\n","n=100\n","m = 30\n","\n","# Recalculate s and z\n","s = math.floor(n / 2 + 1) - m\n","z = (n - m - s) / (n - m)\n","print(z)"]},{"cell_type":"markdown","metadata":{"id":"AfA9uC4lkvAv"},"source":["Federated Learning Training"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1744700145461,"user":{"displayName":"Israt Mouri","userId":"17729180794010364471"},"user_tz":-360},"id":"zXWWAdggktr4"},"outputs":[],"source":["def train_server_model(global_model, root_data, batch_size, criterion, device, optim):\n","    \"\"\"\n","    Train the server on the trusted root dataset (100 samples) each round.\n","    This is required for FLTrust to generate an anchor update.\n","\n","    Arguments:\n","    - global_model: Current global model\n","    - root_data: Trusted root dataset\n","    - batch_size: Batch size for training\n","    - criterion: Loss function (e.g., CrossEntropyLoss)\n","    - device: GPU/CPU device\n","    - optim: Optimizer type ('SGD' or 'Adam')\n","\n","    Returns:\n","    - server_params: Final parameter vector after training\n","    \"\"\"\n","\n","    # Copy the current global model (server starts from this)\n","    server_model = deepcopy(global_model).to(device)\n","\n","    # Select an optimizer for training\n","    if optim == 'SGD':\n","        server_optimizer = torch.optim.SGD(server_model.parameters(), lr=0.5, momentum=0.9)\n","    else:\n","        server_optimizer = torch.optim.Adam(server_model.parameters(), lr=0.001)\n","\n","    # Load root dataset into DataLoader\n","    root_loader = DataLoader(root_data, batch_size=batch_size, shuffle=True, num_workers=0)\n","\n","    # Train server model on root dataset (single iteration or full epoch)\n","    for inputs, targets in root_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        server_optimizer.zero_grad()\n","        outputs = server_model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(server_model.parameters(), max_norm=1.0)\n","        server_optimizer.step()\n","        break  # Only train for 1 pass (FLTrust paper suggests a single iteration)\n","\n","    # Convert trained server model to a 1D parameter vector\n","    server_params = torch.cat([p.data.view(-1) for p in server_model.parameters()])\n","\n","    # Cleanup to free memory\n","    del server_model, root_loader\n","    torch.cuda.empty_cache()\n","\n","    return server_params\n","\n","\n","def train_local_model(client_id, client_indices, global_model, train_data, batch_size, criterion, device, optimizer):\n","    sampled_indices = random.sample(client_indices, min(batch_size, len(client_indices)))\n","    sampled_data = Subset(train_data, sampled_indices)\n","    # print(f\"client_id: {client_id}, sampled_indices: {len(sampled_indices)}, sampled_data: {len(sampled_data)}\")\n","    sampled_loader = DataLoader(sampled_data, batch_size=len(sampled_indices), shuffle=False, num_workers=0) # Set batch_size to the length of sampled_data\n","\n","    # Move the model to the assigned GPU device\n","    local_model = deepcopy(global_model).to(device)\n","    if optimizer == 'SGD':\n","        local_optimizer = optim.SGD(local_model.parameters(), lr=0.5, momentum=0.9)\n","    else:\n","        local_optimizer = torch.optim.Adam(local_model.parameters(), lr=0.001)\n","\n","\n","    for inputs, targets in sampled_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        # print(len(inputs), len(targets))\n","        local_optimizer.zero_grad()\n","        outputs = local_model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n","        local_optimizer.step()\n","\n","    # Collect model parameters for aggregation\n","    # local_params = torch.cat([param.data.view(-1).cpu() for param in local_model.parameters()])\n","    local_params = torch.cat([param.data.view(-1) for param in local_model.parameters()])\n","\n","\n","    # Cleanup\n","    del local_model, sampled_data, sampled_loader\n","    torch.cuda.empty_cache()\n","\n","    return client_id, local_params\n","\n","\n","def federated_learning(num_clients, aggregation, n_attackers, attack_type, dataset, n_round, batch_size, optim, cross_device, collab, consider_min_round):\n","    \"\"\"Main federated learning loop.\"\"\"\n","    global_model, train_data, testloader = load_model(dataset)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # Initialize global_model_data right away:\n","    global_model_data = torch.cat([p.data.view(-1) for p in global_model.parameters()]).to(device)\n","\n","    # pick 100 random examples as root dataset\n","    #root_indices = random.sample(range(len(train_data)), 50)\n","    #root_data = Subset(train_data, root_indices)\n","\n","    root_size=100\n","    bias_prob = 0.1\n","    biased_class=1\n","    n_biased = int(root_size * bias_prob)  # e.g., 100 * 0.5 = 50\n","    n_other = root_size - n_biased         # e.g., 50\n","\n","    # 1) Gather indices for each group\n","    biased_indices = []\n","    other_indices = []\n","    for i in range(len(train_data)):\n","        _, label = train_data[i]\n","        if label == biased_class:\n","            biased_indices.append(i)\n","        else:\n","            other_indices.append(i)\n","\n","    # 2) Sample from each group\n","    selected_biased = random.sample(biased_indices, n_biased)\n","    selected_others = random.sample(other_indices, n_other)\n","\n","    # 3) Combine them, optionally shuffle\n","    root_indices = selected_biased + selected_others\n","    random.shuffle(root_indices)\n","\n","    # 4) Build a Subset for the root dataset\n","    root_data = Subset(train_data, root_indices)\n","\n","    if dataset == 'HAR':\n","        # Step 1: Split the dataset among clients\n","        total_data_size = len(train_data)\n","\n","        # 1) Identify unique subjects:\n","        subject_list = []\n","        current_subject_id = 1\n","        for ds in train_data.datasets:  # train_data.datasets is a list of sub-datasets\n","            length_ds = len(ds)\n","            for _ in range(length_ds):\n","                subject_list.append(current_subject_id)\n","            current_subject_id += 1\n","\n","        unique_subjects = sorted(list(set(subject_list)))  # e.g., [1, 2, 3, ..., 30]\n","        num_clients = len(unique_subjects)\n","        print(\"Number of clients (subjects):\", num_clients)\n","\n","        # 2) For each subject, gather all example indices belonging to that subject\n","        clients_data_indices = []\n","        for s in unique_subjects:\n","            subject_indices = [i for i, subj in enumerate(subject_list) if subj == s]\n","            clients_data_indices.append(subject_indices)\n","            # Initialize global_model_data right away:\n","\n","    else:\n","\n","        # Step 1: Split the dataset among clients\n","        total_data_size = len(train_data)\n","        client_data_size = total_data_size // num_clients\n","        print(\"client_data_size\", client_data_size)\n","        indices = list(range(total_data_size))\n","        random.shuffle(indices)\n","        clients_data_indices = [indices[i * client_data_size:(i + 1) * client_data_size] for i in range(num_clients)]\n","\n","    global_models = []\n","    mn, sm, mx = 100, 0, 0\n","\n","    with ThreadPoolExecutor(max_workers=THREAD_NUMBER) as executor:  # Adjust max_workers based on your system capabilities\n","        for epoch in range(n_round):\n","            # Ensure server trains on root_data each round\n","            server_params = train_server_model(global_model, root_data, batch_size, criterion, device, optim)\n","\n","            global_model.train()\n","            local_models_data_diff = []\n","\n","            # Delete the oldest item if size is greater then 25\n","            if len(global_models) > 4:\n","                del global_models[0]\n","\n","            futures = [\n","                executor.submit(\n","                    train_local_model,\n","                    client_id,\n","                    client_indices,\n","                    global_model,\n","                    train_data,\n","                    batch_size,\n","                    criterion,\n","                    devices[client_id % len(devices)],  # Alternate between 'cuda:0' and 'cuda:1'\n","                    optim\n","                )\n","                for client_id, client_indices in enumerate(clients_data_indices)\n","            ]\n","\n","            # Collect results\n","            for future in as_completed(futures):\n","                client_id, local_params = future.result()\n","                local_models_data_diff.append(local_params)\n","\n","            for i in range(torch.cuda.device_count()):\n","                torch.cuda.set_device(i)\n","                torch.cuda.empty_cache()\n","            if num_gpus > 0:\n","                torch.cuda.set_device(device)\n","            print(f'For round {epoch}, training done')\n","            # time.sleep(30)\n","            local_models_data = torch.stack(local_models_data_diff).to(device)\n","            del local_models_data_diff\n","            gc.collect()\n","\n","            if attack_type.startswith('XFED'):\n","                for local_machine in range(n_attackers):\n","                    if attack_type == 'XFED_unit_vec':\n","                        deviation = local_models_data[local_machine] / torch.norm(local_models_data[local_machine])\n","                        # deviation = global_model_data / global_model_data\n","                    elif attack_type == 'XFED_sign':\n","                        sgn_vec = torch.sign(local_models_data[local_machine])\n","                        deviation = sgn_vec / torch.norm(sgn_vec)\n","                    else:\n","                        raise ValueError(\"Invalid attack type\")\n","\n","                    if len(global_models) > 1:\n","\n","                        # version 1\n","                        # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu\", torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models))\n","                        # mu = torch.max(torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models, MU_MULTIPLIER))\n","\n","                        # version 2\n","                        # mu = torch.norm(local_models_data[local_machine] - global_model_data)\n","                        # print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}\")\n","\n","                        # version 3\n","                        # global_models.append(local_models_data[local_machine])\n","                        global_distance, pairwise_distance = torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models, MU_MULTIPLIER=MU_MULTIPLIER)\n","                        # global_models.pop()\n","                        # mu = torch.max(global_distance, pairwise_distance)\n","                        # mu = torch.min(global_distance, pairwise_distance)\n","                        # mu = global_distance * 0.5\n","                        # mu = (pairwise_distance + global_distance) / torch.tensor(2)\n","                        mu = pairwise_distance\n","                        # print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}, global_distance: {global_distance}, pairwise_distance: {pairwise_distance}\")\n","\n","                    else:\n","                        mu = torch.tensor(1.0)\n","\n","                    delta = mu * deviation\n","\n","                    # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu: {mu}\\ndeviation: {deviation}\\ndelta: {delta}\\nlocal model: {local_models_data[local_machine]}\\nglobal model: {global_model_data}\")\n","                    if epoch == 0:\n","                        print(f'local_models_data[local_machine] {local_models_data[local_machine].shape} delta {delta.shape}')\n","                        local_models_data[local_machine] -= delta\n","                    else:\n","                        # del local_models_data[local_machine]\n","                        local_models_data[local_machine] = global_model_data - delta\n","                    # print(f\"after update model after attack: {local_models_data[local_machine]}\\n\")\n","                    del deviation, delta, mu\n","\n","\n","            elif attack_type.startswith('VIRAT') and n_attackers > 0:\n","                local_models_data = virat_min_max(local_models_data, n_attackers, attack_type, epoch=epoch)\n","\n","            elif attack_type.startswith('LIE') and n_attackers > 0:\n","                local_models_data = lie_attack(local_models_data, n_attackers, z_values[(num_clients, n_attackers)])\n","\n","            elif attack_type =='FANG_TR_MEAN' and n_attackers > 0:\n","                local_models_data = fang_attack_trmean_partial(local_models_data, n_attackers)\n","\n","            elif attack_type =='FANG_KRUM' and n_attackers > 0:\n","                attacker_grads = local_models_data[:n_attackers]\n","                agg_grads = torch.mean(attacker_grads, 0)\n","                deviation = torch.sign(agg_grads)\n","                mal_update = get_malicious_updates_fang(attacker_grads, agg_grads, deviation, n_attackers)\n","                mal_updates = mal_update.unsqueeze(0).repeat(n_attackers, *[1 for _ in mal_update.shape])\n","                return torch.cat((mal_updates, local_models_data[n_attackers:]), dim=0)\n","\n","            elif attack_type.startswith('C_XFED'):\n","                local_models_data = xfed_c(local_models_data, n_attackers, attack_type, len(global_models), global_model_data, global_models, 0)\n","\n","            elif attack_type.startswith('Hybrid_XFED'):\n","                individual_attacker = n_attackers - collab\n","                for local_machine in range(individual_attacker):\n","                    if attack_type == 'Hybrid_XFED_unit_vec':\n","                        deviation = local_models_data[local_machine] / torch.norm(local_models_data[local_machine])\n","                    elif attack_type == 'Hybrid_XFED_sign':\n","                        sgn_vec = torch.sign(local_models_data[local_machine])\n","                        deviation = sgn_vec / torch.norm(sgn_vec)\n","                    else:\n","                        raise ValueError(\"Invalid attack type\")\n","\n","                    if len(global_models) > 1:\n","                        global_distance, pairwise_distance = torch.norm(local_models_data[local_machine] - global_model_data), get_mu_pairwise_distance(global_models, MU_MULTIPLIER=MU_MULTIPLIER)\n","                        mu = pairwise_distance\n","                        # print(f\"For round {epoch} and advNumber {local_machine}, mu: {mu}, global_distance: {global_distance}, pairwise_distance: {pairwise_distance}\")\n","\n","                    else:\n","                        mu = torch.tensor(1.0)\n","\n","                    delta = mu * deviation\n","\n","                    # print(f\"\\n\\nFor round {epoch} and advNumber {local_machine}, mu: {mu}\\ndeviation: {deviation}\\ndelta: {delta}\\nlocal model: {local_models_data[local_machine]}\\nglobal model: {global_model_data}\")\n","                    if epoch == 0:\n","                        # print(f'local_models_data[local_machine] {local_models_data[local_machine].shape} delta {delta.shape}')\n","                        local_models_data[local_machine] -= delta\n","                    else:\n","                        # del local_models_data[local_machine]\n","                        local_models_data[local_machine] = global_model_data - delta\n","                    # print(f\"after update model after attack: {local_models_data[local_machine]}\\n\")\n","                    del deviation, delta, mu\n","\n","                local_models_data = xfed_c(local_models_data, n_attackers, attack_type, len(global_models), global_model_data, global_models, collab)\n","\n","            elif n_attackers > 0:\n","                raise ValueError(\"Invalid attack type\")\n","\n","            print(f'For round {epoch}, attack done, Lenght of local_models_data:', len(local_models_data))\n","            print(f'Global model data device {global_model_data.device}')\n","\n","\n","            if cross_device == True:\n","\n","                local_models_list = local_models_data.tolist()\n","                # Calculate the number of clients to select\n","                num_clients_to_select = max(1, int(num_clients * (20 / 100)))\n","                # Randomly select clients\n","                selected_clients_list = random.sample(local_models_list, num_clients_to_select)\n","                # Convert the selected list back to a tensor\n","                selected_clients_tensor = torch.tensor(selected_clients_list, device=local_models_data.device)\n","                local_models_data = selected_clients_tensor\n","                print(f'For round {epoch}, cross device done, Lenght of local_models_data:', len(local_models_data))\n","            else:\n","                pass\n","\n","            # Aggregate model updates\n","            if aggregation == 'MEAN':\n","                global_model_data = torch.mean(local_models_data, dim=0)\n","            elif aggregation == 'MEDIAN':\n","                global_model_data = torch.median(local_models_data, dim=0)[0]\n","            elif aggregation == 'KRUM':\n","                # Check if local_models_data is already a tensor\n","                if isinstance(local_models_data, list):\n","                    global_model_data, _ = multi_krum_optimized(local_updates=local_models_data)\n","                else:\n","                    global_model_data, _ = multi_krum_optimized(local_updates=local_models_data)\n","            elif aggregation == 'TR-MEAN':\n","                global_model_data = tr_mean(local_models_data)\n","            elif aggregation == 'CC':\n","                global_model_data = Clippedclustering(local_models_data)\n","            elif aggregation == 'SignGuard':\n","                global_model_data = SignGuard(local_models_data)\n","            elif aggregation == 'FLAME':\n","                global_model_data = flame(local_models_data, global_model, device, num_clients)\n","            elif aggregation == 'DNC':\n","                # NEW aggregator block:\n","                # let's define default hyperparams:\n","                subfrac = 0.2\n","                iters = 5\n","                fltr = 1.0\n","                # call aggregator\n","                # global_model_data = dnc_aggregator(\n","                #     local_models_data,  # shape (num_clients, param_dim)\n","                #     num_clients=num_clients,\n","                #     num_adv=n_attackers,\n","                #     subsample_frac=subfrac,\n","                #     num_iters=iters,\n","                #     fliter_frac=fltr\n","                # )\n","                global_model_data = dnc_aggregator_torch(\n","                    local_models_data,  # shape (num_clients, param_dim)\n","                    num_clients=num_clients\n","                )\n","            elif aggregation == 'FLTrust':\n","                new_update = FLTrust(\n","                    global_model_data,      # old global param vector\n","                    local_models_data,      # final param vectors from clients\n","                    server_params           # final param vector from server root training\n","                )\n","            elif aggregation == 'FreqFred':\n","                global_model_data = freqfed_aggregator(local_models_data)\n","            else:\n","                raise ValueError(\"Invalid aggregation method\")\n","\n","            if torch.isnan(global_model_data).any():\n","                raise ValueError(\"NaN detected in model aggregation\")\n","\n","            # Update global model\n","            start_idx = 0\n","            with torch.no_grad():\n","                for param in global_model.parameters():\n","                    param_size = param.numel()\n","\n","                    if aggregation == 'FLTrust':\n","                        # Because new_update is a difference\n","                        param.copy_(\n","                            (global_model_data[start_idx:start_idx + param_size]\n","                            + new_update[start_idx:start_idx + param_size]\n","                            ).view(param.shape)\n","                        )\n","                    else:\n","                        # Because for your older code, aggregator returns a final param vector\n","                        param.copy_(\n","                            param.copy_(global_model_data[start_idx:start_idx + param_size].view(param.shape))\n","                        )\n","\n","                    start_idx += param_size\n","\n","            # global_models.append(global_model_data.cpu())\n","            global_models.append(global_model_data)\n","\n","            print(f'For round {epoch}, aggregation done')\n","            last_ten_percent = int(n_round * 0.89)\n","            if epoch >= last_ten_percent or epoch%20 == 0:\n","                # Evaluate global model\n","                global_model.eval()\n","                global_model = global_model.to(device)\n","                correct = 0\n","                total = 0\n","                with torch.no_grad():\n","                    for images, labels in testloader:\n","                        images, labels = images.to(device), labels.to(device)\n","                        outputs = global_model(images)\n","                        _, predicted = torch.max(outputs.data, 1)\n","                        total += labels.size(0)\n","                        correct += (predicted == labels).sum().item()\n","\n","                accuracy = 100 * correct / total\n","                print(f'Time {datetime.now()}: Accuracy on round {epoch}, total {num_clients}, attackers {n_attackers}, attack_type {attack_type}, aggregation {aggregation} is: {accuracy:.2f} %')\n","\n","                # File path to save the accuracy log\n","                file_path = os.path.join(data_root, f'accuracy_{dataset}_{aggregation}_{attack_type}_{n_attackers}_mu{MU_MULTIPLIER}_cd_{cross_device}_collab{collab}_log.txt')\n","\n","                # Append accuracy to the file in the data_root location\n","                with open(file_path, 'a') as f:\n","                    f.write(f'Time {datetime.now()}: Accuracy on round {epoch}, dataset {dataset}, total {num_clients}, attackers {n_attackers}, attack_type {attack_type}, aggregation {aggregation} is: {accuracy:.2f} %\\n')\n","\n","                if consider_min_round <= epoch:\n","                    mn = min(mn, accuracy)\n","                    sm += accuracy\n","                    mx = max(mx, accuracy)\n","\n","            global_model = global_model.to('cpu')\n","            del local_models_data\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","        print(f'accuracy_{dataset}_{aggregation}_{attack_type}_{n_attackers}_mu{MU_MULTIPLIER}_cd_{cross_device}_collab{collab}: min {mn} max {mx} avg {sm/(n_round - consider_min_round)}')\n","        # File path to save the accuracy log\n","        file_path = os.path.join(data_root, f'accuracy_{dataset}_{aggregation}_{attack_type}_{n_attackers}_mu{MU_MULTIPLIER}_cd_{cross_device}_collab{collab}_log.txt')\n","\n","        # Append accuracy to the file in the data_root location\n","        with open(file_path, 'a') as f:\n","            f.write(f'Time {datetime.now()}: accuracy_{dataset}_{aggregation}_{attack_type}_{n_attackers}_mu{MU_MULTIPLIER}_cd_{cross_device}_collab{collab}: avg {sm/(n_round - consider_min_round)}% min {mn}% max {mx}%\\n')\n","\n","    # Final cleanup after training\n","    del global_model, train_data, testloader, global_models, criterion\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NG0kwZK9lM9X"},"source":["Example Execution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnRgpMBTlSqv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1528b0e5-c6ee-4ed3-e957-f35027c92021"},"outputs":[{"output_type":"stream","name":"stdout","text":["Subjects found: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n"," 25 26 27 28 29 30]\n","Number of clients (subjects): 30\n","For round 0, training done\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","local_models_data[local_machine] torch.Size([3372]) delta torch.Size([3372])\n","For round 0, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 0, aggregation done\n","Time 2025-04-15 06:55:50.537235: Accuracy on round 0, total 30, attackers 8, attack_type XFED_unit_vec, aggregation MEDIAN is: 57.39 %\n","For round 1, training done\n","For round 1, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 1, aggregation done\n","For round 2, training done\n","For round 2, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 2, aggregation done\n","For round 3, training done\n","For round 3, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 3, aggregation done\n","For round 4, training done\n","For round 4, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 4, aggregation done\n","For round 5, training done\n","For round 5, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 5, aggregation done\n","For round 6, training done\n","For round 6, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 6, aggregation done\n","For round 7, training done\n","For round 7, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 7, aggregation done\n","For round 8, training done\n","For round 8, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 8, aggregation done\n","For round 9, training done\n","For round 9, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 9, aggregation done\n","For round 10, training done\n","For round 10, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 10, aggregation done\n","For round 11, training done\n","For round 11, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 11, aggregation done\n","For round 12, training done\n","For round 12, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 12, aggregation done\n","For round 13, training done\n","For round 13, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 13, aggregation done\n","For round 14, training done\n","For round 14, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 14, aggregation done\n","For round 15, training done\n","For round 15, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 15, aggregation done\n","For round 16, training done\n","For round 16, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 16, aggregation done\n","For round 17, training done\n","For round 17, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 17, aggregation done\n","For round 18, training done\n","For round 18, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 18, aggregation done\n","For round 19, training done\n","For round 19, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 19, aggregation done\n","For round 20, training done\n","For round 20, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 20, aggregation done\n","Time 2025-04-15 06:55:58.649210: Accuracy on round 20, total 30, attackers 8, attack_type XFED_unit_vec, aggregation MEDIAN is: 78.29 %\n","For round 21, training done\n","For round 21, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 21, aggregation done\n","For round 22, training done\n","For round 22, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 22, aggregation done\n","For round 23, training done\n","For round 23, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 23, aggregation done\n","For round 24, training done\n","For round 24, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 24, aggregation done\n","For round 25, training done\n","For round 25, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 25, aggregation done\n","For round 26, training done\n","For round 26, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 26, aggregation done\n","For round 27, training done\n","For round 27, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 27, aggregation done\n","For round 28, training done\n","For round 28, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 28, aggregation done\n","For round 29, training done\n","For round 29, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 29, aggregation done\n","For round 30, training done\n","For round 30, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 30, aggregation done\n","For round 31, training done\n","For round 31, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 31, aggregation done\n","For round 32, training done\n","For round 32, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 32, aggregation done\n","For round 33, training done\n","For round 33, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 33, aggregation done\n","For round 34, training done\n","For round 34, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 34, aggregation done\n","For round 35, training done\n","For round 35, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 35, aggregation done\n","For round 36, training done\n","For round 36, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 36, aggregation done\n","For round 37, training done\n","For round 37, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 37, aggregation done\n","For round 38, training done\n","For round 38, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 38, aggregation done\n","For round 39, training done\n","For round 39, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 39, aggregation done\n","For round 40, training done\n","For round 40, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 40, aggregation done\n","Time 2025-04-15 06:56:06.561924: Accuracy on round 40, total 30, attackers 8, attack_type XFED_unit_vec, aggregation MEDIAN is: 78.56 %\n","For round 41, training done\n","For round 41, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 41, aggregation done\n","For round 42, training done\n","For round 42, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 42, aggregation done\n","For round 43, training done\n","For round 43, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 43, aggregation done\n","For round 44, training done\n","For round 44, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 44, aggregation done\n","For round 45, training done\n","For round 45, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 45, aggregation done\n","For round 46, training done\n","For round 46, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 46, aggregation done\n","For round 47, training done\n","For round 47, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 47, aggregation done\n","For round 48, training done\n","For round 48, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 48, aggregation done\n","For round 49, training done\n","For round 49, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 49, aggregation done\n","For round 50, training done\n","For round 50, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 50, aggregation done\n","For round 51, training done\n","For round 51, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 51, aggregation done\n","For round 52, training done\n","For round 52, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 52, aggregation done\n","For round 53, training done\n","For round 53, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 53, aggregation done\n","For round 54, training done\n","For round 54, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 54, aggregation done\n","For round 55, training done\n","For round 55, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 55, aggregation done\n","For round 56, training done\n","For round 56, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 56, aggregation done\n","For round 57, training done\n","For round 57, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 57, aggregation done\n","For round 58, training done\n","For round 58, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 58, aggregation done\n","For round 59, training done\n","For round 59, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 59, aggregation done\n","For round 60, training done\n","For round 60, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 60, aggregation done\n","Time 2025-04-15 06:56:14.770950: Accuracy on round 60, total 30, attackers 8, attack_type XFED_unit_vec, aggregation MEDIAN is: 80.50 %\n","For round 61, training done\n","For round 61, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 61, aggregation done\n","For round 62, training done\n","For round 62, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 62, aggregation done\n","For round 63, training done\n","For round 63, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 63, aggregation done\n","For round 64, training done\n","For round 64, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 64, aggregation done\n","For round 65, training done\n","For round 65, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 65, aggregation done\n","For round 66, training done\n","For round 66, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 66, aggregation done\n","For round 67, training done\n","For round 67, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 67, aggregation done\n","For round 68, training done\n","For round 68, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 68, aggregation done\n","For round 69, training done\n","For round 69, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 69, aggregation done\n","For round 70, training done\n","For round 70, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 70, aggregation done\n","For round 71, training done\n","For round 71, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 71, aggregation done\n","For round 72, training done\n","For round 72, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 72, aggregation done\n","For round 73, training done\n","For round 73, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 73, aggregation done\n","For round 74, training done\n","For round 74, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 74, aggregation done\n","For round 75, training done\n","For round 75, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 75, aggregation done\n","For round 76, training done\n","For round 76, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 76, aggregation done\n","For round 77, training done\n","For round 77, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 77, aggregation done\n","For round 78, training done\n","For round 78, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 78, aggregation done\n","For round 79, training done\n","For round 79, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 79, aggregation done\n","For round 80, training done\n","For round 80, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 80, aggregation done\n","Time 2025-04-15 06:56:22.915156: Accuracy on round 80, total 30, attackers 8, attack_type XFED_unit_vec, aggregation MEDIAN is: 82.55 %\n","For round 81, training done\n","For round 81, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 81, aggregation done\n","For round 82, training done\n","For round 82, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 82, aggregation done\n","For round 83, training done\n","For round 83, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 83, aggregation done\n","For round 84, training done\n","For round 84, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 84, aggregation done\n","For round 85, training done\n","For round 85, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 85, aggregation done\n","For round 86, training done\n","For round 86, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 86, aggregation done\n","For round 87, training done\n","For round 87, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 87, aggregation done\n","For round 88, training done\n","For round 88, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 88, aggregation done\n","For round 89, training done\n","For round 89, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 89, aggregation done\n","For round 90, training done\n","For round 90, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 90, aggregation done\n","For round 91, training done\n","For round 91, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 91, aggregation done\n","For round 92, training done\n","For round 92, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 92, aggregation done\n","For round 93, training done\n","For round 93, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 93, aggregation done\n","For round 94, training done\n","For round 94, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 94, aggregation done\n","For round 95, training done\n","For round 95, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 95, aggregation done\n","For round 96, training done\n","For round 96, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 96, aggregation done\n","For round 97, training done\n","For round 97, attack done, Lenght of local_models_data: 30\n","Global model data device cuda:0\n","For round 97, aggregation done\n"]}],"source":["# Example execution\n","for MU_MULTIPLIER in [2.5, 3, 3.5, 4]:\n","    for cb in [0]:\n","        for attack_type in ['XFED_unit_vec']: # 'Hybrid_XFED_unit_vec','Hybrid_XFED_sign'  'XFED_unit_vec', 'XFED_sign', 'VIRAT_unit_vec', 'C_XFED_sign', 'LIE', 'FANG_TR_MEAN'\n","            for agg in ['MEDIAN']: # 'FLAME' 'MEAN', 'MEDIAN', 'KRUM', 'TR-MEAN', 'SignGuard', 'CC' 'MEAN', 'MEDIAN', 'KRUM', 'TR-MEAN', 'SignGuard'\n","                for attackers in [8]:\n","                    # torch.cuda.memory._record_memory_history()\n","                    # federated_learning(num_clients=200, n_attackers=attackers, aggregation=agg, n_round=300, dataset='EMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\", cross_device=False, collab=cb, consider_min_round=240)\n","                    # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=250, dataset='FashionMNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\", cross_device=False, collab=0, consider_min_round=225)\n","                    # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=250, dataset='FashionMNIST_3DNN', attack_type=attack_type, batch_size=256, optim=\"SGD\", cross_device=False, collab=0, consider_min_round=225)\n","                    # federated_learning(num_clients=50, n_attackers=attackers, aggregation=agg, n_round=255, dataset='CIFAR10', attack_type=attack_type, batch_size=250)\n","                    # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=1000, dataset='SVHN', attack_type=attack_type, batch_size=64, optim=\"SGD\")\n","                    # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=275, dataset='MNIST', attack_type=attack_type, batch_size=256, optim=\"SGD\", cross_device=False, collab=cb, consider_min_round=248)\n","                    # federated_learning(num_clients=100, n_attackers=attackers, aggregation=agg, n_round=500, dataset='PURCHASE', attack_type=attack_type, batch_size=128, optim=\"SGD\", cross_device=False, collab=cb, consider_min_round=450)\n","                    # federated_learning(num_clients=40, n_attackers=attackers, aggregation=agg, n_round=300, dataset='CIFAR100', attack_type=attack_type, batch_size=250, optim=\"Adam\")\n","                    # federated_learning(num_clients=200, n_attackers=attackers, aggregation=agg, n_round=50, dataset='SYMBIPREDICT', attack_type=attack_type, batch_size=10, optim=\"SGD\", collab=0)\n","                    # federated_learning(num_clients=200, n_attackers=attackers, aggregation=agg, n_round=50, dataset='SYMBIPREDICT', attack_type=attack_type, batch_size=10, optim=\"Adam\", cross_device=False, collab=0)\n","                    federated_learning(num_clients=30, n_attackers=attackers, aggregation=agg, n_round=1000, dataset='HAR', attack_type=attack_type, batch_size=32, optim=\"SGD\", cross_device=False, collab=0, consider_min_round=900)\n","                    # torch.cuda.memory._dump_snapshot(\"cifar10.pickle\")\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1X3t5mq5GeYar0SJTQdAWqgIr9zVQTsLp","timestamp":1740121279934},{"file_id":"1zDVH8FKTgN-bePGXWP0Hy_EIVOkPG2KF","timestamp":1730633766005}],"authorship_tag":"ABX9TyPYk1GVRdQ0xhrSwY2nzSUX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}